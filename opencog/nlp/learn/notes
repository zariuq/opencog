
======================================================================
Crashes and bugs 2013, 2014


Crash 2
-------
All new crash. Note:
1) This is with the old scheme singleton-instance.
2) This one received when defining a function with an unbound variable
   in it.  It should have just been a standard stack trace, but wasn't.
3) Sometimes, when doing this, and parser is running, I get

[2013-12-26 22:50:57:680] [ERROR] Caught signal 11 (Segmentation fault) on thread 47486186035520
        Stack Trace:
        2: CogServerMain.cc:92  _Z7sighandi()
        3: sigaction.c:0        __restore_rt()
        4: ??:0   std::string::append(std::string const&)
        5: basic_string.h:290     std::string::_M_data() const
        6: SchemeEval.cc:381      opencog::SchemeEval::c_wrap_eval(void*)
line 381 is  self->answer = self->do_eval(*(self->pexpr));
So maybe p is null, or self->pexpr is null..
...
        7: continuations.c:511  c_body()
        8: vm-i-system.c:855    vm_regular_engine()
        9: eval.c:508   scm_call_4()
        10: continuations.c:456 scm_i_with_continuation_barrier()
        11: continuations.c:550 scm_c_with_continuation_barrier()
        12: pthread_support.c:1272      GC_call_with_gc_active()
        13: threads.c:937       with_guile_and_parent()
        14: misc.c:1835 GC_call_with_stack_base()
        15: threads.c:959       scm_with_guile()
        16: SchemeEval.cc:372     opencog::SchemeEval::eval(std::string const&)
        17: basic_string.h:536  ~basic_string()
        18: GenericShell.cc:157   opencog::GenericShell::eval(std::string const&, opencog::ConsoleSocket*)
        19: ConsoleSocket.cc:232          opencog::ConsoleSocket::OnLine(std::string const&)
        20: basic_string.h:536  ~basic_string()
        21: thread.cpp:0        thread_proxy()
        22: pthread_create.c:0  start_thread()
        23: ??:0        __clone()

again 7 Jan 2014 but this time its different:

[2014-01-07 00:58:32:234] [ERROR] Caught signal 11 (Segmentation fault) on threa
d 47389012408640
        Stack Trace:
        2: CogServerMain.cc:91  _Z7sighandi()
        3: sigaction.c:0        __restore_rt()
        4: vm-i-system.c:887    vm_regular_engine()
        5: eval.c:508   scm_call_4()
        6: backtrace.c:163      scm_display_error()
        7: inline.h:131 scm_puts()
        8: vm-i-system.c:855    vm_regular_engine()
        9: eval.c:508   scm_call_4()
        10: SchemeEval.cc:433     opencog::SchemeEval::do_eval(std::string const&)
        11: SchemeEval.cc:392     opencog::SchemeEval::c_wrap_eval(void*)
        12: continuations.c:511 c_body()
        13: vm-i-system.c:855   vm_regular_engine()
        14: eval.c:508  scm_call_4()

19 Jan 2014: again: same but different:

[2014-01-19 06:06:32:335] [ERROR] Caught signal 11 (Segmentation fault)
on threa
d 47820857940288
        Stack Trace:
        2: CogServerMain.cc:91  _Z7sighandi()
        3: sigaction.c:0        __restore_rt()
        4: ??:0 strlen()
        5: strings.c:1518       scm_from_stringn()
        6: strports.c:517       scm_c_eval_string()
        7: vm-i-system.c:855    vm_regular_engine()
        8: eval.c:508   scm_call_4()
        9: SchemeEval.cc:433    opencog::SchemeEval::do_eval(std::string const&)
        10: SchemeEval.cc:392   opencog::SchemeEval::c_wrap_eval(void*)

Got exactly above, again 21 Jan.

Preceeded a few minutes earlier by below.

opencog-fr> Backtrace:
In ice-9/boot-9.scm:
 157: 6 [catch #t #<catch-closure 25dd04e0> ...]
In unknown file:
   ?: 5 [apply-smob/1 #<catch-closure 25dd04e0>]
In ice-9/boot-9.scm:
 157: 4 [catch #t #<catch-closure 25d2ff20> ...]
In unknown file:
   ?: 3 [apply-smob/1 #<catch-closure 25d2ff20>]
   ?: 2 [call-with-input-string "(observe-text \"Hvozdnica est un village de Slovaquie situé dans la région de \u017dilina.\")\n" ...]
In ice-9/boot-9.scm:
 102: 1 [#<procedure cfebf00 at ice-9/boot-9.scm:97:6 (thrown-k . args)> encoding-error ...]
In unknown file:
   ?: 0 [apply-smob/1 #<catch-closure 25d2fee0> encoding-error ...]
ERROR: In procedure apply-smob/1:
ERROR: In procedure scm_to_stringn: Error while printing exception.
ABORT: encoding-error
Backtrace:
In ice-9/boot-9.scm:
 157: 6 [catch #t #<catch-closure 174c8ac0> ...]
In unknown file:
   ?: 5 [apply-smob/1 #<catch-closure 174c8ac0>]
In ice-9/boot-9.scm:
 157: 4 [catch #t #<catch-closure ac0b5e0> ...]
In unknown file:
   ?: 3 [apply-smob/1 #<catch-closure ac0b5e0>]
   ?: 2 [call-with-input-string "(observe-text \"Hvozdnica est un village de Slovaquie situé dans la région de \u017dilina.\")\n" ...]
In ice-9/boot-9.scm:
 102: 1 [#<procedure a82f4c0 at ice-9/boot-9.scm:97:6 (thrown-k . args)> encoding-error ...]
In unknown file:
   ?: 0 [apply-smob/1 #<catch-closure ac0b5a0> encoding-error ...]

ERROR: In procedure apply-smob/1:
ERROR: In procedure scm_to_stringn: Error while printing exception.
ABORT: encoding-error


Crash 6
-------
All new 21 jan 2014

[2014-01-21 20:30:03:348] [ERROR] Caught signal 11 (Segmentation fault) on thread 47570270030144
        Stack Trace:
        2: CogServerMain.cc:91  _Z7sighandi()
        3: sigaction.c:0        __restore_rt()
        4: ??:0   std::back_insert_iterator<std::vector<opencog::Handle, std::allocator<opencog::Handle> > > opencog::Atom::getIncomingSet<std::back_insert_iterator<std::vector<opencog::Handle, std::allocator<opencog::Handle> > > >(std::back_insert_iterator<std::vector<opencog::Handle, std::allocator<opencog::Handle> > >)
        5: AtomSpaceImpl.cc:402 opencog::AtomSpaceImpl::getIncoming(opencog::H
andle)
        6: ??:0   opencog::AtomSpace::getIncoming(opencog::Handle)
        7: SchemeSmobNew.cc:538   opencog::SchemeSmob::ss_delete(scm_u

Again, same exact trace:
[2014-01-22 07:42:21:675] [ERROR] Caught signal 11
* Again, same exact trace .. again, only for french. Why is french different???
* Again, same exact trace ..  22 Jan
* Again, same exact trace ..  23 Jan  Only in french ... wtf ...
* Again, same exact trace ..  23 Jan  Only in french ... wtf ...
* Again, same exact trace ..  24 Jan  Only in french ... wtf ...
* Again, handle=480036842 ptr is null .. why?


But this time without the weirdo message:
terminate called after throwing an instance of 'boost::exception_detail::clone_impl<boost::exception_detail::error_info_injector<boost::lock_error> >'
  what():  boost shared_lock has no mutex: Operation not permitted

WTF ... where is the above shared_lock coming from????



Crash 7
-------
[2014-01-22 10:18:24:103] [ERROR] Caught signal 11 (Segmentation fault)
on thread 47155674880320
        Stack Trace:
        2: CogServerMain.cc:91  _Z7sighandi()
        3: sigaction.c:0        __restore_rt()
        4: ConsoleSocket.cc:211 opencog::ConsoleSocket::OnLine(std::string const&)





Irritation 4
------------
Occasionally see this:

In ice-9/boot-9.scm:
 157: 6 [catch #t #<catch-closure 294a63c0> ...]

   ?: 3 [apply-smob/1 #<catch-closure 294a62a0>]
   ?: 2 [call-with-input-string "(observe-text \"Cheopso piramid\u0117, arba Did
\u017eioji Gizos piramid\u0117 \u2013 Egipto piramid\u0117, faraono Cheopso kapa
s.\")\n" ...]
In ice-9/boot-9.scm:
 102: 1 [#<procedure 193e5c80 at ice-9/boot-9.scm:97:6 (thrown-k . args)> encodi
ng-error ...]

-----------
another:
 "(observe-text \"Andrzej G\u0105siorowski i Krzysztof Steyer, Tajna Organizacja Wojskowa Gryf Pomorski, Polnord Wydawnictwo Oskar, Gda\u0144sk 2010 r.\")\n" .

Andrzej Gąsiorowski i Krzysztof Steyer, Tajna Organizacja Wojskowa Gryf Pomorski, Polnord Wydawnictwo Oskar, Gdańsk 2010 r.

In ice-9/boot-9.scm:
 102: 1 [#<procedure 3db5240 at ice-9/boot-9.scm:97:6 (thrown-k . args)> encoding-error ...]
In unknown file:
   ?: 0 [apply-smob/1 #<catch-closure 3be53c40> encoding-error ...]

ABORT: encoding-error

ERROR: In procedure scm_to_stringn: Error while printing exception.


Crash 8
-------
[2015-07-17 12:37:57:428] [ERROR] Caught signal 11 (Segmentation fault) on
thread 140537051608832
        Stack Trace:
        2: basic_string.h:539   ~basic_string()
        3: CogServerMain.cc:79  _Z7sighandi()
        4: ??:0 killpg()
        5: ??:0 scm_make_vm()
        6: ??:0 GC_mark_from()
        7: ??:0 GC_mark_some()
        8: ??:0 GC_stopped_mark()
        9: ??:0 GC_try_to_collect_inner()
        10: ??:0        GC_collect_or_expand()
        11: ??:0        GC_allocobj()
        12: ??:0        GC_generic_malloc_inner()
        13: ??:0        GC_register_finalizer_inner()
        14: ??:0        scm_closedir()
        15: ??:0        scm_i_new_smob()
        16: smob.h:91   scm_new_smob()
        17: ??:0        scm_vm_engine()
        18: ??:0        scm_call_1()
        19: ??:0        scm_vm_engine()
        20: ??:0        scm_call_3()
        21: ??:0        scm_vm_engine()
        22: ??:0        scm_call_1()
        23: ??:0        scm_vm_engine()
        24: ??:0        scm_call_3()
        25: ??:0        scm_vm_engine()
        26: ??:0        scm_call_4()
        27: SchemeEval.cc:606     opencog::SchemeEval::do_eval(std::string
const&)
        28: SchemeEval.cc:535     opencog::SchemeEval::c_wrap_eval(void*)
        29: ??:0        scm_at_abort()
        30: ??:0        scm_vm_engine()
        31: ??:0        scm_call_4()
        32: ??:0        scm_at_abort()
        33: ??:0        scm_c_with_continuation_barrier()
        34: ??:0        GC_call_with_gc_active()
        35: ??:0        scm_current_processor_count()
        36: ??:0        GC_call_with_stack_base()
        37: ??:0        scm_with_guile()
        38: SchemeEval.cc:502     opencog::SchemeEval::eval_expr(std::string
const&)
        39: basic_string.h:293    std::string::_M_data() const
        40: ??:0
std::this_thread::__sleep_for(std::chrono::duration<long, std::ratio<1l, 1l>
>, std::chrono::duration<long, std::ratio<1l, 1000000000l> >)
        41: ??:0        start_thread()
        42: ??:0        clone()


Garbage 9
---------
submit-one: The town has an area of 88 km², population (2003) is 158,000, and is
located 20 km north of downtown Hồ Chí Minh City, on the left bank of the Saigon River,
upstream from Hồ Chí Minh City.
duuude before nectcat open 27
opencog-en> Backtrace:
In ice-9/boot-9.scm:
 157: 6 [catch #t #<catch-closure 195d220> ...]
In unknown file:
   ?: 5 [apply-smob/1 #<catch-closure 195d220>]
In ice-9/boot-9.scm:
 157: 4 [catch #t #<catch-closure 195d0e0> ...]
   ?: 5 [apply-smob/1 #<catch-closure 1959f00>]
In ice-9/boot-9.scm:
 157: 4 [catch #t #<catch-closure 1959dc0> ...]
In unknown file:
   ?: 3 [apply-smob/1 #<catch-closure 1959dc0>]
   ?: 2 [call-with-input-string "(observe-text \"Although this town is an
administratively separate town, it is considered as part of the H\u1ed3 Chí Minh City
Metropolitan Area since this town is bordered by H\u1ed3 Chí Minh City\u2019s urban
area.\")\n" ...]
In ice-9/boot-9.scm:
 102: 1 [#<procedure 1addf40 at ice-9/boot-9.scm:97:6 (thrown-k . args)> encoding-error
...]
In unknown file:
   ?: 0 [apply-smob/1 #<catch-closure 1959d80> encoding-error ...]


/bin/bash ./ss-one.sh en beta-pages/T/Thủ Dầu Một lo


So -- looks like netcat is sending correct text, but by the time
observe-text gets it, it has been garbled. Why?
Well, nlp/scm/processing-utils.scm prints it ungarbled.

OK, so this fails:
(define sss (socket PF_INET SOCK_STREAM 0))
(connect sss AF_INET (inet-pton AF_INET "127.0.0.1") 7777)
(display "SmålandSmåland" sss)

prints garbage

(set-port-encoding! sss "utf-8")
does not fix it.
(use-modules (rnrs bytevectors))
(send sss (string->utf8 "Hòa Phú Tân Mỹ")) does not work


Ahhh ... (string->utf8 "Småland") prints
#vu8(83 109 63 108 97 110 100)
which is what netcat receives

å should be c3 a5  U+00E5

guile-git is broken
guile-2.0.9 shell works great.
cogserver linked to guile-2.0.9 is broken
... but is fixed by using (set-port-encoding! sss "utf-8")
Yayyy!


Boo ...
submit-one: Phú Mỹ.
(observe-text \"Phú M\u1ef9.\")

ditto for Phú Thọ.
Chánh Nghĩa.
Hiệp Thành
Thủ Dầu Một
Hồ Chí Minh

(relex-parse "Ćićolina\n")
(x-sock-io "Ćićolina\n")
(x-sock-io "Thủ Dầu Một\n")

(define (x-sock-io sent-txt)
   (let ((s (socket PF_INET SOCK_STREAM 0)))
      (connect s AF_INET (inet-pton AF_INET "10.70.70.2") 7777)
      (set-port-encoding! s "utf-8")

      (display sent-txt s)
      (system (string-join (list "echo \"Info: send to parser: " sent-txt "\"")))
      (close-port s)))

(setlocale LC_ALL "")

(set-port-encoding! (current-input-port) "utf-8")
(display "Ćićolina\n")
(define x "Ćićolina\n")   breaks  on cogserver for guile-2.0.9 but
(define x "Thủ Dầu Một\n")  as above
(define x "Småland\n") ... works!!
(define x "Hòa Phú Phú Tân\n")  ... works  !!!
(define x "x\u0106i\u0107olina\\n") works

Ć is U+0106  c4 86
ć is U+0107  c4 87

what is bizarre is that the above is exactly inverted for
the guile-2.1 shell:
sending the  "working" ones sends garbage, sending the failing ones goes through.
(ditto for just simply printing....)

both define/display seem to work fine in the guile-2.0.9 shell...
and define/display seem to work well for the cogserver-2.1 shell. WTF.
so is it due to a shared-library mis-match?  Caching of compiled files?

(display "SmålandSmåland\n")
(display "Ćićolina\n")
(display "Thủ Dầu Một\n")
(display "Hòa Phú Phú Tân\n")

Avoiding preload of all scheme does not fix it.
Clearling the guile compiler cache does not fix it.

[call-with-input-string "(define x \"\u0106i\u0107olina\\n\")\n" ...]

ERROR: In procedure call-with-input-string:
ERROR: Throw to key `encoding-error' with args `("scm_to_stringn" "cannot convert wide
string to output locale" 84 #f #f)'.

(define x "\u0106i\u0107olina\n")

%default-port-encoding is a fluid ....
make fluid with default ...
make dynamic state (with parent ....)

Solution! (setlocale LC_ALL "") every time a new thread is created.

======================================================================
Jan-Feb 2014

Performance
-----------
Performance seems to suck:
-- two parsers, each takes maybe 4% cpu time total. Load avg of about 0.03
-- each parser runs 4 async write threads pushing atoms to postgres.
   each one complains about it taking too long to flush the write queues.
-- postmaster is running 10 threads, load-avg of about 2.00  so about
   2 cpu's at 100%
-- vmstat shows 500 blks per second written. This is low...
-- top shows maybe 0.2% wait state. So its not disk-bound.
-- what is taking so long?

So, take a tcpdump:
-- a typical tcpdump packet:
   UPDATE Atoms SET tv_type = 2, stv_mean = 0 , stv_confidence = 0, stv_count = 54036 WHERE uuid = 367785;
   its maybe 226 bytes long.
-- this gets one response from server, about 96 bytes long.
-- then one more req, one more repsonse, seems to be a 'were'done' mesg
   or something ...  which I guess is due to SQLFreeHandle(SQL_HANDLE_STMT ???
-- time delta in seconds, of tcpdump of traffic packets, between update, and
   response from server:
   0.0006  0.0002 0.0002 0.0002 0.028 (yow!!) 0.001 0.0002

-- so it looks like about every 8-10 packets are replied to fairly quick,
   then there's one that takes 0.025 seconds to reply.... stair-steps in
   response time like this all the way through the capture.

Wild guess:
-- Hmm ... this seems to be related to the commit delay in postgresql.conf
   Change commit_delay to 1 second
   change wal_bufers to 32MB since its mostly update traffic.
   change checkpoint_segments to 32 (each one takes up 16MB of disk space.)

-- Making these changes has no obvious effect ... bummer.

I don't get it; performance sucks and I don't see why.  Or rather: postmaster
is chewing up vast amounts of cpu time for no apparent reason...


select * from pg_stat_user_tables;
select * from pg_stat_all_tables;
select * from pg_statio_user_tables;
select * from pg_database;

pg_stat_user_indexes
pg_stat_all_indexes

select * from pg_catalog.pg_stat_activity;
select * from pg_catalog.pg_locks;


-- WOW!!!   VACUUM ANALYZE; had a huge effect!!

-- vacuum tells em to do following:
   change max_fsm_pages to 600K
   chage max_fsm_relations to 10K

Anyway ... performance measured as of 27 Dec 2013:

Takes about 105 millisecs to clear 90 eval-links from the write-back
queues. This each eval-link is 5 atoms (eval, defind, list, word, word)
so this works out to 5*90 atoms /0.105 seconds = 4.3KAtoms/sec
which is still pretty pathetic...

gdb:
---
handle SIGPWR nostop noprint
handle SIGXCPU nostop noprint


How about using a reader-writer lock?
----------------------------------

boost::shared_lock  for reading,
unique_lock for writing ...

upgrade_lock<shared_mutex> lock(workerAccess);
        upgrade_to_unique_lock<shared_mutex> uniqueLock(lock);


shared_mutex
write uses:  unique_lock<shared_mutex>
readers use shared_lock<shared_mutex>

writer does:

  // get upgradable access
  boost::upgrade_lock<boost::shared_mutex> lock(_access);

  // get exclusive access
  boost::upgrade_to_unique_lock<boost::shared_mutex> uniqueLock(lock);
  // now we have exclusive access
}

am using boost-1.49 on cray

======================================================================
======================================================================

8 Aug 2015
----------

# select * from typecodes where typename='WordNode';
 type | typename 
------+----------
   73 | WordNode

select * from typecodes where typename='ListLink';
 type | typename 
------+----------
    8 | ListLink

select * from typecodes where typename='EvaluationLink';
 type |    typename    
------+----------------
   47 | EvaluationLink

en_pairs=# select * from typecodes where typename='AnyNode';
 type | typename 
------+----------
   74 | AnyNode



select uuid,stv_count,name from atoms where type=73 and name='Northern';
  uuid   | stv_count |   name   
---------+-----------+----------
 1018149 |      9426 | Northern

select uuid,stv_count,name from atoms where type=73 and name='Ireland';
  uuid   | stv_count |  name   
---------+-----------+---------
 1018155 |     12288 | Ireland

select sum(stv_count) from atoms where type=73;
   sum    
----------
 78615971

that is, N(*) = 78615971


So we conclude that -log_2 P(Northern) = -log_2 (9426 / 78615971)
= -log_2 (1.1989930137732446e-4) = 13.025889126989188

-log_2(Ireland) = -log_2(12288 / 78615971)
= -log_2(1.563041178999112e-4) = 12.643356592283384




select uuid, stv_count from atoms where type=8 and outgoing='{1018149, 1018155}';
  uuid   | stv_count 
---------+-----------
 1023156 |         0

any==152
select * from typecodes where type=89;
 type |          typename           
------+-----------------------------
   89 | LinkGrammarRelationshipNode


select uuid,type,stv_count from atoms where type=89;
 uuid | type | stv_count 
------+------+-----------
  152 |   89 |  23830549


select uuid,stv_confidence, stv_count from atoms where type=47 and outgoing='{152, 1023156}';
  uuid   | stv_confidence | stv_count 
---------+----------------+-----------
 1023157 |      10.743062 |      1314


So N(Northern, Ireland) = 1314

Next ...
select uuid,name from atoms where type=74;
   uuid    |    name    
-----------+------------
 143427138 | left-word
 143427163 | right-word

select uuid, stv_count from atoms where type=8 and outgoing='{143427138, 143427163}';
   uuid    | stv_count 
-----------+-----------
 143670792 |         0

select uuid,stv_confidence,stv_count from atoms where type=47 and outgoing='{152, 143670792}';
   uuid    | stv_confidence | stv_count 
-----------+----------------+-----------
 143670793 |              0 |  39333063


So N(*,*) = 39333063

So P(Northern, Ireland) = 1314 / 39333063 = 3.340700926342807e-5

-log_2 P(Northern, Ireland) = 14.869489642136607


Get (Northern,*)
select uuid, stv_count from atoms where type=8 and outgoing='{1018149, 143427163}';

143526182 == uuid of above
select uuid,stv_confidence,stv_count from atoms where type=47 and outgoing='{152, 143526182}';
   uuid    | stv_confidence | stv_count 
-----------+----------------+-----------
 143526183 |      12.992029 |      4828

So N(Northern,*) = 4828

P(Northern,*) = 4828 / 39333063 = 1.227466063347266e-4

-log_2 P(Northern,*) = 12.992029241703914  agrees with above.

Get (*, Ireland)
select uuid, stv_count from atoms where type=8 and outgoing='{143427138, 1018155}';

uuid=143526120

select uuid,stv_confidence,stv_count from atoms where type=47 and outgoing='{152,143526120}';
   uuid    | stv_confidence | stv_count 
-----------+----------------+-----------
 143526121 |      12.620522 |      6246


So: N(*, Ireland) = 6246
P(*, Ireland) = 6246 / 39333063 = 1.58797701567254e-4

-log_2 P(*, Ireland) = 12.620522348438364

MI(Northern, Ireland) = 
log_2 P(Northern, Ireland) - log_2 P(Northern,*) - log_2 P(*, Ireland)

= - 14.869489642136607 + 12.992029241703914 + 12.620522348438364
= 10.743061948005671 agrees with SQL

Next:
P(Northern,*) = 4828 / 39333063 = 1.227466063347266e-4

P(Northern) = (9426 / 78615971) = 1.1989930137732446e-4

So P(Northern,*) < P(Northern)  aiiieeeee false!
and 
P(R(Northern,*)|Northern) ==
P(Northern,*) / P(Northern) = 

P(*, Ireland) = 6246 / 39333063 = 1.58797701567254e-4

P(Ireland) = (12288 / 78615971) = 1.563041178999112e-4


P(R(*, Ireland) | Ireland) ==
  P(*, Ireland) / P(Ireland)

So P(R(Northern, Ireland) | Northern, Ireland) is huge!! >> 1



So N(*,*) = 39333063

N(*) = 78615971

P(R(*,*)) = 39333063 / 78615971 = 0.5003189873467314

log_2 ((R,*,*)) = 0.9990798905456042

Strange ... I expect more pairs than words ... !?

Is the 1/2 an accident due to the parse-damange?


31 Dec 2016
-----------

psql en_pairs
\dt

select count(*) from atoms;
 18487291

loadmodule libPersistModule.so

sql-open learn-pairs linas asdf
sql-open en-pairs linas asdf

password authentication failed for user "linas"

sql-open opencog_test opencog_tester cheese

/etc/postgresql/9.6/main/pg_hba.conf looks OK...

So: I have en_pairs and 
 opencog_test | linas    | UTF8     | en_US.UTF-8 | en_US.UTF-8 | 
but the owner of the tables is opencog_tester

/var/log/postgresql/postgresql-9.6-main.log

2017-01-03 16:15:50 CST [2856-1] linas@en_pairs FATAL:  password authentication
failed for user "linas"
2017-01-03 16:15:50 CST [2856-2] linas@en_pairs DETAIL:  User "linas" has no password
assigned.


2017-01-01 17:20:54 CST [4829-1] opencog_tester@opencog_test ERROR:  insert or update
on table "atoms" violates foreign key constraint "atoms_space_fkey"
2017-01-01 17:20:54 CST [4829-2] opencog_tester@opencog_test DETAIL:  Key (space)=(2)
is not present in table "spaces".

(use-modules (opencog persist-sql))
(sql-open "en-pairs" "learner" "asdf")

\du
alter user learner password 'asdf';
grant CONNECT ON DATABASE en_pairs to learner;
grant SELECT,INSERT,UPDATE on table atoms to learner;

sql-open en-pairs learner asdf

it worked!
(sql-load)

18 million atoms

Loaded 9045489 atoms at height 2
Finished loading 18487291 atoms in total
12:35 to load .. !? 18487291 atoms/755 secs = 24.5K atoms/sec

psql -h localhost -U ubuntu lt_pairs 

ALTER USER ubuntu PASSWORD 'asdf';

========================================================
-----------------------------------------
lxc -- create an all-updated opencog-base

lxc-start -n opencog-base --daemon

time lxc-copy -n  opencog-learn -N learn-lt

------------------------------------
4 Jan 2016
----------
https://dumps.wikimedia.org/zhwiki/20170101/
https://dumps.wikimedia.org/zh_yuewiki/20170101/
https://dumps.wikimedia.org/frwiki/20170101/

lynx https://dumps.wikimedia.org/ltwiki/20170101/ltwiki-20170101-pages-articles-multistream.xml.bz2

time cat ltwiki-20170101-pages-articles-multistream.xml.bz2 |bunzip2 |/home/ubuntu/src/relex/src/perl/wiki-scrub.pl
real	4m58.871s
user	5m35.652s
sys	0m11.700s

find |wc gives 209011 total articles
find |wc gives 178514 after cat/template removal

createdb lt_pairs
createdb lt_morph
cat opencog/persist/sql/odbc/atom.sql | psql lt_pairs
cat opencog/persist/sql/odbc/atom.sql | psql lt_morph

=============================================================

time cat zh_yuewiki-20170101-pages-articles.xml.bz2 |bunzip2 |/home/ubuntu/src/relex/src/perl/wiki-scrub.pl

about 48 seconds
find |wc gives 67363 total articles
find |wc gives 49170 after cat/template removal

apt-get install fonts-arphic-ukai fonts-arphic-uming fonts-babelstone-han
fonts-wqy-zenhei fonts-hanazono

fonts-arphic-bkai00mp
fonts-arphic-bsmi00lp
fonts-arphic-gbsn00lp
fonts-arphic-gkai00mp

Arghh. None of the above provide the Kangxi radicals for the terminal.
Which I think are coming from fonts-wqy-microhei

U+2F13  Kangxi Radicals,

U+42AA  U+4401   CJK_Ext_A  CJK-Ext.A

createdb yue_pairs

cd ~/src/atomspace
cat opencog/persist/sql/odbc/atom.sql | psql yue_pairs

。。

\p{Block: CJK}   
\p{Block=CJK_Symbols_And_Punctuation} 
\p{Punct}
\p{InCJK}) 
\p{Close_Punctuation}   aka \p{Pe}   (close parent)
 \p{Final_Punctuation}   aka \p{Pf})  more quote-close or open.. things
\p{Ps} open quote


full stop

relex-server-port relex-server-host


; -- count-all -- Return the total number of atoms in the atomspace.
; -- cog-get-atoms -- Return a list of all atoms of type 'atom-type'
; -- cog-prt-atomspace -- Prints all atoms in the atomspace
; -- cog-count-atoms -- Count of the number of atoms of given type.
; -- cog-report-counts -- Return an association list of counts.


wtf 
(define (foo atom) (display "duude\n")(display atom) (newline) #f) 

WARNING: No known abbreviations for language 'yue', attempting fall-back
to English version..    FIXED

odbc is still logging! FIXED
CommLog           = No in /etc/odbcinst.ini

don't use "foo", it prints a warning .. better yet, don't warn! FIXED


below is due to bug opencog/relex#248 and is now fixed.
It  needed a new link-grammar version
link-grammar: Error: EMPTY-WORD.zzz must be defined!

link-grammar: Error: Word 'EMPTY-WORDzzz': Internal error: NULL X_node

link-grammar: Error: sentence_split(): Internal error detected
Warning: No parses found for:
港 區 全 國 人 大 代 表 係 代 表 香 港 居 民 響 中 華 人 民 共 和 國 全 國 人 民 代 表 大 會 行 使 國 家 立 法 權 嘅 代 表 ， 名 額 36 人 （1997 年 香 港 主 權 移 交 之 後 ）。


link-grammar: Error: EMPTY-WORD.zzz must be defined!

link-grammar: Error: Word 'EMPTY-WORDzzz': Internal error: NULL X_node

link-grammar: Error: sentence_split(): Internal error detected
Warning: No parses found for:
深 圳 習 慣 叫 特 區 範 圍 做 「 關 內 」， 而 特 區 範 圍 之 外 嘅 ，
包 括 寶 安 區 、 龍 崗 區 同 光 明 新 區 、 坪 山 新 區 就 叫 「 關 外
」； 由 「 關 外 」 入 特 區 叫 「 入 關 」， 反 之 係 「 出 關 」。

<title>永利街</title>  contains junk yest it does...


Started 5 Jan 2017 16:00 exactly.
ten minutes later: 5048 atoms -- so 500 atoms per minute...
after some halts and hiccups:
2211 articles after 1 hour = 37 articles/minute
18529 atoms after about 1 hour ...
or about 8.4 atoms per article... 

There are only about 48K articles, so it should conclude in 24 hours
...!?

hours later... 219127 atoms 6345 articles done ...
Now its about 34.5 atoms per article.. whoa ... 

java claims to have parsed 12424 sentences
11459 articles processed.
457009 atoms


29291 articles processed 19919 remaining
668042 atoms ...


; -- cog-report-counts -- Return an association list of counts.

(count-all)
(cog-report-counts)
(gc-stats)

... ram usage slowly increasing...

 (gc-stats)
((gc-time-taken . 315428672862) (heap-size . 3479842816) (heap-free-size
. 1406132224) (heap-total-allocated . 132540491040)
(heap-allocated-since-gc . 906048240) (protected-objects . 500)
(gc-times . 414))

(gc-stats)
((gc-time-taken . 327615529234) (heap-size . 3582787584) (heap-free-size
. 1584795648) (heap-total-allocated . 138942040624)
(heap-allocated-since-gc . 1123554048) (protected-objects . 500)
(gc-times . 422))

((gc-time-taken . 491224665617) (heap-size . 4601581568) (heap-free-size
. 2257489920) (heap-total-allocated . 211782122608)
(heap-allocated-since-gc . 399939472) (protected-objects . 500)
(gc-times . 485))


if (number-of-cells-collected-recently < GUILE_MIN_YIELD_X)
  then
    allocate-new-heap
  else
    run-a-collection

`scm_i_gc_grow_heap_p ()' and `scm_gc_for_newcell ()'.)


(WordSequenceLink lots of these ... 


 gcprof procedure in the statprof library
https://www.gnu.org/software/guile/manual/html_node/Statprof.html

guile-yue> (statprof-display)
%     cumulative   self             self     total             
time   seconds    seconds  calls    ms/call  ms/call       name
 49.18  11506.88  11506.88   13516   851.35   851.35  inc
  4.92  23397.33   1150.69      27 42618.08 866567.64  catch
  4.92  12657.57   1150.69     215  5352.04 58872.42  cog-map-type
  3.28    767.13    767.13    1420   540.23   540.23  char=?
  3.28    767.13    767.13     619  1239.30  1239.30  write-char
  3.28    767.13    767.13     372  2062.17  2062.17  memq
  3.28    767.13    767.13     182  4214.97  4214.97  call-with-output-string
  1.64   2684.94    383.56     182  2107.49 14752.41  tilde-dispatch
  1.64    383.56    383.56      29 13226.30 13226.30  close-port
  1.64    383.56    383.56     240  1598.18  1598.18  assv-ref
...
  0.00  12657.57      0.00     215     0.00 58872.42  cog-count-atoms

above over about 24K seconds total, so accurate... ish

(use-modules (statprof))
(statprof-reset 0 50000 #t) ;
(statprof-start)
(do-something)
(statprof-stop)
(statprof-display)
(gcprof (λ () (observe-text "1769 年 ： 伊 萬 克 雷 洛 夫 ， 俄 國 寓 言 作 家 1910 年 ： 威 廉  肖 克 利 （William Shockley）， 美 國 物 理 學 家 ， 有 份 發 明 半 導 體 ，1956 年 諾 貝 爾 物 理 獎 得 主 1915 年 ： 昂 山 ， 緬 甸 國 父 1921 年 ： 趙 無 極 ， 法 國 華 裔 畫 家 1974 年 ：Robbie Williams， 英 國 歌 手 1974 年 ： 馬 國 明 ， 香 港 無 綫 電 視 演 員 1981 年 ： 何 紫 綸 ， 香 港 模 特 兒 1990 年 ： 西 藏 第 十 一 世 班 禪 額 爾 德 尼 金 瑞 瑤 ， 台 灣 音 樂 經 理 人 1993 年 ： 宋 希 濂 ， 抗 日 戰 爭 同 國 共 內 戰 時 期 中 國 國 民 黨 將 軍 2006 年 ： 王 選 ， 中 國 計 算 機 學 者 ， 發 明 漢 字 激 光 照 排 技 術")))

Maybe use it in "observe-text"? ...

total time is correct...
... its a thread thing. staprof with threads is borked.
See comments in ./module/statprof.scm ~ Implementation notes ~


compute-mi.scm:		(for-each inc atom-list)
compute-mi.scm:		(define (inc atom) (set! cnt (+ cnt (tv-count
(cog-tv atom)))))

Maybe lots and lots of threads ... ? Seems to get very backed-up.
No .. only 14 threads

(hash-map->list cons (module-obarray (current-module)))

(module-map (λ (sym var) sym) (resolve-interface '(guile)))
(module-map (λ (sym var) sym) (resolve-interface '(opencog)))
(module-map (λ (sym var) sym) (resolve-interface '(opencog learn)))

who is using a module?
(module-uses (resolve-module '(guile-user)))

>>>> excellent for modules!
http://git.net/ml/guile-user-gnu/2016-06/msg00040.html

101000   26627  256 11.9 15129736 11795708 pts/6 Sl+ 18:41 516:33 guile
-l pair-count-yue.scm


not being split: FIXED.
fix is
$text =~ s/([\.?!]) *(\p{InCJK})/$1\n$2/g;

呢度啲路順序係從南去到北嚟排列嘅，其中加粗咗嘅字係主幹道：美華北路.新河浦二橫路.新河浦五橫路.新慶路.煙墩路、寺右新馬路.寺貝通津.共和大街.松崗東.共和西路.中山一路.

2012年，《向前走向愛走》.第四十五屆金鐘獎個人獎戲劇節目女主角獎.郭采潔官方網站.


No database persistant storage configured! Use the STORAGE config
keyword to define.

Java gets slower and slower

-------------------------

(use-modules (opencog) (opencog cogserver))
(start-cogserver "cogserver.conf")

(define (inc atom) (cog-set-tv! atom (cog-new-ctv 0 0 (+ 1 (tv-count (cog-tv atom))))))

(define foo (Concept "foo"))
(define (loo) (inc foo) (loo))

Hmmm
(gc-stats)
((gc-time-taken . 9229154858) (heap-size . 14364672) (heap-free-size . 987136)
(heap-total-allocated . 965473792) (heap-allocated-since-gc . 4150752)
(protected-objects . 7) (gc-times . 382))

(ConceptNode "foo" (ctv 0 0 1297544))

---------

(gc-stats)
((gc-time-taken . 36662444393) (heap-size . 27287552) (heap-free-size . 2043904)
(heap-total-allocated . 6769590208) (heap-allocated-since-gc . 12259216)
(protected-objects . 7) (gc-times . 1011))

(ConceptNode "foo" (ctv 0 0 25027699))

---------

gc-stats)
((gc-time-taken . 61656366381) (heap-size . 53968896) (heap-free-size . 18456576)
(heap-total-allocated . 13686988416) (heap-allocated-since-gc . 5711392)
(protected-objects . 7) (gc-times . 1240))

(ConceptNode "foo" (ctv 0 0 38117275))

-------
Hmm looks like we are leaking tv's ... oh wait.. does it stop?

(gc-stats)
((gc-time-taken . 105993964481) (heap-size . 72843264) (heap-free-size . 29458432)
(heap-total-allocated . 27893224720) (heap-allocated-since-gc . 9728)
(protected-objects . 7) (gc-times . 1591))
guile-yue> foo
(ConceptNode "foo" (ctv 0 0 79863947))

Nope ... just a temporary pause, while the free size is whittled down.

(gc-stats)
((gc-time-taken . 114596558158) (heap-size . 89620480) (heap-free-size . 33521664)
(heap-total-allocated . 30637347648) (heap-allocated-since-gc . 7308304)
(protected-objects . 7) (gc-times . 1654))
guile-yue> foo
(ConceptNode "foo" (ctv 0 0 87085578))

But I don't get it .. just one byte per tv ???

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND     
 2603 linas     20   0  981064 160664  30904 R 123.1  0.2  17:28.70 guile       
 2603 linas     20   0  998888 178524  30904 R 123.7  0.2  25:52.19 guile       
 2603 linas     20   0  998888 178580  30904 R 128.7  0.2  40:07.75 guile       
 2603 linas     20   0 1038496 217948  30904 R 131.9  0.2  46:48.42 guile       
 2603 linas     20   0 1040744 220368  30904 R 125.2  0.2  51:08.05 guile       
 2603 linas     20   0 1040876 220276  30904 R 120.1  0.2  83:44.38 guile       
 2603 linas     20   0 1117852 297744  31132 R 118.1  0.3 172:51.42 guile       




----------
 2603 linas     20   0  998888 178524  30904 R 123.7  0.2  25:52.19 guile
Even less than that:
(gc-stats)
((gc-time-taken . 172622614398) (heap-size . 89620480) (heap-free-size . 36347904)
(heap-total-allocated . 48279193696) (heap-allocated-since-gc . 4224)
(protected-objects . 7) (gc-times . 2002))
guile-yue> foo
(ConceptNode "foo" (ctv 0 0 1.3901905e+08))

-------------
 2603 linas     20   0  998888 178580  30904 R 128.7  0.2  40:07.75 guile
(gc-stats)
((gc-time-taken . 217265746382) (heap-size . 106405888) (heap-free-size . 4673536)
(heap-total-allocated . 61824766864) (heap-allocated-since-gc . 59720592)
(protected-objects . 7) (gc-times . 2265))
guile-yue> foo
(ConceptNode "foo" (ctv 0 0 1.7490337e+08))
--------------
2603 linas     20   0 1038496 217948  30904 R 131.9  0.2 46:48.42 guile
(gc-stats)
((gc-time-taken . 415346915596) (heap-size . 139968512) (heap-free-size . 36679680)
(heap-total-allocated . 125921049232) (heap-allocated-since-gc . 26342512)
(protected-objects . 7) (gc-times . 3325))
guile-yue> foo
(ConceptNode "foo" (ctv 0 0 3.5583169e+08))
-------------
 2603 linas     20   0 1040876 220276  30904 R 120.1  0.2  83:44.38 guile       
(gc-stats)
((gc-time-taken . 711424805684) (heap-size . 139968512) (heap-free-size . 11227136)
(heap-total-allocated . 225609862112) (heap-allocated-since-gc . 66243952)
(protected-objects . 7) (gc-times . 4683))
guile-yue> foo
(ConceptNode "foo" (ctv 0 0 6.3894746e+08))

----------------
 2603 linas     20   0 1117848 297520  30904 R 118.8  0.3  97:20.18 guile       
(gc-stats)
((gc-time-taken . 823234806093) (heap-size . 207081472) (heap-free-size . 70197248)
(heap-total-allocated . 263246315808) (heap-allocated-since-gc . 75918272)
(protected-objects . 7) (gc-times . 5155))
guile-yue> foo
(ConceptNode "foo" (ctv 0 0 7.4406271e+08))

---------------------
 2603 linas     20   0 1117852 297744  31132 R 118.1  0.3 172:51.42 guile       
(gc-stats)
((gc-time-taken . 1445970832414) (heap-size . 207081472) (heap-free-size .
63324160) (heap-total-allocated . 471514682464) (heap-allocated-since-gc . 6332752)
(protected-objects . 7) (gc-times . 7211))
guile-yue> foo
(ConceptNode "foo" (ctv 0 0 1.3366125e+09))




=========================

replace call to scm_gc_register_collectable_memory by call to 
scm_gc_register_allocation(size)


whoa --- 
GC Warning: Repeated allocation of very large block (appr. size 27369472):
        May lead to memory leak and poor performance.
GC Warning: Repeated allocation of very large block (appr. size 28766208):
        May lead to memory leak and poor performance.
Loaded 280000 atoms.
GC Warning: Repeated allocation of very large block (appr. size 28766208):
        May lead to memory leak and poor performance.
GC Warning: Repeated allocation of very large block (appr. size 28766208):
        May lead to memory leak and poor performance.
        Loaded 270000 atoms.
GC Warning: Repeated allocation of very large block (appr. size 28766208):
        May lead to memory leak and poor performance.
GC Warning: Repeated allocation of very large block (appr. size 14385152):
        May lead to memory leak and poor performance.
        Loaded 260000 atoms.

================================

fresh, guile-2.0
 (gc-stats)
$6 = ((gc-time-taken . 114568428) (heap-size . 14409728) (heap-free-size .
2711552) (heap-total-allocated . 18881904) (heap-allocated-since-gc .
1054528) (protected-objects . 137) (gc-times . 14))

after half-minute:
(gc-stats)
((gc-time-taken . 7534031063) (heap-size . 19734528) (heap-free-size
. 5259264) (heap-total-allocated . 939889168) (heap-allocated-since-gc .
1657120) (protected-objects . 143) (gc-times . 326))
guile> foo
(ConceptNode "foo" (ctv 0 0 2520410))

 6861 101000    20   0  735404  42952  16680 R 109.9  0.0  14:33.40 guile       
 6861 101000    20   0  735404  42952  16680 R 114.5  0.0  44:35.68 guile       


(gc-stats)
((gc-time-taken . 148069551756) (heap-size . 19734528) (heap-free-size .
2740224) (heap-total-allocated . 28219212944) (heap-allocated-since-gc .
790384) (protected-objects . 143) (gc-times . 4930))
guile> foo
(ConceptNode "foo" (ctv 0 0 54310643))


replace call to scm_gc_register_collectable_memory by call to
scm_gc_register_allocation(size)


   static std::atomic<size_t> _tv_pend_cnt;
   static std::atomic<size_t> _tv_total_cnt;
   static std::atomic<size_t> _tv_pend_sz;
   static std::atomic<size_t> _tv_total_sz;


(define (inc atom) (cog-set-tv! atom (cog-new-ctv 0 0 (+ 1 (tv-count (cog-tv
atom))))))
scheme@(guile-user)> 
scheme@(guile-user)> (define foo (Concept "foo"))
scheme@(guile-user)> (define (loo) (inc foo) (loo))
scheme@(guile-user)> (loo)
duuude its pend cnt=11425 (274200) tot=1400000 (33600000)
duuude its pend cnt=14379 (345096) tot=1500000 (36000000)
duuude its pend cnt=15600 (374400) tot=2200000 (52800000)

duuude its pend cnt=8047 (193128) tot=48300000 (1159200000)
duuude its pend cnt=1230 (29520) tot=49300000 (1183200000)
duuude its pend cnt=12432 (298368) tot=49400000 (1185600000)
duuude its pend cnt=19857 (476568) tot=50000000 (1200000000)
(gc-stats)
((gc-time-taken . 54370538078) (heap-size . 10948608) (heap-free-size . 1925120)
(heap-total-allocated . 8532174704) (heap-allocated-since-gc . 10336)
(protected-objects . 7) (gc-times . 2051))
guile-yue> foo
(ConceptNode "foo" (ctv 0 0 26737610))
 4617 linas     20   0  847596  50284  27072 R 133.2  0.1   5:26.89 guile       

(ConceptNode "foo" (ctv 0 0 46416463))
duuude its pend cnt=20565 (493560) tot=94300000 (2263200000)

so -- 46M incrs but 94M take-tvs -- so two takes for each incr.
-- one to get the value, one to set the value.


 4617 linas     20   0  847584  50612  27156 R 135.2  0.1  23:46.94 guile       

(define (rate)
(define shu (Concept "shu"))
(define cnt 0)
(define start (- (current-time) 0.1))
(define (finc atom) 
	(if (eq? 0 (modulo cnt 100000))
		(begin (display "rate=")
		(display (/ cnt (- (current-time) start))) (newline)))
	(set! cnt (+ cnt 1))
	(cog-set-tv! atom (cog-new-ctv 0 0 (+ 1 (tv-count (cog-tv atom))))))

(define (floo) (finc shu) (floo))
(floo)
)

(define (inc atom) (cog-set-tv! atom (cog-new-ctv 0 0 (+ 1 (tv-count (cog-tv atom))))))

(define foo (Concept "foo"))
(define (loo) (inc foo) (loo))

(statprof-stop)
(statprof-display)


with the atomics: rate == about 145.5K/sec
without the atomics: about 103.2K/sec !!
again with atomics: rate == 125K/sec !! wtf .. why not as high as before?
stop restart, rate=130K ...
stop restart - rate= 107K ... wtf
stop, restart = 109K
stop restart = 107K   glargle
again --- without atomics:
rate = 147K   dafuq
stop restart = 151K
stop restart = 79K   crazy shit
stop restart = 141K  this is so not making sense, except as a
crazy cache-line issue.


clean start: without atomics
(gc-stats)
((gc-time-taken . 845338507) (heap-size . 5963776) (heap-free-size . 421888)
(heap-total-allocated . 73153424) (heap-allocated-since-gc . 902704)
(protected-objects . 7) (gc-times . 65))

(gc-stats)
((gc-time-taken . 605534396784) (heap-size . 6025216) (heap-free-size . 356352)
(heap-total-allocated . 29673578224) (heap-allocated-since-gc . 361904)
(protected-objects . 7) (gc-times . 32428))

no growth at all.


OK, so ... a leak in sql?
a leak in TLB!! ... no because that doesn't explain guile heap...
unless guile heap is confused...

on startup:
(gc-stats)
$1 = ((gc-time-taken . 170774772) (heap-size . 15364096) (heap-free-size .
3166208) (heap-total-allocated . 18421440) (heap-allocated-since-gc .
770768) (protected-objects . 149) (gc-times . 15))

 wtf .. why no printing?


_tv_pend_cnt++;
_tv_pend_sz += sizeof(*tv);

// _tv_total_cnt++;
_tv_total_sz += sizeof(*tv);

if (0 == ((size_t) (_tv_total_cnt.fetch_add(1))) % 100000) {
printf("duuude its pend cnt=%lu (%lu) tot=%lu (%lu)\n",
(size_t) _tv_pend_cnt, (size_t) _tv_pend_sz, (size_t) _tv_total_cnt,
(size_t) _tv_total_sz);
logger().info("duuude its pend cnt=%lu (%lu) tot=%lu (%lu)",
(size_t) _tv_pend_cnt, (size_t) _tv_pend_sz, (size_t) _tv_total_cnt,
(size_t) _tv_total_sz);
}


OK, so its not the TV ... (not the TV in guile gc)

So maybe its prim environ?? Nooo not that either
Maybe handles?? (in guile) no its not that. (not in guile gc)

 well, its not the TLB...
and not the atoms ... TLB has 400K entries, with 18MB of pairs
atoms allocated are 466286 for 63414896 = 63MBytes but guile is
1.6GB resident, 9.3GB virt.... wtf...

each atom is 136 MB ex tv.

2.9 gb resident, but 1.6M atoms for 215MB size, and 64MB of tlb contents
what about atomspace?  only 19922 atoms in atomspace...
heap size is 2GB ... 

Maybe stub out capture-stack? it was the cuplrit before...
Nope seems to make no difference.

are we leaking SCM values somwhere?  How?

misc_to_string ?  no, code audit.
scm_to_utf8_string   no, code audit...

--------------------------------------------------------------
try guile-2.2 from git
Great. that seg-faults... maybe some other version doesn't ...
try 2.1.5 ? 2.1.4 ?   No, because even though it segfaulted
it did seem to also grow.

Seg-faults twice in a row, within 10 minutes wall-clock time
(about 36 mins cpu time).

---------------------------------------------------------------

Try below. ... It does not leak.

(use-modules (opencog) (opencog cogserver))
(start-cogserver)

(define (slu)
(define cnt 0)
(define start (- (current-time) 0.1))
(define (mka) 
	(if (eq? 0 (modulo cnt 100000))
		(begin (display "rate=")
		(display (/ cnt (- (current-time) start))) (newline)
		(cog-map-type (lambda (ato) (cog-extract ato) #f) 'ListLink)
		(cog-map-type (lambda (ato) (cog-extract ato) #f) 'ConceptNode)
	))
	(set! cnt (+ cnt 1))
	(ListLink
		(ConceptNode (string-append "concepto " (number->string cnt )))
		(ConceptNode (string-append "glorg " (number->string cnt )))))

(define (aloo) (mka) (aloo))
(aloo)
)

(count-all)
(cog-report-counts)

(gc-stats)
((gc-time-taken . 6660684289) (heap-size . 15646720) (heap-free-size . 3055616)
(heap-total-allocated . 861940880) (heap-allocated-since-gc . 5203440)
(protected-objects . 7) (gc-times . 298))

((gc-time-taken . 15414762477) (heap-size . 16101376) (heap-free-size . 2859008)
(heap-total-allocated . 2665977008) (heap-allocated-since-gc . 5064624)
(protected-objects . 7) (gc-times . 562))

rate=47.3K  (concept only)
rate=15.7K (listlinks+concepts)

---------------------------------------------------------------

/tmp/bang.sh
#!/bin/bash

i=0
while true ; do
  let i=$i+1
  if [ "$(($i % 2000))" -eq "0" ] ; then
    echo loop $i
  fi
  echo '(display ctr)' | nc localhost 17001
  # echo '(NumberNode ctr)' | nc 10.0.3.239 17001
  # echo '(NumberNode' $i ')' | nc 10.0.3.239 17001
  # echo '(NumberNode 42)' | nc localhost 17001
echo '(ConceptNode "fooo ' $i $$ ' you too")' | nc localhost 17001 >> /dev/null

done

run 10 copies of above.
--- no leak   ... and no crash...  so this is very stable. wtf.

---------------------------------------------------------------
OK, so lets try the full pipeline.
but without updates

Whoops. Its blowing up

((gc-time-taken . 8772615322) (heap-size . 820801536) (heap-free-size . 90624000)
(heap-total-allocated . 6508583904) (heap-allocated-since-gc . 84464688)
(protected-objects . 313) (gc-times . 210))

((gc-time-taken . 8772615322) (heap-size . 1179750400) (heap-free-size . 27713536)
(heap-total-allocated . 16069320928) (heap-allocated-since-gc . 339494096)
(protected-objects . 313) (gc-times . 255))


what if we just do one article over and over?
./ss-one.sh yue beta-pages/A-Z/Zyu4 localhost 17006

It blows up.

what if we do one sentence over and over?
(observe-text "係 拉 丁 字 母 同 阿 剌 伯 數 字 串 字")

run it once, goes from (heap-size . 5963776)  to (heap-size . 20996096)
run 10 times: (heap-size . 28332032) 
It still blows up....

without bang.sh

(define (lo)
(define cnt 0)
(define start (- (current-time) 0.1))
(define (mke) 
	(if (eq? 0 (modulo cnt 20))
		(begin (display "rate=")
		(display (/ cnt (- (current-time) start))) (newline)
	))
	(set! cnt (+ cnt 1))
	(observe-text "係 拉 丁 字 母 同 阿 剌 伯 數 字 串 字")
)

(define (aloo) (mke) (aloo))
(aloo)
)

Above is .. wow its stable :
(heap-size . 21184512) (gc-times . 70)
(heap-size . 40243200) (gc-times . 242)
(heap-size . 40243200) (gc-times . 1458)  14:19.43 cpu
(heap-size . 40243200) (gc-times . 2554)  23:48.49 guile 

ssooo .. its something thread-related.  But just having netcat did not do the
trick. ... using java on one thread doesn't trigger it.  Using observe-text
does not trigger it. (ie. relex-parse, etc from one thread.)

do we have zombie threads?

(define x (call-with-new-thread (lambda () (observe-text " 係 拉 丁 字 母 同 阿 剌
伯 數 字 串 字"))))

(define (th)
(define cnt 0)
(define start (- (current-time) 0.1))
(define (thu v) (call-with-new-thread (lambda () 
	(observe-text " 係 拉 丁 字 母 同 阿 剌 伯 數 字 串 字"))))

(define lst (list 1 2 3 4 5 6 7 8 9 0))
(define lst (make-list 10 42))

(define (mke) 
	(define thl (map thu lst))
	(length (all-threads))
	(map join-thread thl)

	(set! cnt (+ cnt 1))
	(display "rate=")
	(display (/ cnt (- (current-time) start))) (newline)
)

(define (aloo) (mke) (aloo))
(aloo)
)

Hmmm ... above is blowing up!  but also .. its not actually threading,
(the atoms stuff is not happening out of order...)
either.   Oh, but it is blowing up ....

(heap-size . 87683072) (gc-times . 4295)
(heap-size . 104460288) (gc-times . 4513)
(heap-size . 255717376) (gc-times . 4884)

OK, full production system with the new guile:
(heap-size . 481013760) (gc-times . 301)
(heap-size . 755843072) (gc-times . 402) 11 minutes CPU
(heap-size . 797286400) (gc-times . 530) 15 mins cpu
(heap-size . 1285570560) (gc-times . 1713) 100 mins CPU
(heap-size . 1546678272) (gc-times . 2251) 140 mins CPU 

but is this really new? It was recompiled, but the version number is
wrong...

Again, full prduction: with guile -v
guile (GNU Guile) 2.1.5.19-7e9395 (8 Jan 2017)

(heap-size . 652918784) (gc-times . 233) ; about 8 mins CPU
(heap-size . 737722368) (gc-times . 339) ; 12 mins CPU
(heap-size . 1332973568) (gc-times . 1797) ; 120 mins CPU
(heap-size . 1441443840) (gc-times . 2221) ; 151 min CPU
(heap-size . 1521213440) (gc-times . 2441) ; 168 min cpu
(heap-size . 1595101184) (gc-times . 3061) ; 218 min cpu
(heap-size . 1726119936) (gc-times . 3292) ; 237 min
(heap-size . 1960865792) (gc-times . 6698) ; 510 minn
(heap-size . 1960865792) (gc-times . 10383) ; 805 min
(heap-size . 2931556352) (gc-times . 14211) ; 1199 min
(heap-size . 3302985728) (gc-times . 23278) ; 2186

 
Much improved: an earlier result was:
(heap-size . 4601581568) (gc-times . 485) ; almost 5GB!



===========================================

Non-openccog test case showing problem: bug 
https://debbugs.gnu.org/cgi/bugreport.cgi?bug=25386

(define junk 0)
(define halt #f)

(define (wtf-thr)
	(define start (- (current-time) 0.1))

	; Create thread that does junk and exits.  Yes, the increment
	; of `junk` is not protected, and its racey, but so what.
	(define (mkthr v) (call-with-new-thread (lambda () (set! junk (+ junk 1)))))

	; thread arguments
	(define thrarg (make-list 10 0))

	(define cnt 0)
	(define (mke) 
		; Create a limited number of threads
		(define thr-list (map mkthr thrarg))
		; (display (length (all-threads)))
		(map join-thread thr-list)

		; Some handy debug printing.
		(set! cnt (+ cnt 1))
		(if (eq? 0 (modulo cnt 500))
			(begin
				(display "rate=")
				(display (/ cnt (- (current-time) start))) (newline)
            (display "num threads=")
            (display (length (all-threads))) (newline)
            (display (gc-stats)) (newline) (newline)
			)))

	; tail recursive infinite loop.
	(define (aloop) (mke) (if (not halt) (aloop)))

	; while forever.
	(aloop)
)

(call-with-new-thread wtf-thr)
(set! halt #t)

Gahh seg-faults too

Thread 1 "guile" received signal SIGSEGV, Segmentation fault.
thread_mark (addr=0x55556a3f9e00, mark_stack_ptr=<optimized out>, 
    mark_stack_limit=0x7fffffffd350, env=<optimized out>)
    at ../../libguile/threads.c:111
warning: Source file is more recent than executable.
111	/* No threads; we can just use GC_stackbottom.  */
(gdb) bt
#0  thread_mark (addr=0x55556a3f9e00, mark_stack_ptr=<optimized out>, 
    mark_stack_limit=0x7fffffffd350, env=<optimized out>)
    at ../../libguile/threads.c:111

bug-guile@gnu.org 

https://debbugs.gnu.org/cgi/bugreport.cgi?bug=25386

----------------------------------------------------


(heap-size . 5939200)  (gc-times . 70)
(heap-size . 45510656) (gc-times . 147)
(heap-size . 399896576) (gc-times . 1018)

(hash-map->list cons (module-obarray (current-module)))

(heap-size . 183734272)  with gc inside the thread ... (gc-times . 402007)
(heap-size . 183734272) (gc-times . 976989)
(heap-size . 183734272) (gc-times . 1869962)
(heap-size . 183734272) (gc-times . 8526663)

stochastic gc: 
(heap-size . 369917952) (gc-times . 40387)
(heap-size . 428638208) (gc-times . 511116)
(heap-size . 428638208) (gc-times . 1218770)
(heap-size . 428638208) (gc-times . 6515758)

every-17th gc:
(heap-size . 1875902464) (gc-times . 290105)
(heap-size . 2068840448) (gc-times . 2605562) -- 44325000 threads

every 10th-gc in main loop, not in thread:
(heap-size . 544063488) (gc-times . 113)
(heap-size . 5151375360) (gc-times . 1113)
(heap-size . 8322269184) (gc-times . 2113)
Too many heap sections: Increase MAXHINCR or MAX_HEAP_SECTS

gc must be done at thread-exit, for this plan to work!

size=120MB+90MB * n

(define mtx (make-mutex))

   (define (mkthr v) (call-with-new-thread (lambda ()
                (lock-mutex mtx)
                (if (eq? 0 (modulo junk 17)) (gc))
                (set! junk (+ junk 1))
                (unlock-mutex mtx)
                )))


--------
OK new guile-2.2 doesn't blow up any more:

(heap-size . 7921664) (gc-times . 40)
(heap-size . 14344192) (gc-times . 953)
(heap-size . 14344192) (gc-times . 5219)  ; after 4 minutes CPU
(heap-size . 26419200) (gc-times . 64975) ; after 77 minutes CPU
(heap-size . 26419200) (gc-times . 133346) ; after 154 mins CPU
(heap-size . 26419200) (gc-times . 170083) ; after 192 mins CPU
(heap-size . 26419200) (gc-times . 249102) ; after 283 mins cpu
(heap-size . 26419200) (gc-times . 420031) ; after 468 min cpu
(heap-size . 26419200) (gc-times . 557039) ; after 804 mins CPU

alt version: 510 threads:
(heap-size . 10604544) (gc-times . 32)
(heap-size . 19505152) (gc-times . 484)
(heap-size . 35926016) (gc-times . 1761)
(heap-size . 48238592) (gc-times . 4217)  ; after 8 minutes cpu time
(heap-size . 48238592) (gc-times . 47902) ; after 76 mins CPU
(heap-size . 48238592) (gc-times . 73063) ; after 114 mins CPU
(heap-size . 65540096) (gc-times . 128094) ; after 209 mins cpu
(heap-size . 65540096) (gc-times . 248321) ; after 399 mins
(heap-size . 65540096) (gc-times . 344197) ; after 546 min

dffe495d0de1466f62a91a6d74cc0f388e0f4f3f
* libguile/threads.c (on_thread_exit): Lessen excess retention.
12eb7b8256f579fab60ebe0b38eb8788c1276eb8

scm_i_vm_free_stack 

=================================================================
Also 25387

https://debbugs.gnu.org/cgi/bugreport.cgi?bug=25387



===================================================================

(make-dynamic-state (current-dynamic-state))

(define (ds)
	(define cnt 0)
	(define start (- (current-time) 0.1))

	(define (mke) 
		(define x (make-dynamic-state (current-dynamic-state)))
	
		(set! cnt (+ cnt 1))
		(if (eq? 0 (modulo cnt 1000000))
			(begin
				(display "iter=") (display cnt) (newline)
				(display "rate=")
				(display (/ cnt (- (current-time) start))) (newline)
			)))

	(define (aloo) (mke) (aloo))
	(aloo)
)

Above looks just fine.


(count-all)
(cog-report-counts)
(cog-prt-atomspace)
(length (all-threads))
(gc-stats)

====================================================================
Bug -- split needs to put whitespace around parent, before/after commas,
etc. and begin-end quotes  FIXED

====================================================================
Bugg- the utf8 is fucked up.   Fixed. Its a guile-2.1.5 regression
its ok in the containers ... select * from atoms where type=110;
(cog-get-atoms 'WordInstanceNode)

but guile-2.2 fucks up. 
(string-append "a" "係" "c") is OK.
(Concept "係") is broken
scm_c_eval_string
scm_print_state
scm_puts now does scm_c_put_latin1_chars fuuuuuck,.

scm_lfwrite (s, strlen (s), port); --- again with latin1
scm_c_put_string
arggg
bug-guile@gnu.org  --  bug#25397:
https://debbugs.gnu.org/cgi/bugreport.cgi?bug=25387  
GUILE_VERSION_MINOR 1


====================================================================

call-with-new-thread
threads.c

  data = scm_gc_typed_calloc (launch_data);
  err = scm_i_pthread_create (&id, NULL, launch_thread, data);


scm_i_pthread_detach (scm_i_pthread_self ());
pthread-threads.h:#define scm_i_pthread_detach                pthread_detach
#define scm_i_pthread_self                  pthread_self


join_thread_var  libguile/threads.x  uh no 


(with-continuation-barrier
(set! (thread-join-data thread) (cons cv mutex))

scm_i_with_guile calls ...
	GC_call_with_stack_base  which is from boehm
	calls with_guile
		calls scm_i_init_thread_for_guile calls scm_i_init_guile
		scm_c_with_continuation_barrier

scm_current_dynamic_state ()   -- save_dynamic_state  ? maybe not freed?

what is in the currrent dynamic state?

everything looks kosher.  best guess: copy of dyanmic state is not being gc'ed.
SCM_USE_PTHREAD_THREADS ?? defined ?? yes.
build/libguile/scmconfig.h:#define SCM_USE_PTHREAD_THREADS 1 

GC_register_my_thread

on_thread_exit ??? thread_count--; seems to be called because throead count 
is correct ... who sets scm_i_thread_key ? .. guile init does.


---------------------------------------------------------------
Ongoing failure:
If I gc after every thread, then hit this:

guile: hashtab.c:137: vacuum_weak_hash_table: Assertion `removed <= len'
failed.
Aborted

2x... once after a minute
3x ...

try 2.0.13
autoconf flex gettext libunistring-dev libffi-dev texinfo

apt-get purge guile-2.0 guile-2.0-libs

---------------------------------------------------------------
Bug --- java fucks up like this:
above: java is runnning at 900% so its getting stuff in paralel.
It seems to be responding slowly, though ... and guile is not running
at high cpu .. its under 100% wtf... ah haha -- java is spinning 
on socket wait in some way...

Its messed up. Java is buggy.
------------------------------------------------------------------

Bug --- java always gives back exactly the same ... is the rand
num generator being reset each time??? I think it is, for
reproducibility?  No .. it was a bug. Fixed. pull req #471 in LG

for morphemes, anysplit.c always sets seed=0 every call.


anysplit.c:
rng_uniform 
sample_point
use_sampling 

api.c:				(rand_r(&sent->rand_state) %
parse_options_set_repeatable_rand

struct anysplit_params * anysplit;
 set by 

duuuude wtf 0 3b23e1b0 240 st=1840299789
duuuude wtf 1 78520aa1 33 st=-895367152
duuuude wtf 2 6372c222 322 st=1780636463
duuuude wtf 3 5c322e38 312 st=-231201766
duuuude wtf 4 303c3bea 146 st=-1008023999
duuuude wtf 5 2a463357 233 st=-480833580

      Linkage lkg = &sent->lnkages[in];
      Linkage_info *lifo = &lkg->lifo;
iindex
sentence_parse

63  70 248 277 -- birthday paradox



------------------------------------
LG:   FIXED, will be in version 5.3.14  -- LG pull req #470
any is ignoring the last word
no its not, its just not displaying it. so its a minor bug.
linkage_print_diagram

l->r pass removed 1
LEFT-WALL[1] 港[2] 區[2] 全[2] 國[2] 人[2] 

utf8_strlen


------------------------

BUGGGGGGGGGGG -- delete everything fails, cause  still counting in the other
threads!! Aieee! ... 

its also probably picking up the wrong sentence...

use .. parse-get-relex-outputs ? Uh no

(define foo
	(let ((mtx (make-mutex)))
		(lambda ()
			(display mtx) (newline)
			(format #t "duude is locked? ~A\n" (mutex-locked? mtx))
			(format #t "duude owner ~A\n" (mutex-owner mtx))
			(format #t "duude try ~A\n" (try-mutex mtx))
	))
)

(use-modules (opencog))

(AnchorNode "foo")
(ListLink (AnchorNode "foo") (Concept "a"))
(ListLink (AnchorNode "foo") (Concept "b"))
(ListLink (AnchorNode "foo") (Concept "c"))

(SentenceSequenceLink
(WordSequenceLink
(cog-extract-recursive sent)


Delete (SentenceSequenceLink (sent numbernode))
(use-modules (ice-9 receive) (srfi srfi-1) (opencog) (opencog
atom-types))

(use-modules (opencog) (opencog persist) (opencog persist-sql))
(use-modules (opencog nlp learn))
(sql-open "opencog_test" "opencog_tester" "cheese")
(observe-text "this is a foo")


psql -h localhost -U opencog_tester opencog_test


PACKAGE_VERSION
config.h:#define PACKAGE_VERSION "2.1.5.19-7e9395"

Seem to have 

libgc-dev

dpkg -l libgc1c2
Desired=Unknown/Install/Remove/Purge/Hold
|
Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend
|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)
||/ Name           Version      Architecture Description
+++-==============-============-============-=================================
ii  libgc1c2:amd64 1:7.4.2-8    amd64        conservative garbage
collector fo

---------------------------------------------------------------

        May lead to memory leak and poor performance.
GC Warning: Repeated allocation of very large block (appr. size
21573632):
        May lead to memory leak and poor performance.
GC Warning: Repeated allocation of very large block (appr. size
43147264):
        May lead to memory leak and poor performance.
GC Warning: Repeated allocation of very large block (appr. size
9056256):
        May lead to memory leak and poor performance.
GC Warning: Repeated allocation of very large block (appr. size
43147264):
        May lead to memory leak and poor performance.
GC Warning: Repeated allocation of very large block (appr. size
43147264):
        May lead to memory leak and poor performance.
GC Warning: Repeated allocation of very large block (appr. size
86290432):
        May lead to memory leak and poor performance.
GC Warning: Repeated allocation of very large block (appr. size
7438336):
        May lead to memory leak and poor performance.
GC Warning: Repeated allocation of very large block (appr. size
9588736):
        May lead to memory leak and poor performance.


In conclusion:

(gc-stats)
Entering scheme shell; use ^D or a single . on a line by itself to exit.
guile-yue> ((gc-time-taken . 7077498787602) (heap-size . 15487754240)
(heap-free-size . 3580190720) (heap-total-allocated . 900893846432)
(heap-allocated-since-gc . 6264284448) (protected-objects . 288)
(gc-times . 1059))

15.5GB in total, 3.6GB free

guile-yue> (gc)

guile-yue> (gc-stats)
((gc-time-taken . 7122988472428) (heap-size . 15487754240)
(heap-free-size . 8725934080) (heap-total-allocated . 900895104976)
(heap-allocated-since-gc . 1142496) (protected-objects . 288) (gc-times
. 1060))

Now its 8.7GB free, leaving 7GB in use.

guile-yue> (cog-report-counts)
((ListLink . 331150) (EvaluationLink . 331150) (AnchorNode . 1)
(WordNode . 10720) (LinkGrammarRelationshipNode . 1) (LgConnectorNode .
1) (LgConnMultiNode . 1) (LgConnDirNode . 2) (LgConnector . 4) (LgAnd .
4))

guile-yue> (count-all)
673034

So why is guile so splurgy?  This is just not that many atoms ... 
is bdwgc too conservative, somehow finding the TLB stuff?
what If I close out the TLB, does guile free it all?

1244:00 start of sql-close cpu time at start
1244:36 at stop -- so about 40 cpu-sconds, OK.

((gc-time-taken . 7128743570856) (heap-size . 15487754240)
(heap-free-size . 14163222528) (heap-total-allocated . 900991577328)
(heap-allocated-since-gc . 172640) (protected-objects . 288) (gc-times .
1061))

whoa -- that was it:
fre is now 14.2 out of 15.5GB so actual use is only 1.3GB 
... for 673K atoms, so about 2KBytes/atom which is still a lot, but 
... plausible.

So bdwgc was confused about the TLB... how? why? what about atom
creation that leaves around this handle-confusion?

before sql close:

ubuntu    4335  217 29.4 32768196 29150768 pts/6 Sl+ Jan11 1243:04 guile -l pair-count-yue.scm

after:
ubuntu    4335  210 28.9 32164608 28616384 pts/6 Sl+ Jan11 1244:45 guile -l pair-count-yue.scm

so no shrinkage directly....

(cog-map-type (lambda (ato) (cog-extract-recursive ato) #f) 'WordNode)
(gc)
.. fails to shrink the heap!

stop the cogserver ... (gc) still no shrinkage


void fn (char*, GC_word)

GC_set_warn_proc (fn)
https://www.hboehm.info/gc/gcinterface.html

GC_warn_proc GC_set_warn_proc(GC_warn_proc p)

libcord
libgc.so -> libgc.so.1.0.3

GC_current_warn_proc
GC_default_warn_proc
WARN


select count(*) from atoms;
1480054
1522104

        6: ??:0 GC_alloc_large()
        7: ??:0 GC_generic_malloc()
        8: ??:0 GC_core_malloc_atomic()
        9: strings.c:165        make_wide_stringbuf()
        10: strings.c:331       scm_i_make_wide_string()
        11: strings.c:1165      scm_string()
        12: vm-engine.c:763     vm_debug_engine()

SCM_STRING_LENGTH_HISTOGRAM
%stringbuf-hist

        6: ??:0 GC_alloc_large()
        7: ??:0 GC_generic_malloc()
        8: weak-table.c:362     allocate_entries()
        9: weak-table.c:432     is_acceptable_size_index()
        10: weak-table.c:677    weak_table_put_x()
        11: weak-table.c:893    scm_c_weak_table_put_x()
        12: read.c:423  maybe_annotate_source()
        13: gc.h:182    maybe_annotate_source()
        14: read.c:725  scm_read_string()
        15: read.c:476  scm_read_sexp()
        16: read.c:1814 read_inner_expression()
        17: read.c:476  scm_read_sexp()
        18: read.c:1814 read_inner_expression()
        19: read.c:1964 scm_read()
        20: vm-engine.c:763     vm_debug_engine()

scm_sys_string_dump
scm_sys_symbol_dump

scm_ilength

#define SCM_CHAR(x) ((scm_t_wchar)SCM_ITAG8_DATA(x))


Ah hah ... very long strings are ... very long strings
from java.


---------------------------------------------------------------


local_id_cache
add_id_to_cache
get_ids

maybe_create_id
id_create_cache

WordInstanceNode
LgLinkInstanceNode
  119 | WordInstanceNode
  120 | WordInstanceLink

  159 | LgLinkInstanceNode
  160 | LgLinkInstanceLink

how are these getting in the TLB???

SQLBackingStore::getLink(Handle& h) const
{

AtomSpace::fetch_atom
persist/guile/PersistSCM.cc

fetch-atom
fetch-incoming-set

is id deadlocking on the resolve? 

t1
delete
get table lock
rele table lock
  now t2 gets the table lock.
get tlb lock  << maybe halt here?
<<<< safe because nothing inside, so forward progress...
relese tlb lock
get table lock. << maybe halt here?


t2
add
table lock 1
tlb lock
do_res
table lock  2
<<< should wordwar prgress cause in ssame thread.

argh 201 theads
 201 -- do_poll_result SchemeEval.cc:655
 200 -- join from eval_loop GenericShell.cc:457
 197 -- getNodeHandle AtomTable.cc:255 
        owenr 20950 whih is 44
  44 -- TLB::removeAtom TLB.cc:143
        owner is 21423 which is 179
 179 -- AtomTable::getNodeHandl AtomTable.cc:255
        owner is 20950 which is 44

 so TLB can't get lock cause its held by 179 

but 179 is holding lock and calling do_res while holding the
atomspace lock. called by tlb::add atom

solutions(s): TLB must drop lock while doing do_res
atomtable must fully unwindws recursive lock


so who in 44 has it?
AtomTable.cc:841 is hwere we are ... 
called at line 762 with lock held at line 729  so we are at least
one-deep. maybe more??

std::unique_lock<std::recursive_mutex> 

    double frac = 100.0 * extra / ((double) all.size());
    printf("sql-stats: Examined %lu atoms in atomspace; %lu extra in TLB
(%f percent) \n", 
        all.size(), extra, frac);


    double frac = 100.0 * extra / ((double) all.size());
    printf("sql-stats: Found %lu atoms in atomspace; %lu extra in TLB
(%f percent) \n",
        all.size(), extra, frac);
frac = 100.0 * extra / ((double) _store->_tlbuf.size());
    printf("sql-stats: tlbuf size=%lu extra=%f percent\n",
_store->_tlbuf.size(), 
frac);
}




the __data.__owner member of the pthread_mutex_t 
print mutex.__data.__owner

---------------------------------------------------------------

(near-startup)
sql-stats: Atomspace holds 55484 atoms
sql-stats: tlbuf holds 19928 atoms
sql-stats: tlbuf holds 0 atoms not in atomspace (0.000000 pct)
sql-stats: tlbuf holds 2031 unremapped atoms (6.600585 pct)
sql-stats: 211017858 of 211020413 uuids unused (99.998789 pct)

Gaaaaackk .. this implies that 99.999 percent of calls to sql
are wasted ! well, actually not, since the cache should stop
the bad acting.

sql-stats: Atomspace holds 420064 atoms
sql-stats: tlbuf holds 154316 atoms
sql-stats: tlbuf holds 0 atoms not in atomspace (0.000000 pct)
sql-stats: tlbuf holds 16398 unremapped atoms (6.627275 pct)
sql-stats: 211339442 of 211467072 uuids unused (99.939645 pct)

sql-stats: Atomspace holds 86550 atoms
sql-stats: tlbuf holds 80674 atoms
sql-stats: tlbuf holds 0 atoms not in atomspace (0.000000 pct)
sql-stats: tlbuf holds 59344 unremapped atoms (72.948089 pct)
sql-stats: 212784068 of 212861833 uuids unused (99.963467 pct)


====================================================
clean start:

sql-stats: Atomspace holds 13949 atoms
sql-stats: tlbuf holds 5750 atoms
num_get_nodes=18537 num_got_nodes=235 (1.267735 pct)
num_get_links=56472 num_got_links=1116 (1.976201 pct)
num_get_insets=0 num_get_inatoms=0
num_node_inserts=6 num_node_updates=31444
num_link_inserts=256 num_link_updates=20732
Remove 21485 of 64000 (33.570312 pct) calls tlbzz=9219
sql-stats: tlbuf holds 0 atoms not in atomspace (0.000000 pct)
sql-stats: tlbuf holds 1484 unremapped atoms (20.694464 pct)
sql-stats: 213462841 of 213464601 uuids unused (99.999176 pct)

sql-stats: Atomspace holds 31687 atoms
sql-stats: tlbuf holds 23769 atoms
num_get_nodes=253402 num_got_nodes=1131 (0.446326 pct)
num_get_links=779439 num_got_links=14328 (1.838245 pct)
num_get_insets=0 num_get_inatoms=0
num_node_inserts=70 num_node_updates=517152
num_link_inserts=4190 num_link_updates=340938
sql-stats: tlbuf holds 0 atoms not in atomspace (0.000000 pct)
sql-stats: tlbuf holds 15624 unremapped atoms (66.088575 pct)
sql-stats: 213763992 of 213783890 uuids unused (99.990692 pct)

sql-stats: AtomSpace not set
sql-stats: Atomspace holds 45225 atoms
sql-stats: tlbuf holds 45225 atoms
num_get_nodes=646388 num_got_nodes=1763 (0.272746 pct)
num_get_links=1988905 num_got_links=33444 (1.681528 pct)
num_get_insets=0 num_get_inatoms=0
num_node_inserts=107 num_node_updates=1339311
num_link_inserts=9898 num_link_updates=883771
sql-stats: tlbuf holds 0 atoms not in atomspace (0.000000 pct)
sql-stats: tlbuf holds 46231 unremapped atoms (52.940099 pct)
sql-stats: 214585523 of 214645132 uuids unused (99.972229 pct)


sql-stats: Atomspace holds 446035 atoms
sql-stats: tlbuf holds 212056 atoms
num_get_nodes=1572865 num_got_nodes=2519 (0.160154 pct)
num_get_links=4838305 num_got_links=68870 (1.423432 pct)
num_get_insets=0 num_get_inatoms=0
num_node_inserts=215 num_node_updates=3172207
num_link_inserts=22422 num_link_updates=2094051
sql-stats: tlbuf holds 0 atoms not in atomspace (0.000000 pct)
sql-stats: tlbuf holds 72188 unremapped atoms (28.542847 pct)
sql-stats: 215438536 of 215580711 uuids unused (99.934050 pct)

after 10 hours:
sql-stats: AtomSpace not set
sql-stats: Atomspace holds 731146 atoms
sql-stats: tlbuf holds 725447 atoms
num_get_nodes=20215212 num_got_nodes=6866 (0.033965 pct)
num_get_links=61851573 num_got_links=404021 (0.653211 pct)
num_get_insets=0 num_get_inatoms=0
num_node_inserts=4251 num_node_updates=42211029
num_link_inserts=307398 num_link_updates=27844955
sql-stats: tlbuf holds 0 atoms not in atomspace (0.000000 pct)
sql-stats: tlbuf holds 411009 unremapped atoms (56.626772 pct)
sql-stats: 240293860 of 241016540 uuids unused (99.700153 pct)

20 gb resident 81 M atoms removed.

Finally:
---------
sql-stats: Atomspace holds 726040 atoms
sql-stats: tlbuf holds 726040 atoms
num_get_nodes=20356005 num_got_nodes=6882 (0.033808 pct)
num_get_links=62281852 num_got_links=405421 (0.650946 pct)
num_get_insets=0 num_get_inatoms=0
num_node_inserts=4264 num_node_updates=42510570
num_link_inserts=309468 num_link_updates=28042704
sql-stats: tlbuf holds 0 atoms not in atomspace (0.000000 pct)
sql-stats: tlbuf holds 412287 unremapped atoms (56.785714 pct)
sql-stats: 240482670 of 241208711 uuids unused (99.698999 pct)


((gc-time-taken . 7898668634177) (heap-size . 17208950784)
(heap-free-size . 9361924096) (heap-total-allocated . 996784769424)
(heap-allocated-since-gc . 1247263344) (protected-objects . 292)
(gc-times . 1068))

heap is 17.2GB!! free is 9.4GB so 7.8GB in use

((gc-time-taken . 7910648760945) (heap-size . 17208950784)
(heap-free-size . 12845494272) (heap-total-allocated . 996787132704)
(heap-allocated-since-gc . 331136) (protected-objects . 292) (gc-times .
1069))

heap is 17.2GB!! free  12.8GB so actually only 4.4GB is needed.

guile-yue> (sql-close)
guile-yue> (gc)
guile-yue> (gc-stats)
((gc-time-taken . 7912464056925) (heap-size . 17208950784)
(heap-free-size . 16106553344) (heap-total-allocated . 996792364160)
(heap-allocated-since-gc . 164096) (protected-objects . 292) (gc-times .
1070))

free is 16.1GB so somehow the TLB was chewing up 3.3GB holding
412287 unremapped atoms!?  How is this possible? Should I have run gc a
bunch more times? 
-------------------------------------------------------------
New API:
Very fast: in 3 minutes:
sql-stats: Atomspace holds 113815 atoms
sql-stats: tlbuf holds 1195 atoms
num_get_nodes=26378 num_got_nodes=26361 (99.935552 pct)
num_get_links=8813 num_got_links=8251 (93.623057 pct)
num_get_insets=0 num_get_inatoms=0
num_node_inserts=133 num_node_updates=52697
num_link_inserts=1062 num_link_updates=16550
sql-stats: tlbuf holds 0 atoms not in atomspace (0.000000 pct)
sql-stats: tlbuf holds 0 unremapped atoms (0.000000 pct)
sql-stats: 0 of 1196 uuids unused (0.000000 pct)



wtf...

(cog-report-counts)
((NumberNode . 46505) (ListLink . 163927) (EvaluationLink . 215741)
(AnchorNode . 1) (WordNode . 5199) (ReferenceLink . 99275) (SentenceNode
. 55) (ParseNode . 837) (ParseLink . 835) (WordInstanceNode . 47312)
(WordInstanceLink . 47437) (WordSequenceLink . 47464)
(SentenceSequenceLink . 55) (LinkGrammarRelationshipNode . 1)
(LgConnectorNode . 1) (LgConnMultiNode . 1) (LgConnDirNode . 2)
(LgConnector . 4) (LgAnd . 4) (LgWordCset . 46306) (LgLinkInstanceNode .
52608) (LgLinkInstanceLink . 52715))


Runnning
sql-stats: Atomspace holds 687522 atoms
sql-stats: tlbuf holds 684142 atoms
num_get_nodes=39921257 num_got_nodes=40050951 (100.324875 pct)
num_get_links=13354387 num_got_links=13011199 (97.430148 pct)
num_get_insets=0 num_get_inatoms=0
num_node_inserts=10662 num_node_updates=80083214
num_link_inserts=673480 num_link_updates=26027646
sql-stats: tlbuf holds 0 atoms not in atomspace (0.000000 pct)
sql-stats: tlbuf holds 0 unremapped atoms (0.000000 pct)
sql-stats: 0 of 684143 uuids unused (0.000000 pct)

(gc-stats)
((gc-time-taken . 49802336967563) (heap-size . 14738780160)
(heap-free-size . 9885679616) (heap-total-allocated . 947281529744)
(heap-allocated-since-gc . 1685837392) (protected-objects . 352)
(gc-times . 1242))

So while running: 14.7GB heap, 9.9GB free

guile-yue> (cog-report-counts)
((NumberNode . 737) (ListLink . 337776) (EvaluationLink . 338599)
(AnchorNode . 1) (WordNode . 10670) (ReferenceLink . 1557) (SentenceNode
. 1) (ParseNode . 16) (ParseLink . 16) (WordInstanceNode . 736)
(WordInstanceLink . 736) (WordSequenceLink . 736) (SentenceSequenceLink
. 1) (LinkGrammarRelationshipNode . 1) (LgConnectorNode . 1)
(LgConnMultiNode . 1) (LgConnDirNode . 2) (LgConnector . 4) (LgAnd . 4)
(LgWordCset . 720) (LgLinkInstanceNode . 821) (LgLinkInstanceLink .
821))

while idle:
(cog-report-counts)
((ListLink . 339276) (EvaluationLink . 339276) (AnchorNode . 1)
(WordNode . 10750) (LinkGrammarRelationshipNode . 1) (LgConnectorNode .
1) (LgConnMultiNode . 1) (LgConnDirNode . 2) (LgConnector . 4) (LgAnd .
4))
So the cruuft goes away.

((gc-time-taken . 49831001288560) (heap-size . 14738780160)
(heap-free-size . 5885931520) (heap-total-allocated . 956146319472)
(heap-allocated-since-gc . 4515746160) (protected-objects . 296)
(gc-times . 1243))

Heap:free: 5.9GB wow -- lots smaller than while runing.
Because 4.5GB alloced since last gc
(heap-free-size . 9419513856)
(heap-free-size . 13306900480)
(heap-free-size . 13710024704) 
(heap-free-size . 13740257280)  wow
of
(heap-size . 14738780160) 14.7 so only 1 GB needed.




ten-word-java: 289105 bytes 2m18 backlog
20-word java: 550294 bytes 3m12.772s
40-word hava: 1101459 bytes: 3m15 delay


ignoreType is not being used

 Wow .. the remove is completely un-needed!  DONE

The "Loaded 370000 atoms" not needed at all, if not bulk-loading. DONE

this dead-locks the shell:
(observe-test "商 餘 質 數 分 解 質 數 定 理 相 對 質 數")
ERROR: In procedure apply-smob/1:
ERROR: Throw to key `decoding-error' with args `("scm_from_utf8_stringn"
"input locale conversion error" 29 #vu8(40 111 98 115 101 114 118 101 45
116 101 115 116 32 34 229 149 134 32 233 164 152 32 232 179 170 32 230
149 184 32 229 136 134 32 232 167 163 32 232 179 170 32 230 149 184 32
229 174 255 237 255 253 6 10))'.

ERROR: In procedure fetch-atom: Earlier version of atom has mis-matched
UUID! (/home/ubuntu/src/atomspace/opencog/atomspaceutils/TLB.cc:85)


---------------------------------------------------------------
-- fix TLB tables in sql -  underway
    (deadlock) DONE

-- fix sennas bug.  DONE
-- publish new LG DONE
---------------------------------------------------------------

The fetch not needed if in the atomspace already. Well,
then don't fetch it!

There is no TV invalidation mechanism...
---------------------------------------------------------------
-- fetch not requied, unless updating the TV ... !!
   (or getting the tv...
-- fix pgsql variant .. maybe
-- update all lxc's.

=======================================================================
20 Jan 2017 Friday
OK, all bugs above fixed, reinstalled the latest LG in yue,
erase all tables, start from scratch. At 4PM exactly, wall-clock time
to the second.

at start
$ find beta-pages |wc          49193   52687 1489227
$ find submitted-articles |wc     24      24     629

-------

After 40 minutes:
select count(*) from atoms;   111632
Java/do-count: 1064 sentences  
find submitted-articles |wc      205

so, rate: 4.5 articles/minute, 5.9 sentences/article.
rate: 26.6 sents/minute
projected finish: 182 hours === 7.5 days

(do-count "report-stuff") gives alternate sentence count...


------

After 4.000 hours:
select count(*) from atoms;    454240
Java: cnt=6533  but 6610 from do-count !! wtf.
$ find submitted-articles |wc 919
38.9M node insert/updates   7164 total nodes!?
12.99 link insert/updates   447516 total links!?
== 51946920 total stores, so that cross-checks OK
total number of atoms also checks out (skew for measurement delay) OK

so, rate: 3.73 articles/minute, 7.4 sents/article
rate: 27.5 sents/minute
projected finish: 220 hours = 9.1 days

So the article-rate is bouncing around, but sentences/minute holds
steady.  Numbers are checking out.

-------

After 8.00 hours:
select count(*) from atoms;  666606
Java: cnt=10787 but  do-count says cnt=11464
$ find submitted-articles |wc 1634
66.1M node updates
22.0M link updates

So...
rate: 1610 / 8 hours = 201 articles/hour, 3.35 articles/minute
rate: 11464 / 480 min = 23.9 sents/min

22 minutes downtime for system upgrade....


4 concurrent writers:
after 15 mins: 
write items=417737 drains=2532 fill_fraction=164.983017 concurrency=51.921801

after 20 mins cpu:
write items=616070 drains=3826 fill_fraction=161.021955 concurrency=53.232358


12 concurrent writers:
after 15 mins
write items=372257 drains=1805 fill_fraction=206.236565 concurrency=53.760111

after 20 mins:
write items=539921 drains=2802 fill_fraction=192.691292 concurrency=54.867595

... doesn't improve concurrency, and seems slower for total CPU, but
that may be fucked up java. ... XXX see below: because there were only
6 connections to postgres, so really of the 12 writers, 7 were blocked.
(assumiong one reader thread, or more...)


New code, where no atom get: (and 12 writer threads)

write items=21516264 drains=167609 fill_fraction=128.371770 concurrency=4.759196
avg drain time=0.345310 seconds; longest drain time=80.337000

New code, 12 writers, and C impl of count-increment:
write items=7817004 drains=61061 fill_fraction=128.019587 concurrency=3.714679
avg drain time=0.517914 seconds; longest drain time=29.733000


New code, 4 writers, and C impl of count-increment:
drains=7186 fill_fraction=136.883245 concurrency=3.445728
drains=25794 fill_fraction=124.202528 concurrency=3.613825
avg drain time=0.440724 seconds; longest drain time=5.136000

4 writers is not obvious worse and seems better than 12.

Ohh .. well, turns out there were only 6 odbc connections
available to work with.

--------------------------------------------------
21 January -- saturday -- start from scratch, again.

start at exactly 15:00

after 15 mins:
select count(*) from atoms; 66221
find submitted* |wc  127

sql-stats: total loads = 296 total stores = 4379768 ratio=14796.513514

num_get_nodes=4246 num_got_nodes=296 (6.971267 pct)
num_get_links=61974 num_got_links=0 (0.000000 pct)
num_get_insets=0 num_get_inatoms=0 ratio=-nan
num_node_inserts=2123 num_node_updates=3282677 ratio=1546.244465
num_link_inserts=61974 num_link_updates=1033002 ratio=16.668313
total stores for node=3284800 link=1094976 ratio=2.999883

write items=2189854 flushes=0 flush_ratio=inf
drains=17804 fill_fraction=122.997866 concurrency=3.866659
avg drain time=0.418640 seconds; longest drain time=4.090000

(monitor-rate "foo")

------------
18:15 -- 3hrs 15 mins later:
find submitted* |wc gives 1025 so 
exactly 1000 articles in 195 minutes = 5.12 articles per minute

select count(*) from atoms; 482295
total loads = 803 total stores = 55843525 
num_node_inserts=7427 num_node_updates=41875213 ratio=5638.240609
num_link_inserts=472298 num_link_updates=13488591 ratio=28.559492
total stores for node=41882640 link=13960889 ratio=2.999998

write items=27921766 flushes=0 flush_ratio=inf
drains=234012 fill_fraction=119.317667 concurrency=2.665735
avg drain time=0.348755 seconds; longest drain time=6.107000

why is write-items=27.9M but total stores=55.8M ?

write-items is exactly half of total stores ...
select sum(stv_count) from atoms; gives 28995086 shortly later.

they're close ... so write-items actually matches word-counting...
so we are double-storing somehow...

-------------------------------------------------
on shutdown, at 22:30 --
select sum(stv_count) from atoms; 62921108
select count(*) from atoms; 861867

find submitted* |wc 2314  

total stores = 125995216
write items=62997608

write items=62997608 flushes=0 flush_ratio=inf
drains=532502 fill_fraction=118.304923 concurrency=2.559669
avg drain time=0.344836 seconds; longest drain time=6.107000

Rearrange; total stores still running at 2x write-items.

But ... 2 links, 3 nodes:
  Eval link --
     Pred node
     List link
        left node
        right node

so the list link is never explicitly stored.  which leaves 1 link, 3
nodes being explicit i.e. 4 explicit stores (for 5 atoms)
is write-items counting only the links? that would be only two, in tat
case...  but the write items are counted in the queue.



--------------------------------------------

Bugs:
if there is a store in the queue, and there is is a get for something
in the queue, then the get will get stale data, and then try to write
back more stale data, ad infinitum... causing the counts to be bad.

well, its up to user to use the barrier, which should now work.

 So .. need mechanism to fetch locally, until fully retired!
Better yet, in scheme, just don't .. don't what? 
don't fetch, unless stv is the default stv ...!

-----------------------------------------------
23 Jan 2017:
------------
Holy cow -- postgres is sooo much faster!!
check this out:

after just a few minutes:

write items=94794 flushes=0 flush_ratio=inf
drains=70 fill_fraction=1354.200000 concurrency=4.385714
avg drain time=0.065023 seconds; longest drain time=0.623000


fill fraction used to be only about 150, before, and average drain time
was something like 0.3 seconds... this is a whole new ballgame!

after 1/2 hour wall clock
write items=1462482 flushes=0 flush_ratio=inf
drains=1830 fill_fraction=799.170492 concurrency=5.049180
avg drain time=0.080646 seconds; longest drain time=1.829000

after 100 minutes
write items=4580980 flushes=0 flush_ratio=inf
drains=5394 fill_fraction=849.273267 concurrency=4.693919
avg drain time=0.118629 seconds; longest drain time=70.343000

after 7 hours
write items=18375732 flushes=0 flush_ratio=inf
drains=21386 fill_fraction=859.241186 concurrency=4.406621
avg drain time=0.084344 seconds; longest drain time=70.343000

after 13 hours:
write items=32066762 flushes=0 flush_ratio=inf
drains=37044 fill_fraction=865.639834 concurrency=4.370316
avg drain time=0.077263 seconds; longest drain time=70.343000

after 24 hours:
write items=56233665 flushes=0 flush_ratio=inf
drains=67199 fill_fraction=836.822944 concurrency=4.378875
avg drain time=0.072986 seconds; longest drain time=70.343000

So this looks to be stable.
after 3 days:
write items=199535356 flushes=0 flush_ratio=inf
drains=310946 fill_fraction=641.704206 concurrency=5.116091
avg drain time=0.087041 seconds; longest drain time=70.343000

so its ogt a little worse... but atomspace is much much bigger, now.


---------------
and also: java is fixed: the magic fix was:
-- shut everything down every 500 sentences,
-- run gc five times in a row,
-- restart everything. 
This unclogs the kitchen sink. -- java now stays up for 4+ hours,
without tanking.

progress:
as of 23 jan 01:50 AM have find submitted* |wc being 8198
              2:15 AM 8299  and (monitor-rate "foo") cnt=2080 rate=0.740
                   i.e. 0.74 sents/sec = 44 sents/minute!
                     that's nearly double the previous rate.
              9:15 AM 10711 -> 10711-8299=2412/(7*60+25) = 5.4 articles/min
                            -> 325 articles/hour = 7805 articles/day
                       cnt=18200 rate=0.65566 -> 39 sentences/minute
              10:47 AM cnt=21430 rate=0.640945
              12:43 PM cnt=27054 rate=0.668858
              15:04 PM cnt=33874 rate=0.692012
      24 jan  01:34 AM cnt=57497 rate=0.663148
                       18160 articles->(18160-8198)/24 = 415 articles/hour
                       10K articles/day
      25 Jan  12:04 PM cnt=134017 rate=0.63543
                       27967 articles->(27967-8198)/59 = 335 articles/hour
      26 Jan  15:26 PM cnt=196794 rate=0.63602
                       35736 articles


-----------------
CentOS 5

psql opencog_test -U opencog_tester -W -h localhost

PGPORT=5433
PGDATA=/home/linas/postgres/var/lib/pgsql/data
PGLOG=/tmp/pgstartup.log

postgres -c "/usr/bin/postmaster -p '$PGPORT' -D '$PGDATA' &" >> "$PGLOG" 2>&1 
postgres -c "/usr/bin/postmaster -p 5432 -D /home/linas/postgres/var/lib/pgsq/data &" >> /home/linas/postgres/tmp/pgstartup.log 2>&1 

alt: chroot /home/linas/postgres; /etc/init.d/postgresql start
nooo dudn't work.

just this:
/home/linas/postgres/etc/init.d/postgresql start

/usr/bin/postmaster -p 5432 -D /home/linas/postgres/var/lib/pgsql/data &
>> /home/linas/postgres/tmp/pgstartup.log 2>&1 

psql opencog_test -U opencog_tester -W -h localhost
Nooooo
look at .odbc.ini

psql test-persist -p 6543

CREATE TABLE Spaces (
    space  BIGINT PRIMARY KEY,
    parent BIGINT
);  
INSERT INTO Spaces VALUES (0,0); -- no space defined; raw atoms.
INSERT INTO Spaces VALUES (1,1); -- default root

ALTER TABLE atoms ADD COLUMN space INT REFERENCES spaces(space);

select count(*) from atoms;
select sum(stv_count) from atoms;


all of these are only the ANY type:

fr_pairs -- learn-fr -- 11161199 (11M) atoms, 6842302577 (6.8G) count
                         ANY-count = 1200368900 = 1.2GB relations

lt_pairs -- learn-lt --  9798103 (10M) atoms, 2873920459 (2.8G) count
                         ANY-count = 647356630 = 0.65G relations

pl_pairs -- learn-pl -- 16192701 (16M) atoms, 4331274070 (4.3G) count
                         ANY-count = 1061898400 = 1G relations

simple_pairs -- learn-simple -- empty
pair_data -- 532 atoms, junk

frwiki-20131220-pages-articles
   find alpha-pages |wc -- 1452754 - 1.4M
   find beta-pages |wc -- 1436278 
   find submitted-articles |wc -- 16505

plwiki-20131218-pages-articles
   find alpha-pages | wc -- 1007645 -- 1.0M
   find submitted-articles |wc -- 107190

ltwiki-20131216-pages-articles
   find alpha-pages | wc -- 161488 -- 161K
   submitted-articles |wc -- 18108

fr_ady : mophology pairs.
.odbc.ini -> fr-ady

relex is not spewing ady correctly -- FIXED

fr-ady on 17003, ady relex on 4446

Warning: Combinatorial explosion! nulls=1 cnt=2147483647
FIXED -- hacked on LG; works-ish, but slow for long sentences.

psql -p 6543 fr_ady
select type, name,stv_count from atoms where height=0;

Argh.
after a day: guile hung; but also, no articles moved from
split to submitted!

crash: string_set_add + 0x47
000000000003ad90 t string_set_add

  e0:	84 c9                	test   %cl,%cl
  e2:	0f 84 89 01 00 00    	je     271 <string_set_add+0x1b1>
  e8:	48 8b 36             	mov    (%rsi),%rsi
  eb:	49 89 f8             	mov    %rdi,%r8
  ee:	0f b6 d1             	movzbl %cl,%edx
  f1:	45 31 ed             	xor    %r13d,%r13d
  f4:	0f 1f 40 00          	nopl   0x0(%rax)
  f8:	41 c1 e5 08          	shl    $0x8,%r13d
  fc:	49 83 c0 01          	add    $0x1,%r8
 100:	41 8d 44 15 00       	lea    0x0(%r13,%rdx,1),%eax
 105:	31 d2                	xor    %edx,%edx
 107:	48 f7 f6             	div    %rsi

but RSI is zero

liblink-grammar.so.5+0x3b6b3]  int+0x3
000000000003b6b0 t is_capitalizable.isra.9


PrintWriter out -- done
outs  OutputStream  done
in_sock  Socket  -- done
send_sock Socket  ... is null

23:30: 2159 articles
23:43: 2535 articles : 276/13 minutes = 21 articles/min

23:48  2540 articles
23:59  2872 articles : 332 aritcles/ 11 mins = 30 articles/min! waa

00:45  3651 articles
select sum(stv_count) from atoms; 1375507899  == 1.38 G counts
select count(*) from atoms; 7146891 == 7.1M atoms

# C  [liblink-grammar.so.5+0x120d5]  print_flat_constituents+0xbd5
# C  [liblink-grammar.so.5+0x120d5]  print_flat_constituents+0xbd5

from 
C  [liblink-grammar.so.5+0x12a25]  linkage_print_constituent_tree+0x85

4180 + bd5 = 4d55
objdump -d -F -g -S

in build tree:
0000000000011500 t print_flat_constituents
00000000000120e0 t print_tree

in build tree so:


4ccd:
   1207f:   31 c9                   xor    %ecx,%ecx
   12081:   31 c0                   xor    %eax,%eax
   12083:   e8 78 2a 01 00          callq  24b00 <feature_enabled>
   12088:   48 85 c0                test   %rax,%rax
   1208b:   0f 85 1f ff ff ff       jne    11fb0
<print_flat_constituents+0xab0>
   12091:   eb d6                   jmp    12069
<print_flat_constituents+0xb69>
   12093:   48 89 c3                mov    %rax,%rbx
   12096:   48 8b 00                mov    (%rax),%rax
   12099:   48 8b b8 98 00 00 00    mov    0x98(%rax),%rdi
   120a0:   e8 9b 89 01 00          callq  2aa40 <post_process_new>
   120a5:   48 89 c7                mov    %rax,%rdi
   120a8:   48 89 bb 88 00 00 00    mov    %rdi,0x88(%rbx)
   120af:   e9 ff f7 ff ff          jmpq   118b3
<print_flat_constituents+0x3b3>
   120b4:   e8 47 3e ff ff          callq  5f00 <__stack_chk_fail@plt>
   120b9:   48 8d 3d b0 00 05 00    lea    0x500b0(%rip),%rdi        # 62170 <__func__.7560+0x8f0>
   120c0:   31 c0                   xor    %eax,%eax
   120c2:   e8 e9 3b ff ff          callq  5cb0 <prt_error@plt>
   120c7:   48 8d 3d ac bf 05 00    lea    0x5bfac(%rip),%rdi        # 6e07a <_ZTSN7Minisat6SolverE+0xca>
4d22:
   120ce:   31 c0                   xor    %eax,%eax
   120d0:   e8 db 3b ff ff          callq  5cb0 <prt_error@plt>
>>>>>>>>>>>>>>>>>>>> crash here.
   120d5:   0f 0b                   ud2
   120d7:   48 8d 3d 0a 00 05 00    lea    0x5000a(%rip),%rdi        # 620e8 <__func__.7560+0x868>
   120de:   eb e0                   jmp    120c0 <print_flat_constituents+0xbc0>

OK
00000000000120e0 <print_tree>:
   120e0:   48 85 d2                test   %rdx,%rdx
   120e3:   0f 84 ab 08 00 00       je     12994 <print_tree+0x8b4>
   120e9:   41 57                   push   %r15
   120eb:   41 56                   push   %r14
   120ed:   49 89 ff                mov    %rdi,%r15
   120f0:   41 55                   push   %r13

So: 

blank banshee
I just wasn't made for these times -- beach boys -- pet sounds

linkage_print_constituent_tree
getConstituentString
LinkGrammar.java -- wraps the C api w/static funcs
    public static native String getConstituentString();
LGService.java -- where the struture is restored
if (config.isStoreConstituentString())


finish
Java_org_linkgrammar_LinkGrammar_close(JNIEnv *env, jclass cls)
    public static native void close();

LGService.do_finalize()

allowSkippedWords
setAllowSkippedWords

linkgrammar_get_dict_version+0x0  <-- crash here twice ...
parser.parse(sentence);

parseSentence   159

parser.parse(sentence);

start again yue 30 Jan 22:19 
at 22:49 -- 488 articles/30 minutes = 16 articles/minute! -- 3x faster than before.
at 23:48 -- 796 articles in 90 minutes = 9 artciles/min
at 00:19 -- 926 articles in 120 mins = 7.7 articles/min
            4500 sents = 4.86 sents/article
            22908000 stored, stv total = 18315330
            stv/5 = 3.66M pairs or 814 pairs/sent(!)
at 11:55 -- 4275 articles in 816 mins = 5.24 articles/min - back to old rates.
            restart java, no noticable diference in rate: its same cpu/loadavg
restart, and load all. Before stopping:
            tlbuf holds 1381888 atoms Atomspace holds 1381901 atoms Hmm.

restart: explicit load: 1381888 atoms in 31 cpu-secs: 44.6K atoms/sec load speed.
at 12:13 -- restarted. Baseline: 4304 articles
at 18:13 -- 6094-4304 = 1790/6 hrs = 4.97 articles/min
at 00:26 -- 7547-6094 = 1453/373 mins = 3.90 articles/min
at 12:22 -- 12376-7547 = 4829/716 mins = 6.74 articles/min (!)
24-hour avg: 12376 - 4304 = 8072/1449min = 5.57 articles/min

1 Feb 2017:
change postgres shared_buffers = 24576MB  from 1GB previously.
also -- change java to 2GB from 1GB
restart at 12:31 no explicit load.
at 14:14 -- 13926 - 12376 = 1550/103min = 15.0 articles/min(!)

at 15:40 - 12:31 = 189 mins, have 
         guile=637:07 mins, or 637/189 = 3.37 load
         java = 50:25 = 50/189 = 0.267 load
         postgres = 10974 secs = 182.9 mins = 182.9/189 = 0.968 load

at 21:27  -- 17014 - 13926 = 3088 / 433 mins = 7.13 articles/min

at 21:30 - 12:31 = 539 mins
        guile = 1850:15 / 539 = 3.42 load
        java  =  148:04 / 539 = 0.274 load
        postgres = 519 / 539 = 0.963 load

2 Feb 2017 -- guile crashed! no prints no dump. 
restart at 12:05 -- 21174 articles
        at 12:43 -- 21411 articles = 411-174/38 = 237/38 = 6.2 artciles/min
        at 19:28 -- 23422 articles = 23422-21174/443 = 2248/443 = 5.07 arts/min
3 Feb   at 07:46 -- 26828 articles = 26828-23422/738 = 3406/738 = 4.62 arts/min
           11:45 -- 27691 articles = 27691-26828/239 = 863/239 = 3.61 arts/min

Hmm. the rate keeps dropping...

final stats for above:
sql-stats: total loads = 1228941 total stores = 286453870 ratio=233.090010
write items=57290774 flushes=0 flush_ratio=inf
drains=98324 fill_fraction=582.673345 concurrency=6.286054
avg drain time=0.109933 seconds; longest drain time=9.216000

scheme@(guile-user)> (gc-stats)
$9 = ((gc-time-taken . 19242586423) (heap-size . 5229101056) (heap-free-size .
5109686272) (heap-total-allocated . 3874090716576) (heap-allocated-since-gc . 509440)
(protected-objects . 301) (gc-times . 53424))

select sum(stv_count) from atoms; -- 801969742 -- 802M
select count(*) from atoms; -- 4786479 -- 4.8M


3 Feb 2017 -- restart. All-new atomspace, all-new link-grammar
      at 12:18PM -- 27691 articles 
      at 12:30 -- crash of guile, restart.
      at 14:11 -- 28246 articles, 28246-27691/100 = 555 / 100 = 5.5 arts/min
      at 15:47 -- 28772 articles, 28772-28246/96 = 526 / 96 = 5.48 articles/min
      at 20:03 -- 30166 articles, 30166-28772/256 = 1394/256 = 5.45 arts/min
4 Feb at 11:20 -- 35014 articles, 35014-30166/917 = 4848/917 = 5.29 artciles/min
5 Feb at 00:02 -- 38511 articles; there was accidental pause of system for hours.
      at 11:25 -- 43905 articles; 43905-38511/683 = 5394/683 = 7.90 arts/min whoa!
6 Feb completed -- 49194 articles.

sql-stats: total loads = 2013739 total stores = 741785040 ratio=368.362057
write items=148357008 flushes=0 flush_ratio=inf
drains=256330 fill_fraction=578.773487 concurrency=5.138489
avg drain time=0.100850 seconds; longest drain time=10.537000

select count(*) from atoms;           6927244 -- 6.9M  -- 6 Feb final
select sum(stv_count) from atoms;  1396889746 -- 1.40G -- 6 Feb final


cpu-ratio guile/java: 4846/425 = 11.4 at 11:20 4 Feb
                      6732/602 = 11.2 at 00:02 5 Feb
                      9001/786 = 11.5 at 11:30 5 Feb
                     12532/1127 = 11.1 final 6 Feb at completion

114022593 total stores in  1820 cpu-mins = 62.6K atoms/min = 1.04K sto/sec
292674070 total stores in  4846 cpu-mins = 60.4K atoms/min = 1.01K sto/sec
534084730 total stores in  8978 cpu-mins = 59.5K atoms/min = 991 stores/sec
741785040 total stores in 12532 cpu-mins = 59.2K atoms/min = 987 stores/sec

 vs cx1 (fr-ady):
 76688189 stores in  3325 cpu-mins = 23.1K stores/min = 384 stores/sec
193457228 stores in  6838 cpu-mins = 28.3K stores/min = 472 stores/sec
378934530 stores in 12396 cpu-mins = 30.6K stores/min = 509 stores/sec

cx1 has old, inefficient kernel and/or old-ineffcient postgres (and
crappy odbc)


postgres:
ps ax |grep postgres > x
cat  x |cut -f 4 > y


EPOCH='jan 1 1970'
sum=")"

for i in 00:03:34 00:00:35 00:12:34
do
  sum="$(date -u -d "$EPOCH $i" +%s) $sum"
done
echo "(+" $sum| guile

=====================================================================
French pairs

french pairs: start again: 22:36PM 30 Jan - find submitted* |wc 17053 
                           12:25PM  2 Feb - find submitted* |wc 24563
                           11:43AM  4 Feb - find submitted* |wc 25361
                           11:34AM  5 Feb - find submitted* |wc 25830
                           19:19PM 10 Feb - find submitted* |wc 27763
                           20:16PM 14 Feb - find submitted* |wc 29720

disk: 206447916 used 41097304 free
disk  206574808 used 40970412 free  24 hours later... about 100MB more
disk  206888724 used 40656496 free  12:25 2 Feb
disk  208585480 used 38959740 free  11:42 4 Feb ... 2.1GB more
disk  208897572 used 38647648 free  00:00AM 5 feb
disk  211829000 used 35716220 free  19:20 10 Feb
disk  213607532 used 33937688 free  20:16 14 Feb

select count(*) from atoms;         2090064 --   2.1M -- 12:25PM  2 Feb
select sum(stv_count) from atoms; 115251031 -- 115M   -- 12:25PM  2 Feb

select count(*) from atoms;          5676118 --    5.7M -- 11:19AM  4 Feb
select sum(stv_count) from atoms;  351323640 --  351M   -- 11:19AM  4 Feb

select count(*) from atoms;          7714679 --    7.7M -- 11:38AM  5 Feb
select sum(stv_count) from atoms;  502509756 --  503M   -- 11:38AM  5 Feb

select count(*) from atoms;         16945084 --   16.9M -- 19:21PM 10 Feb
select sum(stv_count) from atoms; 1289249056 -- 1.29G   -- 19:21PM 10 Feb

select count(*) from atoms;         23072988 --   23.1M -- 20:20PM 14 Feb
select sum(stv_count) from atoms; 1856669388 -- 1.86G   -- 20:20PM 14 Feb


guile/java ratio: 6781/683  = 9.93 -- 11:19AM  4 Feb
                  9401/1001 = 9.40 -- 00:00AM  5 Feb
                 12433/1304 = 9.53 -- 11:40AM  5 Feb
                 47250/4576 = 10.3 -- 19:23PM 10 Feb
                 22980/2340 = 9.82 -- 20:20PM 14 Feb

guile hangs:
cx1 - 30 jan hang after 4.4M stores 
      31 jan hang after 42M stores
       1 Feb hang after 33M stores -- 2000:26 cpu
       1 Feb hang after 6.9M stores
       2 Feb hang
       2 Feb hang after 20M stores -- 865:47 cpu


155 threads

155: pthread_cond_wait - multi-driver/SQLAtomStorage.cc:325

Ahhh ... too many open sockets, and one is deadlocked.

wait ... deadlocked in conn_pool.pop()
in SQLAtomStorage::get_conn() SQLAtomStorage.cc:325

so who is using all these conns?

154: ~GenericShell 152 150 148 .. 130 .. 127

153: same as 155 151 149 147 ... 131 .. 128

alternates like this till 131 or so

129: SchemeEval::do_poll_result SchemeEval.cc:655  86

90 76: nanosleep --SQLAtomStorage::storeAtom SQLAtomStorage.cc:754
    waiting to drain ... so its not draining ... why?

25: GC25: GC

24: get_conn, do_store_single --- this is the write-back handler.
    there are 8 of these .. through 17 

so .. the 8 busy writers are blocking readers, cause there are only 8
conns total ... 

works better if we double the pool...

no one seems to be waiting on postgres ... suggests that the 
we've lost track of the number items in the queue ...

15: console list
14: logger
13-2: gc
12

So, its idle ... and ... we've leaked:
currently in_drain=0 num_busy=0 queue_size=0
current conn_pool free=4 of 20


ahhh its due to throws, which kill the put_conns ...

[2017-02-03 05:44:02:785] [WARN] (34) The # of binded parameters < the #
of parameter markers;
Unrecognized key passed to SQLGetInfo30.

[2017-02-03 05:44:02:785] [WARN]    Query was: SELECT * FROM Atoms WHERE
type = 110 AND name = $ocp$?$ocp$ ;

[2017-02-03 05:44:02:785] [ERROR] Can't perform query rc=-1
(/home/linas/src/atomspace-git/opencog/persist/sql/multi-driver/odbcxx.cc:259)
   Stack Trace:

Query was: SELECT * FROM Atoms WHERE type = 110 AND name =
$ocp$?,!ANY-PUNCT$ocp$ ;

... need to try-catch these blocks.

SELECT * FROM Atoms WHERE type = 110 AND name = $ocp$?$ocp$ ;
Seems to be an ODBC issue ...

(34) The # of binded parameters < the # of parameter markers;
Unrecognized key passed to SQLGetInfo30.

SQLBindParameter


glurg. ODBC needs this: replace ? by &#63; what a clusterfuck

Also: 

[2017-02-08 08:16:43:154] [WARN] ODBC Driver: (1) ODBC escape convert
error

[2017-02-08 08:16:43:155] [WARN] ODCB Driver: Query was: SELECT * FROM
Atoms WHERE type = 110 AND name = $ocp${x$ocp$ ;

[2017-02-08 08:16:43:155] [ERROR] Can't perform query rc=-1
(/home/linas/src/atomspace-git/opencog/persist/sql/multi-driver/odbcxx.cc:340)




------------------
very late:
link-grammar: Info: Dictionary 'ady/4.0.dict': No locale definition -
"en_US.UTF-8" will be used.
link-grammar: Info: Dictionary 'ady/4.0.dict': No locale definition -
"en_US.UTF-8" will be used.
link-grammar: Error: Could not open dictionary "ady/4.0.dict"


restart not happen until connection... OK.
link-grammar not loaded until the next round!

re.setMaxParses

_is_in
dict=0x7f053c1bb0b0
dict=0x7f2e2c1f35a0
local-ptd=0x7f2e2c1f3550

checking for locale_t in locale.h... no
checking for locale_t in xlocale.h... no

__USE_GNU
       semant = new AlgorithmApplier(
         "relex.semalgpath", "relex-semantic.algs");

wordnet.configfile file_properties.xml

src/java/relex/morphy/MapMorphy.java:
src/java/relex/morphy/MorphyFactory.java:

               getJWNLConfigFileStream(
                     WORDNET_PROPERTY,
                     JWNL_FILE_PROPERTIES_XML,
                     JWNL_DIR_PROPERTIES_XML
               )

Info: hndlr=3 recv input: "- |3-1|25-23|20-25|25-17|25-11||95-76|couleur=gris}} - |3-0|28-26|25-19|25-23|||78-68}} - |3-1|25-21|25-21|13-25|25-12||88-79|couleur=gris}} - |3-1|21-25|33-31|40537|25-15||104-83}} - |3-2|25-23|22-25|25-22|17-25|17-15|106-110|couleur=gris}} - |3-0|25-19|25-13|25-23|||75-55}}"

Info: hndlr=8 recv input: "- |3-0|25-16|26-24|25-17|||76-57|couleur=gris}} - |3-1|25-22|23-25|25-20|25-20||98-87}} - |3-2|25-22|20-25|25-27|33-31|15-12|118-117|couleur=gris}} - |3-0|25-14|25-22|25-19|||75-55}} - |3-0|25-14|25-20|25-21|||75-55|couleur=gris}} - |3-0|26-24|25-18|33-31|||84-73}}"

then crash

"ISBN 0-380-72001-9.  http://books.google.be/books?id=FMsNAG-gresC&pg=PA144&lpg=PA144&dq=vlakfontein+Dixon+kemp&source=web&ots=8cB7anqlpV&sig=REOVNA8sQO8iTZhI-0_IHVdhySQ&hl=en&sa=X&oi=book_result&resnum=3&ct=result."


crash again:
C  [libc.so.6+0x7a97b]  unsigned long+0xa5b
C  [liblink-grammar.so.5+0x3dad4]  short+0x164
3dad4 - 164 = 3d970

000000000003d970 t separate_word.isra.12

if (not dict->affix_table ) jump pst anysplit
   3dab8:   74 1a                   je     3dad4 <separate_word.isra.12+0x164>
   3daba:   48 83 78 58 00          cmpq   $0x0,0x58(%rax)
if (not dict->affix_table->anysplit) jump past anysplit
   3dabf:   74 13                   je     3dad4 <separate_word.isra.12+0x164>
   3dac1:   48 8b b5 30 ff ff ff    mov    -0xd0(%rbp),%rsi  # arg2: unsplit_word
   3dac8:   48 8b bd 20 ff ff ff    mov    -0xe0(%rbp),%rdi  # arg1: sent
   3dacf:   e8 4c a9 fc ff          callq  8420 <anysplit>
   3dad4:   48 8b 95 70 ff ff ff    mov    -0x90(%rbp),%rdx  # arg3: word
crash here
RBP=0x00002b9ecaf2e450, RDX=0x0000000000000000

call convention arg 1 2 3 in RDI RSI RDX

looks like RBP is pointing into the stack... and 0x00002b9ecaf2e3c0 is
null ...

0x00002b9ecaf2e3a8:   00002b9eeef04f10 000000004bb2c580
0x00002b9ecaf2e3b8:   00002b9e00000000 0000000000000000
0x00002b9ecaf2e3c8:   0000000000000000 00002b9eec065490
0x00002b9ecaf2e3d8:   fffffffe00000026 00002b9ecaf2e310
0x00002b9ecaf2e3e8:   0000000000000001 00002b9e00737470

OK, this is fine, the crash is somewhere inside of anysplit.

unsplit word is.... at 0x00002b9ecaf2e450 - d0 = ...380 

0x00002b9ecaf2e380: 000000004bb2c960 -- same as contents to rbx



   3dadb:   48 8b b5 30 ff ff ff    mov    -0xd0(%rbp),%rsi  # arg2: unsplit_word
   3dae2:   48 8b bd 20 ff ff ff    mov    -0xe0(%rbp),%rdi # arg1: sent
   3dae9:   e8 a2 f8 ff ff          callq  3d390 <morpheme_split>
   3daee:   80 bd 1f ff ff ff 00    cmpb   $0x0,-0xe1(%rbp)
   3daf5:   89 c3                   mov    %eax,%ebx
   3daf7:   75 2e                   jne    3db27 <separate_word.isra.12+0x1b7>
   3daf9:   84 c0                   test   %al,%al

==================================
again
https://sourceware.org/bugzilla/show_bug.cgi?id=21104

Info: hndlr=1 sentence: "Chaussande (de) [http://gallica.bnf.fr/ark:/12148/bpt6k1120033/f177.image.r=], baron par bref pontifical de 1707, Comtat Venaissin, ANF-1969."
*** glibc detected *** java: free(): invalid pointer: 0x0000000059551940
***
======= Backtrace: =========
/lib64/libc.so.6[0x3e296714af]
/lib64/libc.so.6(cfree+0x4b)[0x3e296757ab]
/usr/local/lib/liblink-grammar.so.5[0x2b3a2392a7ce]
/usr/local/lib/liblink-grammar.so.5[0x2b3a2392b396]
/usr/local/lib/liblink-grammar.so.5(sentence_parse+0x99)[0x2b3a2392bb69]
/usr/local/lib/liblink-grammar-java.so.5.3.15(Java_org_linkgrammar_LinkGrammar_parse+0xf5)[0x2b3a236f8995]
[0x2b3a1690eeee]


#5  0x00002b3a2392a7ce in wordgraph_path_free (free_final_path=true, wp=0x59551860)
    at ../../link-grammar/api.c:937
#6  sane_linkage_morphism (sent=sent@entry=0x586bb130, lkg=lkg@entry=0x5877b850, 
    opts=opts@entry=0x586baef0) at ../../link-grammar/api.c:1021


(gdb) print twp
$1 = (Wordgraph_pathpos *) 0x59551890
(gdb) print *twp
$3 = {word = 0x587d7f40, same_word = 56, next_ok = 74, used = 149, path = 0x59551940}

(gdb) x/16g 0x59551940
0x59551940:	0x00000000587d6ef0	0x0000000000000000
0x59551950:	0x0000000000001270	0x0000000000000021
0x59551960:	0x000000005894f650	0x0000003e29954a68
0x59551970:	0x0000000000000020	0x0000000000000040
0x59551980:	0x00000000595516f0	0x000000005a5c82a0

Hmm everything looks OK, so what's the problem???

struct Wordgraph_pathpos_s
{
   Gword *word;      /* Position in the Wordgraph */
   /* Only for wordgraph_flatten(). */
   bool same_word;   /* Still the same word - issue an empty word */
   bool next_ok;     /* OK to proceed to the next Wordgraph word */
   bool used;        /* Debug - the word has been issued */
   /* Only for sane_morphism(). */
   const Gword **path; /* Linkage candidate wordgraph path */
};

wordgraph_pathpos_resize could take bigger jumps.


wordgraph_pathpos_len

len == len not counting the null.

e.g. n=1 insert = 0
memomve from 0 to 1 for 1 item

=========================================================
Arghh...
scheme@(guile-user)> GC Warning: Repeated allocation of very large block (appr. size
18894848):
        May lead to memory leak and poor performance.
*** Error in `guile': double free or corruption (out): 0x00000000623e6010 ***
======= Backtrace: =========
/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f3a6db117e5]
/lib/x86_64-linux-gnu/libc.so.6(+0x7fe0a)[0x7f3a6db19e0a]
/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f3a6db1d98c]
/usr/local/lib/libguile-2.2.so.0(scm_string_to_utf8+0xd7)[0x7f3a6e0ca067]
/usr/local/lib/libguile-2.2.so.0(scm_mkstrport+0x6b)[0x7f3a6e13d0ab]
/usr/local/lib/libguile-2.2.so.0(+0xbc5cd)[0x7f3a6e1465cd]
/usr/local/lib/libguile-2.2.so.0(scm_call_n+0x186)[0x7f3a6e154046]
/usr/local/lib/libguile-2.2.so.0(scm_call_3+0x2f)[0x7f3a6e0d2eaf]
/usr/local/lib/libguile-2.2.so.0(+0xbc5cd)[0x7f3a6e1465cd]
/usr/local/lib/libguile-2.2.so.0(scm_call_n+0x186)[0x7f3a6e154046]
/usr/local/lib/libguile-2.2.so.0(scm_call_3+0x2f)[0x7f3a6e0d2eaf]
/usr/local/lib/libguile-2.2.so.0(+0xbc5cd)[0x7f3a6e1465cd]
/usr/local/lib/libguile-2.2.so.0(scm_call_n+0x186)[0x7f3a6e154046]
/usr/local/lib/libguile-2.2.so.0(+0xb7fd2)[0x7f3a6e141fd2]
/usr/local/lib/opencog/libsmob.so(_ZN7opencog10SchemeEval7do_evalERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0xb9)[0x7f3a6539be09]
/usr/local/lib/opencog/libsmob.so(_ZN7opencog10SchemeEval11c_wrap_evalEPv+0x1a)[0x7f3a6539beba]
/usr/local/lib/libguile-2.2.so.0(+0x4324a)[0x7f3a6e0cd24a]
/usr/local/lib/libguile-2.2.so.0(+0xbc5cd)[0x7f3a6e1465cd]
/usr/local/lib/libguile-2.2.so.0(scm_call_n+0x186)[0x7f3a6e154046]
/usr/local/lib/libguile-2.2.so.0(+0xb7fd2)[0x7f3a6e141fd2]
/usr/local/lib/libguile-2.2.so.0(+0x43860)[0x7f3a6e0cd860]
/usr/local/lib/libguile-2.2.so.0(scm_c_with_continuation_barrier+0x45)[0x7f3a6e0cd945]
/usr/lib/x86_64-linux-gnu/libgc.so.1(GC_call_with_gc_active+0x77)[0x7f3a6d8438e7]
/usr/local/lib/libguile-2.2.so.0(+0xb6ad1)[0x7f3a6e140ad1]
/usr/lib/x86_64-linux-gnu/libgc.so.1(GC_call_with_stack_base+0x22)[0x7f3a6d83d952]
/usr/local/lib/libguile-2.2.so.0(scm_with_guile+0x38)[0x7f3a6e140e88]
/usr/local/lib/opencog/libsmob.so(_ZN7opencog10SchemeEval9eval_exprERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x2e)[0x7f3a6539bf3e]
/usr/local/lib/opencog/modules/libscheme-shell.so(_ZN7opencog12GenericShell9eval_loopEv+0x2ec)[0x7f3a582ea9cc]
/usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb8c80)[0x7f3a63f4ac80]
/lib/x86_64-linux-gnu/libpthread.so.0(+0x76ba)[0x7f3a6de716ba]
/lib/x86_64-linux-gnu/libc.so.6(clone+0x6d)[0x7f3a6dba082d]
======= Memory map: ========
00400000-00401000 r-xp 00000000 fd:00 80300005 /usr/local/bin/guile
00600000-00601000 r--p 00000000 fd:00 80300005 /usr/local/bin/guile
00601000-00602000 rw-p 00001000 fd:00 80300005 /usr/local/bin/guile
01d52000-6258b000 rw-p 00000000 00:00 0                                  [heap]
7f3870000000-7f38764e3000 rw-p 00000000 00:00 0 
7f38764e3000-7f3878000000 ---p 00000000 00:00 0 
7f3878000000-7f387c000000 rw-p 00000000 00:00 0 
7f387d7bb000-7f387d7bc000 ---p 00000000 00:00 0 
7f387d7bc000-7f387dfbc000 rw-p 00000000 00:00 0 
7f387dfbc000-7f387dfbd000 ---p 00000000 00:00 0 
7f387dfbd000-7f387e7bd000 rw-p 00000000 00:00 0 
7f387e7bd000-7f387e7be000 ---p 00000000 00:00 0 
7f387e7be000-7f387efbe000 rw-p 00000000 00:00 0 
7f387efbe000-7f387efbf000 ---p 00000000 00:00 0 
7f387efbf000-7f387f7bf000 rw-p 00000000 00:00 0 
7f387f7bf000-7f387f7c0000 ---p 00000000 00:00 0 
7f387f7c0000-7f387ffc0000 rw-p 00000000 00:00 0 
7f387ffc0000-7f387ffc1000 ---p 00000000 00:00 0 
7f387ffc1000-7f38807c1000 rw-p 00000000 00:00 0 
7f38807c1000-7f38807c2000 ---p 00000000 00:00 0 
7f38807c2000-7f3880fc2000 rw-p 00000000 00:00 0 
7f3880fc2000-7f3880fc3000 ---p 00000000 00:00 0 
7f3880fc3000-7f38817c3000 rw-p 00000000 00:00 0 
7f38817c3000-7f38817c4000 ---p 00000000 00:00 0 
7f38817c4000-7f3881fc4000 rw-p 00000000 00:00 0 



12 Feb 2017
-----------------
postgres: change  shared_buffers = 64576MB         # min 128kB
/etc/postgresql/9.5/main/postgresql.conf

apt-get update
apt-get upgrade
apt-get install autoconf-archive autoconf automake
apt-get install libgmp-dev libgc-dev libunistring-dev libffi-dev
apt-get install flex gettext texinfo
git clone git://git.sv.gnu.org/guile.git
cd guile; ./autogen.sh --no-configure;
mkdir build; cd build; ../configure; make -j

apt-get install libpq-dev
apt-get purge unixodbc-dev
apt-get autoremove
install link-grammar-5.3.15
cd relex; git pull; ant; ant install

update pair-count.scm to use URL
(sql-open "postgres:///yue_pairs?user=ubuntu&password=asdf")

lynx https://dumps.wikimedia.org/zhwiki/20170101/zhwiki-20170101-pages-articles.xml.bz2

time bzcat zhwiki-20170101-pages-articles.xml.bz2 |/home/ubuntu/src/relex/src/perl/wiki-scrub.pl

real	39m9.964s
user	39m15.964s
sys	1m14.940s

find wiki-stripped/* |wc 1211823
cd wiki-stripped
/home/ubuntu/src/relex/src/perl/wiki-clean-zh.sh
find  |wc   1018923
cd ..

Portal:
Draft:
模块:

mkdir alpha-pages
cd alpha-pages
~/src/relex/src/perl/wiki-alpha-zh.sh
find |wc  1018946

cd ../..
cp -pr alpha-data/alpha-pages beta-pages

createdb zh_pairs
cat src/atomspace/opencog/persist/sql/multi-driver/atom.sql | psql zh_pairs

cp ~/src/relex/src/split-sentences/nonbreaking_prefixes/* ~/run/nonbreaking_prefixes
cp ~/src/relex/src/split-sentences/split-sentences.pl ~/run

.... etc.


===============================================================
Again:
sudo cgm create all linas
sudo cgm chown all linas $(id -u) $(id -g)
cgm movepid all linas $$

14 April status:
---------------
ZH:
select count(*) from atoms;  18941255

14 April 2017
-------------
Start from scratch with English.

time lxc-copy -n  opencog-learn -N learn-en
real	6m43.362s
wget https://dumps.wikimedia.org/enwiki/20170320/enwiki-20170320-pages-articles-multistream.xml.bz2
2 hours 2 mins

time cat enwiki-20170320-pages-articles-multistream.xml.bz2 |bunzip2
|/home/ubuntu/src/relex/src/perl/wiki-count.pl
Counted 955001762 lines in 17398694 pages -- 17.4M articles
real    65m31.329s

time cat enwiki-20170320-pages-articles-multistream.xml.bz2 |bunzip2 |/home/ubuntu/src/relex/src/perl/wiki-scrub.pl
real    604m9.767s
user    413m17.996s
sys     13m8.680s


find |wc gives 7495026 total articles
real    267m1.295s

find |wc gives 5423537 after cat/template removal

createdb en_pairs
cat src/atomspace/opencog/persist/sql/multi-driver/atom.sql | psql en_pairs


----------------
Arghh more bugs:
* failure in LG to split punctuation
* failure to strip regex markup.
linkage_get_word
UBSCRIPT_MARK
SUBSCRIPT_DOT
linkage_print_diagram
DISPLAY_GUESS_MARKS
HIDE_MORPHO  for any language.... except its set to rue for jni
where are the square bracekts removed??????
orig_str in java....
feature/LinkableView.java line 286

LocalLGParser.java circa line 150
-----------------------------
yue: 
17006 -- 21876 submitted 27342 left


en: java crashed:
/home/ubuntu/run/hs_err_pid3206.log
# C  [liblink-grammar.so.5+0x2aa00]  linkage_set_domain_names+0xe0


-------------------------
en_pairs from 2016:
select count(*) from atoms;  18487291 atoms. == 18.5M
select sum(stv_count) from atoms; 1775388151 = 1.77 B

select sum(floatvalue[3]) from valuations where type=177; CountTru

select count(*) from  atoms where type =73;   396255 this is words
select count(*) from  atoms where type =47;   9045489 this is pairs
select count(*) from  atoms where type =8;    9045489 this is list links

select count(*) from valuations where type=121;  -- FloatValue
 select * from valuations where type != 176 and type != 177 limit 50;
select count(*) from valuations where type != 176 and type != 177;

select count(*) from valuations where key =2440463582;  -- 9672428
select count(*) from valuations where key =2440463583;  -- 8880904


(use-modules (opencog) (opencog persist) (opencog persist-sql))
(use-modules (opencog nlp) (opencog nlp learn))
(sql-open "postgres:///en_pairs?user=linas")
(batch-all-pairs)

 (load "compute-mi.scm")
(init-trace "/tmp/progress")
702
(load-atoms-of-type item-type)
(sql-stats)
; hangs... because it is walking the TLB which has 2.4GB of uuid
    _store->print_stats();
(length (cog-get-atoms item-type))

(define lgr (LinkGrammarRelationshipNode "ANY"))
(fetch-incoming-set lgr)
; there aren't any yet....

(define word (car (cog-get-atoms item-type)))
(compute-pair-wildcard-counts word lgr)

delete all-pair-wildcard-counts

      (par-for-each
         (lambda (word)
            (compute-pair-wildcard-counts word lgr)
            (trace-msg-cnt "Wildcard-count did ")) al)

         (cog-get-atoms item-type)
      )

(define al (take (cog-get-atoms item-type) 1000))

scheme@(guile-user) [1]> ,bt
In ice-9/threads.scm:
   289:22  5 (loop _)
In ice-9/futures.scm:
   259:13  4 (touch #<future 55c59c4adb40 queued #<partial-continuation
55c5…>)
   243:14  3 (work)
In unknown file:
           2 (wait-condition-variable #t)
While executing meta-command:
ERROR: In procedure cdr: Wrong type argument in position 1 (expecting
pair): ()


(use-modules (srfi srfi-1))
(define al (list-tabulate 100000 values))
(define foo 0)
(par-for-each (lambda (x) (set! foo (+ x foo))) al)

^CERROR: In procedure scm-error:
ERROR: User interrupt

Entering a new prompt.  Type `,bt' for a backtrace or `,q' to continue.
scheme@(guile-user) [1]> ,bt
In ice-9/threads.scm:
   289:22  5 (loop _)
In ice-9/futures.scm:
   265:11  4 (touch #<future 55e1984d3400 started #<procedure 55e198659f60 a…>)
   243:14  3 (work)
In unknown file:
           2 (wait-condition-variable #t)
While executing meta-command:
ERROR: In procedure cdr: Wrong type argument in position 1 (expecting pair): ()
scheme@(guile-user) [1]>

bug#26616: Acknowledgement (guile-2.2 par-for-each hangs for large lists)


https://debbugs.gnu.org/cgi/bugreport.cgi?bug=26616

-------
(cog-new-value type list) string float link
(cog-set-value! atom key value)
(cog-value atom key)
(cog-value?
cog-value->list
cog-tv-count

confidence

---------
(use-modules (opencog) (opencog persist) (opencog persist-sql))
(use-modules (opencog nlp) (opencog nlp learn))
(sql-open "postgres:///en_pairs?user=linas")
(load-atoms-of-type 'WordNode)

(define lgr (LinkGrammarRelationshipNode "ANY"))
(fetch-incoming-set lgr)
(cog-incoming-set lgr)

(define word (car (cog-get-atoms 'WordNode)))
(fetch-incoming-set word)
(cog-incoming-set word)
(define lpr (car (cog-incoming-set word)))
(fetch-incoming-set lpr)
(length (cog-incoming-set lgr))

scheme@(guile-user)> (length (cog-incoming-set lgr))
Too many heap sections: Increase MAXHINCR or MAX_HEAP_SECTS
Aborted


(load-atoms-of-type 'LinkGrammarRelationshipNode)
(fetch-atom lg_rel)

fetch_incoming_set_cb
SQLAtomStorage::getIncomingSet
tlb get uuid
getNod

h = as->fetch_atom(h);

   Handle h(doGetNode(t, str));
   Handle hg(doGetLink(t, hs));

getUUID  INVALID_UUID

select * from atoms where type = 89;

en_pairs=> select * from atoms where type = 89;
    uuid    | space | type | height | name | outgoing 
------------+-------+------+--------+------+----------
        152 |     1 |   89 |      0 | ANY  | 
 2439209701 |     1 |   89 |      0 | ANY  | 
 2439209706 |     1 |   89 |      0 | ANY  | 
 2439209711 |     1 |   89 |      0 | ANY  | 
 2439209716 |     1 |   89 |      0 | ANY  | 
(5 rows)

OK, so that's a bug .. no unique constraint


   8: SQLAtomStorage.cc:324
opencog::SQLAtomStorage::Response::get_all_values_cb()
"SELECT * FROM Valuations WHERE atom = 

SELECT * FROM Valuations WHERE atom = 152;
   1 |  152 |  177 | {1,0,402733330} |             | 

loading_typemap

(cog-new-ctv 0 0 right-total

set-count   vs ctv, stv, confidence, count etc.
AnyN
any-left
any-right

mst-parser.scm

Going to batch-logli wildcards
Elapsed secs 53
Going to do individual word-pair mi


Noting for pair (When *) -- no frequency!
no frequency's anywhere...
(PredicateNode \"*-FrequencyKey-*\") was never stored!

select * from atoms where type=53; -- the predicateNodes 

wtf line 646 ... sote the keyy....

Wildcard-count did 396255    compute-pair-wildcard-counts -- stores count
Elapsed secs 11
Done with wild-card count
Elapsed secs 0
Going to batch-count all-pairs
Start all-pair-count
Done with all-pair count -- again a count...
Elapsed secs 130
Going to batch-logli wildcards -- batch-all-pair-wildcard-logli
    compute-atom-logli
Elapsed secs 53
Going to do individual word-pair mi

(define k (PredicateNode "*-FrequencyKey-*"))
(define w (WordNode "When"))
(define e (EvaluationLink
(LinkGrammarRelationshipNode "ANY")
(ListLink  (WordNode "When") (AnyNode "right-word")))) 

(cog-value e k)

well ... e has no counts ... and thus no logli

(length (cog-incoming-set (WordNode "When") ))
except there are lots so wtf?

(define lg_rel (LinkGrammarRelationshipNode "ANY"))

(define (get-total-atom-count atom-list)
   (fold + 0.0 (map get-count atom-list))

 (compute-pair-wildcard-counts   w lg_rel

... there are no counts on any e's ... wtf ??

(EvaluationLink  ; uuid  2434162536
   (LinkGrammarRelationshipNode "ANY") ; uuid 152
   (ListLink   ; uuid 2434162535
      (WordNode "Hear")  ; uuid 17490475
      (WordNode "When")  ; uuiid 1537161
   )
)

incoming set failed to load the values!!!
also cog-value is real slowww

   // Get the correct UUID; its possible that we don't know it yet.
   UUID uuid = _tlbuf.getUUID(h);
   if (TLB::INVALID_UUID == uuid)
   {
      Handle hg(doGetAtom(h));
      uuid = _tlbuf.getUUID(hg);
   }
get_uuid
_vindex
_keyset
std::unordered_multimap<ContentHash, Handle>
std::unordered_map<
#include <unordered_map>
std::unordered_set<Handle, handle_hash>  -- kill this -- done
HandlePair

-----------------------------------------

(use-modules (opencog) (opencog persist) (opencog persist-sql))
(use-modules (opencog nlp) (opencog nlp learn))
(sql-open "postgres:///en_pairs?user=linas")
(use-modules (opencog cogserver))
(start-cogserver)
(batch-all-pairs)
(define lg_rel  (LinkGrammarRelationshipNode "ANY"))
      (init-trace "/tmp/progress")
(load "common.scm")
(load "compute-mi.scm")
 (load-atoms-of-type item-type)
 (length (cog-get-atoms item-type))
 (fetch-incoming-set lg_rel)

 (compute-pair-wildcard-counts w lg_rel)


(EvaluationLink (ctv 0 0 90720) ; uuid = 143501595
   (LinkGrammarRelationshipNode "ANY") ; uuid = 152
   (ListLink  ; uuid = 143501594
      (AnyNode "left-word")  ; uuid = 143427138
      (WordNode "When")  ; uuid = 1537161
   )
)
elect * from valuations where atom=143501595;

(store-atom left-star) took forever...

WordNode load took 36s, 38s

9112060 in incoming set

serial inc fetch= 28m11 ,  28m03
serial inc fetch w/GIN idx= 28m39
parallel inc fecth w/GIN idex = 38s, 28s, 29s
parallel inc fetch no idx = 32s, 30s, 33s

serial value fetch=  24m30
parallel value fetch=  1m36, 1m35
parallel resurse+value= 5m16, 6m47(!?), 6m47, 6m50, 7m6

atomspace add = 8m51 = 531 secs, 9m02, 7m56, 7m55, 8m00, 8m21

atsomapce add: added 9112060 atoms in 8m51 = 531 secs = 17.1K/sec
well, each atom is actually 5 atoms so this is 5x faster = 86K/sec

do a parallel type fetch...
as->fetch_all_atoms_of_type(t);
_backing_store->loadType(_atom_table, t);

o_store_single_ato
add_id_to_cache(uuid)
   puts it in local_id_cache
   erases from id_create_cach

maybe_create_id(uuid)

where is check for existance?????
well, get_uuid() does checking()
soo  iif in tlb then works

rp.id_set ...!?
get_ids get all id's  in 

do_store_single_atom
do_store_atom
_write_q

does tlbuf???

I don'd see it being tlbuff....

   UUID uuid = _tlbuf.getUUID(h);
   if (TLB::INVALID_UUID != uuid) return uuid;


+CREATE INDEX ON Atoms USING GIN(outgoing);

TODO:
parallelize get_ids...
actually get_ids is not needed.....

XXX need to store the keys

do_store_atom

total stroes is miscounted!aactually, its right, values don't count.

num_get_nodes=3 num_got_nodes=1 (33.333333 pct)
num_get_links=0 num_got_links=0 (-nan pct)
sql-stats: total loads = 19741116 total stores = 2 ratio=0.000000

get_recursive is not counting what it got.
values and valuations are not counting....

Also: type load doesn't ...? grab the TV's!?  FIXED

type load needs to be conservative with recursion! DONE

do-store_atom stores values recursively. It should have a flag for that.
Documented....

Also: ato->setValue() does not work for raw atoms!  so incoming is
broken.
RuntimeException
move printing exceptiioon ot guile

fetch_incoming_set false
MultiThreadUTest
tv-conf
cog-tv

14:37
 (use-modules (opencog) (opencog persist) (opencog persist-sql))
 (use-modules (opencog nlp) (opencog nlp learn))
 (sql-open "postgres:///en_pairs?user=linas")

 (load-atoms-of-type 'WordNode)   ;; approx 1 minutes?
 (define lg_any (LinkGrammarRelationshipNode "ANY"))
 (fetch-incoming-set lg_any) ;; approx 15 minutes ?
;
(mst-parse-text "this is a test")

 _tlbuf.addAtom(node, p->uuid); can replace!?
line 1427
line 378

start-cost-pair is bogus!
and subsequent crash

 (define e (EvaluationLink 
   (LinkGrammarRelationshipNode "ANY")
   (ListLink (WordNode "this") (WordNode "test"))))

 (cog-value e mi-key)

select * from atoms where name='this'; -- 953769
test -- 1712336
select * from atoms where outgoing='{953769,1712336}'; -- 29138136
select * from atoms where outgoing='{152,29138136}'; -- 29138137

select * from valuations where atom=29138137;


all count-tvs being stored as length 2...
fetch-atom aint getting the tv.

store-atom crashed. ... cause type=-1
store after fetch truncates
ctv print is fuckec
crap. Are teh datbases corrupt???

also .. reload the typemap
type_map_was_loaded = false
classserver().getNumberOfClasses();

INSERT INTO Valuations
   (SELECT 1 AS key,  -- 1 here is the predicate node
      uuid AS atom,
      176 as type,
      ARRAY[stv_mean, stv_confidence] as floatvalue
      FROM Atoms_Backup WHERE tv_type = 1);

INSERT INTO Valuations
   (SELECT 1 AS key, -- 1 here is the predicate node
      uuid AS atom,
      177 as type,
      ARRAY[stv_mean, stv_confidence, stv_count] as floatvalue
      FROM Atoms_Backup WHERE tv_type = 2);

wait .. link pipeline!???

observ-ext ... load???


the -FrequencyKey- shows {0,Infinity} ... wtf. MI is nan!!

Maybe 4 hours

 (use-modules (opencog) (opencog persist) (opencog persist-sql))
 (use-modules (opencog nlp) (opencog nlp learn))
 (sql-open "postgres:///en_pairs?user=linas")

 (load-atoms-of-type 'WordNode)   ;; approx 3 minutes?
 (define lg_any (LinkGrammarRelationshipNode "ANY"))
 (fetch-incoming-set lg_any) ;; approx 15 minutes ?
;
(mst-parse-text "this is a test") ; OK
-----------------
Ben,

Just got out of surgery for my broken leg; this email attempts to prove
that the general anesthesia didn't kill too many brain cells.  Its a report
on some the langauge-learning results.

Lets dive in.
(mst-parse-text "this is a test")

Raw hard-to-read result below.  Easier-to-read versions later.
ctv holds the raw count of how many times the word was observed.

((2.862118287646645 ((2 (WordNode "is" (ctv 1 0 8165736))) (3 (WordNode "a" (ctv 1 0 14691104))
))) (2.1880378875282904 ((1 (WordNode "this" (ctv 1 0 1300681))) (2 (WordNode "is" (ctv 1 0 8165736))
))) (2.8103625339100944 ((1 (WordNode "this" (ctv 1 0 1300681))) (4 (WordNode "test" (ctv 1 0 60328))
))))

The floating point number above and below is the Yuret MI of the word pair.
I've ameneded
https://github.com/opencog/opencog/tree/master/opencog/nlp/learn/learn-lang-diary/learn-lang-diary.pdf
pages 2-5 so that its less confusing and the formulas are accurate.
Basically, it derives Yuret's formulas in a more rigorous
way; if I recall, his argument was scattered, and just asserted the
result without deriving it.  So the PDF derives it.

((2.862118287646645 ((2 (WordNode "is" )) (3 (WordNode "a" ))))
 (2.1880378875282904 ((1 (WordNode "this" )) (2 (WordNode "is" ))))
(2.8103625339100944 ((1 (WordNode "this" )) (4 (WordNode "test" )))))

Simplifying further:

(((2 (WordNode "is" )) (3 (WordNode "a" )))
 ((1 (WordNode "this" )) (2 (WordNode "is" )))
((1 (WordNode "this" )) (4 (WordNode "test" ))))

The integer is the ordinal of the word.  Note that the linkage
"is-a" was selected over "a test" -- that's because "a test" has an
MI of 2.0935.  This is not terribly surprising; any MI of less than
four is pretty crappy, and these four words occur so commonly that
the correlation between them really is quite qeak -- they're alomost
drowning in noise.  Extracting disjuncts should strongly sharpen the
results.  Next email.

Here's a "better" example:

(mst-parse-text "cats eat cat food")
$5 = ((7.329 ((2 (WordNode "eat" (ctv 20938))) (4 (WordNode "food" (ctv 73924)))))
(4.992 ((3 (WordNode "cat" (ctv 18408))) (4 (WordNode "food" (ctv 73924)))))
(-1000 ((1 (WordNode "cats" (ctv 5902))) (4 (WordNode "food" (ctv 73924))))))

So "eat food" has a decent MI, as expected.  Also "cat food" is decent.
The minus-1000 means that the word pair "cats food" was never observed.
(get-pair-mi-str "cats" "eat") = -1000 means that "cats eat" was never
observed!  Bummer! The word "cats" was observed 6000 times, and this was
not enough to discover a sentence that has "cats eat" in it.  These
statistics are from some relatively smallish sample of WP articles, so
lack of such a sentence is maybe not surprising. Here, childrens &
young-adult lit may be better.

Anyway, clustering that reveals that cats, dogs, etc are similar should
help with this, or so goes the hypothesis.

The word-pair "cats cat" does occur and has an MI of 5 but is prevented
from linking by the link-crossing constraint.  Have not attempted to
figure out if the Dick Hudson landmark transitivity idea can be mutated
to apply to this situation. I suppose I should think about things before
writing about them, but not thinking is faster.

Lets try again:

(mst-parse-text "dogs eat dog food")
((7.329 ((2 (WordNode "eat" (ctv 20938))) (4 (WordNode "food" (ctv 73924)))))
(7.047 ((3 (WordNode "dog" (ctv 41896))) (4 (WordNode "food" (ctv 73924)))))
(5.050 ((1 (WordNode "dogs" (ctv 14852))) (2 (WordNode "eat" (ctv 20938))
))))

Well, that's much better. Let's try something harder:
(mst-parse-text "It is not uncommon to discover strange things")

((7.515 ( (WordNode "not" ) (WordNode "uncommon" )))
 (4.142 ( (WordNode "is" ) (WordNode "uncommon" )))
 (4.412 ( (WordNode "It" ) (WordNode "is" )))
 (2.739 ( (WordNode "uncommon" ) (WordNode "to" )))
(3.529 ( (WordNode "to" ) (WordNode "discover" )))
(0.822 ( (WordNode "to" ) (WordNode "things" )))
(6.171 ( (WordNode "strange" ) (WordNode "things" ))))

Almost right -- the stinker in there is "to things" and it has a
terrible MI.  The correct link would have been "discover things"
but again, this word-pair was never ever observed.

That's it for now, more later.

p.s. The above is obtained with code that uses values in full
generality; so for example the normalized word frequency is stored as

(Valuation
    (WordNode "foo")
    (PredicateNode "*-Frequency Key-*")
    (FloatValue 0.1234567 3.018))

Note that "Valuation" is like an EvaluationLink but different.
The first number is the normalized frequency of observation N(foo) / N(all words)
and the second number of log-base-2 of the first number (its easier to
read, than counting zeros in a frequency).

I had to fix a dozen bugs in brand-new SQL backend code to get this to
work right. It all seems stable, now.

==========================================

   (EvaluationLink
      (LinkGrammarRelationshipNode "ANY")
      (ListLink
			(AnyNode "left-word")
			(AnyNode "right-word")))

fooo  failed to store counts for lw, rw...

Hmm
total word pair counts = 4.1823518e+08

(define-public (count-all-words)
	(define total-wordcnt 0)
   (for-each
      (lambda (word)
         (set! total-wordcnt (+ total-wordcnt (get-count word))))
      (cog-get-atoms item-type))
	total-wordcnt
)
836420450.0

342:48 342:50

(define-public (count-all-words)
	(get-total-atom-count (cog-get-atoms item-type))
)

(get-count (WordNode "the"))
$28 = 41658552.0

(define (mkhist)
	(define nbins 100)
	(define lo -0.7)
	(define hi 0.7)
	(define inc (/ nbins (- hi lo)))
	(define hist (make-array 0 nbins))
	(define (rat w) (/ (- (get-left-count-str w) (get-right-count-str w)) (get-word-count-str w)))

	(define x lo)

	(for-each (lambda (w)
			(define bin (round (* inc (- (rat (cog-name w)) lo))))

			(if (nan? bin) (set! bin 0))
				(set! bin (inexact->exact bin))
			(if (>= bin nbins) (set! bin (- nbins 1)))
			(if (< bin 0) (set! bin 0))
			(array-set! hist (+ 1 (array-ref hist bin)) bin))
		(cog-get-atoms 'WordNode))

	(array-for-each (lambda (cnt)
			(format #t "~A	~A\n" x cnt)
			(set! x (+ x (/ 1.0 inc))))
		hist)
)

=============================================

(cog-incoming-by-type
	(LinkGrammarRelationshipNode "ANY")
	'EvaluationLink)

get_left_wildcard_count word lg_rel)
(get-total-atom-count (get-all-pairs))

(define (wtf)
	(for-each
		(lambda (pair)
			(if (> 0.5 (get-count (get-left-word-of-pair pair)))
				(format #t "wtf left of pair ~A" pair))
			(if (> 0.5 (get-count (get-right-word-of-pair pair)))
				(format #t "wtf right of pair ~A" pair))
		)
		(get-all-pairs)))

418235182.0

(get-total-atom-count (get-all-words))
836420450.0
(length (get-all-pairs))

(LgWordCset 
    (WordInstanceNode "adsf@62e9c582-1984-472b-a2f5-b61b2b0707e8")
    (LgAnd 
        (LgConnector 
            (LgConnectorNode "ANY")
            (LgConnDirNode "-")
            (LgConnMultiNode "@")
        )
        (LgConnector 
            (LgConnectorNode "ANY")
            (LgConnDirNode "+")
            (LgConnMultiNode "@")
        )
    )
)

No cset for the last word!!

no DISJUNCT srcNode.get("DISJUNCT"); on last word .. line 139
no attr on the last word
load_senses
config.isStoreSense

ERROR: Throw to key `C++-EXCEPTION' with args `("fetch-atom" "Error:
get_uuid(): cannot find (WordNode \"abcccccccccc\" (ctv 1.000000
0.000000 4.000000)) ; [8608664669745395561][1]\n\n
(/home/linas/src/novamente/src/atomspace-git/opencog/persist/sql/multi-driver/SQLAtomStorage.cc:934)\nFunction
args:\n((EvaluationLink\n   (LinkGrammarRelationshipNode \"ANY\")\n
(ListLink\n      (WordNode \"###LEFT-WALL###\" (ctv 1 0 19431131))\n
(WordNode \"abcccccccccc\" (ctv 1 0 4))\n   )\n)\n)")'.


(fetch-atom (Word "asdfasdfasdf"))
(fetch-atom (EvaluationLink (LinkGrammarRelationshipNode "ANY")
    (ListLink (Word "###LEFT-WALL###") (Word "asdfasdfqewr"))))

(fetch-atom (ListLink (Word "###LEFT-WALL###") (Word "asdfasdfqewr")))

SQLAtomStorage::doGetLink
IOException
 fixed in commit 327fc6c0a3c8b4b62ac80a61e2fdfc6971190c30

arghhh, last checkpoint: 24304265 24M distinct words
select sum(floatvalue[3]) from valuations where type=7;

gives 1914173302 == 1.9G observations

single-quote -- leading
semicolon -- leading
foobar
sql-stats should print name of the DB and the login user.<F4>
/home/ubuntu/run/hs_err_pid31730.log
but only when sock is dropped...
bug https://github.com/opencog/atomspace/issues/1054


Using bdwgc as of 
0f4244e130541a591d638c98f820b6b49e915ac0
Author: Ivan Maidanski <ivmai@mail.ru>
Date:   Thu Jan 12 00:58:41 2017 +0300


stack below seen twice 3 4
#0  0x00007ffff762c350 in pthread_kill ()
   from /lib/x86_64-linux-gnu/libpthread.so.0
#1  0x00007ffff785f490 in GC_suspend_all () at pthread_stop_world.c:640
#2  0x00007ffff785f564 in GC_stop_world () at pthread_stop_world.c:748
#3  0x00007ffff784b19e in GC_stopped_mark (
    stop_func=stop_func@entry=0x7ffff784aca0 <GC_never_stop_func>)
    at alloc.c:650
#4  0x00007ffff784bd19 in GC_try_to_collect_inner (
    stop_func=0x7ffff784aca0 <GC_never_stop_func>) at alloc.c:488
#5  0x00007ffff784bf9a in GC_try_to_collect_general (
    stop_func=stop_func@entry=0x0, force_unmap=force_unmap@entry=0)
    at alloc.c:1064
#6  0x00007ffff784c06d in GC_gcollect () at alloc.c:1088
#7  0x00007ffff7b06529 in scm_i_gc (what=<synthetic pointer>)
    at ../../libguile/gc.c:266
#8  scm_gc () at ../../libguile/gc.c:255
#9  0x00005555555551f2 in Eval::~Eval() ()


stack below seen twice.3 
#0  0x00007ffff762c350 in pthread_kill ()
   from /lib/x86_64-linux-gnu/libpthread.so.0
#1  0x00007ffff785f6fb in GC_start_world () at pthread_stop_world.c:990
#2  0x00007ffff784b2d6 in GC_stopped_mark (
    stop_func=stop_func@entry=0x7ffff784aca0 <GC_never_stop_func>)
    at alloc.c:728
#3  0x00007ffff784bd19 in GC_try_to_collect_inner (
    stop_func=0x7ffff784aca0 <GC_never_stop_func>) at alloc.c:488
#4  0x00007ffff784bf9a in GC_try_to_collect_general (
    stop_func=stop_func@entry=0x0, force_unmap=force_unmap@entry=0)
    at alloc.c:1064
#5  0x00007ffff784c06d in GC_gcollect () at alloc.c:1088
#6  0x00007ffff7b06529 in scm_i_gc (what=<synthetic pointer>)
    at ../../libguile/gc.c:266
#7  scm_gc () at ../../libguile/gc.c:255
#8  0x00005555555551f2 in Eval::~Eval() ()

==============================================
latest bdwgc does this:
#0  GC_push_all_eager (bottom=<optimized out>, 
    top=top@entry=0x7ffff43f7000 <error: Cannot access memory at address
0x7ffff43f7000>) at mark.c:1599
#1  0x00007ffff7855625 in GC_push_all_stack (bottom=<optimized out>, 
    top=top@entry=0x7ffff43f7000 <error: Cannot access memory at address
0x7ffff43f7000>) at mark.c:1609
#2  0x00007ffff78568aa in GC_push_all_stack_sections (lo=<optimized
out>, 
    lo@entry=0x7ffff43f56c0 <error: Cannot access memory at address
0x7ffff43f56c0>, 
    hi=hi@entry=0x7ffff43f7000 <error: Cannot access memory at address
0x7ffff43f7000>, traced_stack_sect=<optimized out>) at mark_rts.c:565
#3  0x00007ffff785f2fd in GC_push_all_stacks () at
pthread_stop_world.c:557
#4  0x00007ffff7855bcf in GC_mark_some (
    cold_gc_frame=0x7fffe43d5d00 "\274ǧ\367\377\177") at mark.c:343
#5  0x00007ffff784b20d in GC_stopped_mark (
    stop_func=stop_func@entry=0x7ffff784aca0 <GC_never_stop_func>)
    at alloc.c:702
#6  0x00007ffff784bd19 in GC_try_to_collect_inner (
    stop_func=0x7ffff784aca0 <GC_never_stop_func>) at alloc.c:488
#7  0x00007ffff784bf9a in GC_try_to_collect_general (
    stop_func=stop_func@entry=0x0, force_unmap=force_unmap@entry=0)
    at alloc.c:1064
#8  0x00007ffff784c06d in GC_gcollect () at alloc.c:1088
#9  0x00007ffff7b06529 in scm_i_gc (what=<synthetic pointer>)
    at ../../libguile/gc.c:266
#10 scm_gc () at ../../libguile/gc.c:255
#11 0x00005555555551f2 in Eval::~Eval() ()


apt-cache show libgc-dev
libgc-dev_7.4.2-8_amd64.deb
git tag
gc7_4_2
gc7_4_4
gc7_6_0 <---  try this one -- notpe still bad.


    txt="Error: get_uuid(): cannot find (ListLink\n  (WordNode \"Hume\"
(ctv 1.000000 0.000000 16.000000)) ; [1287745831931189139][1]\n
(WordNode \",\" (ctv 1.000000 0.000000 64.000000)) ;
[7731950238383222497][1]\n"...)

            result = RAISE_SIGNAL(p, GC_sig_thr_restart);


Guess  some of the threads are exiting when gc runs...

for (p = GC_threads[i]; p != 0; p = p -> next) {
p 

#define RAISE_SIGNAL(t, sig) pthread_kill(THREAD_SYSTEM_ID(t), sig)
#define THREAD_SYSTEM_ID(t) (t)->id

ohhh 7.6 sometimes deadlocks...

------------------ done iteration 14
Done creating 120 threads

Thread 1917 "a.out" received signal SIGSEGV, Segmentation fault.
[Switching to Thread 0x7fffc639b700 (LWP 27872)]
0x00007ffff762d350 in pthread_kill ()
   from /lib/x86_64-linux-gnu/libpthread.so.0
(gdb) bt
#0  0x00007ffff762d350 in pthread_kill ()
   from /lib/x86_64-linux-gnu/libpthread.so.0
#1  0x00007ffff785fe70 in GC_suspend_all () at pthread_stop_world.c:640
#2  0x00007ffff785ff44 in GC_stop_world () at pthread_stop_world.c:748

(igdb) up
#1  0x00007ffff785fe70 in GC_suspend_all () at pthread_stop_world.c:640
640	              result = RAISE_SIGNAL(p, GC_sig_suspend);
(gdb) print p
$1 = (GC_thread) 0x7ffff7a7d380 <first_thread>
(gdb) print i
$2 = 0
(gdb) print p->id
$3 = 140737198868224
(gdb) print /x p->id
$4 = 0x7fffeebec700

Sooo.. p->id  is not self.

(gdb) print /x p->next
$5 = 0x0

(gdb) print GC_threads[1]
$6 = (volatile GC_thread) 0x0

(gdb) print /x self
$10 = 0x7fffc639b700   -- yes this agreees with gdb message on top.

(gdb) info thr --  lists all the threads. ...  0x7fffeebec700 is not listed,
its not a valid thread.

sure looks like bdwgc is failing to keep GC_threads[0] accurate.!!

(gdb) print p->flags
$11 = 6 '\006'

include/private/pthread_support.h
#       define FINISHED 1       /* Thread has exited.
#       define DETACHED 2       /* Thread is treated as detached.
                                /* Thread may really be detached, or
                                /* it may have been explicitly
                                /* registered, in which case we can
                                /* deallocate its GC_Thread_Rep once
                                /* it unregisters itself, since it
                                /* may not return a GC pointer.
#       define MAIN_THREAD 4    /* True for the original thread only.

but its not teh main thread::: .. p is neoither of the below:
(gdb) info thr
  Id   Target Id         Frame 
  1    Thread 0x7ffff7fc7300 (LWP 24666) "a.out" 0x00007ffff762767d in pthread_join () from /lib/x86_64-linux-gnu/libpthread.so.0
* 1917 Thread 0x7fffc639b700 (LWP 27872) "a.out" 0x00007ffff762d350 in pthread_kill () from /lib/x86_64-linux-gnu/libpthread.so.0

(gdb) print *p
$12 = {next = 0x0, id = 140737198868224, stop_info = {last_stop_count = 1545, 
    stack_ptr = 0x7fffeebeb6c0 <error: Cannot access memory at address 0x7fffeebeb6c0>}, flags = 6 '\006', thread_blocked = 0 '\000', finalizer_skipped = 0, 
  finalizer_nested = 0 '\000', stack_end = 0x0, altstack = 0x0, 
  altstack_size = 0, stack = 0x0, stack_size = 0, traced_stack_sect = 0x0, 
  status = 0x0, tlfs = {_freelists = {{0x1, 0xbd, 0x555555818520, 
        0x55555591f5d0, 0x5555557ff500, 0x3d, 0x1, 0x1, 0x1, 0x65, 
        0x1 <repeats 14 times>, 0x1a}, {0x1, 0x5555559242d0, 0x55555587d820, 
        0x555555908540, 0x10, 0x3d, 0x5555558ff2a0, 0xb9, 0x1c, 0xb, 0x0, 0x1, 
        0x1, 0x1, 0x1, 0x1, 0x555555927d00, 0x1, 0x14, 0x1, 0x1, 0x1, 0x1, 
        0x1, 0x1}, {0x1 <repeats 25 times>}}, gcj_freelists = {
      0xffffffffffffffff, 0x1 <repeats 24 times>}}}


new thread handled at line 538
threa delete on 572
GC_delete_thread  line 550
but also ... GC_delete_gc_thread line 592

GC_delete_thread called from only one place:
GC_unregister_my_thread_inner
called from two places:
   GC_unregister_my_thread
   GC_thread_exit_proc  -- not called by guile

pthread_start.c:    pthread_cleanup_push(GC_thread_exit_proc, me);


scm_gc is NOT being called in guile mode.!!  Example 1
but fixing this does not cure the bug.

threads.c:    GC_unregister_my_thread ();

libguile/gc.c

static void on_thread_exit (void *v)
calls GC_unregister_my_thread() but only if t->needs_unregister) is set
called by init_thread_key 
by scm_i_init_thread_for_guile
by scm_init_guile()

Hmm   scm_i_with_guile no longer calls scm_init_guile()
but with_guile() does call scm_i_init_thread_for_guile
which does call init....

maybe the exit handler is still running.... when the gc is called.

except the thread should remain valid until all of the exit handlers
have returned.  So maybe a thread handler did not run? ??


Program terminated with signal SIGSEGV, Segmentation fault.
#0  0x00007f19e496f350 in pthread_kill ()
   from /lib/x86_64-linux-gnu/libpthread.so.0
[Current thread is 1 (Thread 0x7f19aa6a7700 (LWP 7486))]

sconew not being called !  
GC_register_my_thread
print notin
print nxt

x /150xg &board

[Current thread is 1 (Thread 0x7f7aa3a6d700 (LWP 25905))]

 print p
$3 = (GC_thread) 0x7f7abb142380 <first_thread>

(gdb) print /x p->id
$5 = 0x7f7ab7a95700  this is the first thread....

Needs_unreg was not set!!
scm_init_guile ()

------------------ done iteration 540
Done creating 120 threads


argh  this is broken:
cog-map-chase-links-chk
cog-par-chase-links-chk

thus all users of map-parses might be broken
map-parses
parallel-map-parses
map-word-instances

 (use-modules (opencog) (opencog persist) (opencog persist-sql))
 (use-modules (opencog nlp) (opencog nlp learn))
 (sql-open "postgres:///en_pairs?user=linas")
 (use-relex-server "127.0.0.1" 4445)

==========================================

again: using the rohit data:

select count(*) from atoms where type=73; gives 396K unique words.
select count(8) from atoms where type=47; gives number fo evluation
links which is 9672K  but 2*396K of these are anynodes, so really only
9672-792=8880K unique word-pairs.
which were observed 

en_pairs=> select * from atoms where type=74;
   uuid    | space | type | height |    name    | outgoing 
-----------+-------+------+--------+------------+----------
 143427138 |     1 |   74 |      0 | left-word  | 
 143427163 |     1 |   74 |      0 | right-word | 

en_pairs=> select * from atoms where outgoing='{143427138,143427163}';
   uuid    | space | type | height | name |       outgoing        
-----------+-------+------+--------+------+-----------------------
 143670792 |     1 |    8 |      1 |      | {143427138,143427163}

en_pairs=> select * from atoms where outgoing='{152,143670792}';
   uuid    | space | type | height | name |    outgoing     
-----------+-------+------+--------+------+-----------------
 143670793 |     1 |   47 |      2 |      | {152,143670792}

en_pairs=> select * from valuations where atom=143670793;
 key |   atom    | type |   floatvalue    | stringvalue | linkvalue 
-----+-----------+------+-----------------+-------------+-----------
   1 | 143670793 |  177 | {0,0,418235182} |             | 

So 418M observations of word-pairs.

ALTER DATABASE en_pairs RENAME TO en_pairs_rohit;

=========================================================
 (use-modules (opencog) (opencog persist) (opencog persist-sql))
 (use-modules (opencog nlp) (opencog nlp learn))
 (sql-open "postgres:///en_pairs?user=ubuntu")

(fetch-all-words)
(length (get-all-words)) 65021 
(total-word-observations) 7181662.0 7.2M
(PredicateNode "*-Sentence Word Pair-*")
(SchemaNode "*-Pair Distance-*")o
   (define pair-pred (PredicateNode "*-Sentence Word Pair-*"))
   (define pair-dist (SchemaNode "*-Pair Distance-*"))

(length (cog-incoming-set pair-pred))
(get-total-atom-count (cog-incoming-set pair-pred))

get-any-left-wildcard-count
get-any-right-wildcard-count
set-any-pair-total

set-any-left-wildcard-count
set-any-right-wildcard-count
get-any-pair-link
batch-all-pair-wildcard-counts
get-all-words

batch-all-pair-wildcard-logli
get-pair-total

GET-LEFT-WILD
(store-atom
      (set-count GET-LEFT-WILD TOTAL))
batch-all-pair-wildcard-logli
compute-pair-mi
get-any-pair-link-> GET-PAIR
get-word-pairs

cog-incoming-by-type
.scm:		(par-map get-endpoint (cog-filter link-type 
utilities.scm:
cog-map-chase-link dead
cog-map-chase-link-dbg   used by ppars ranker
cog-map-chase-links-chk  used by cog-chase-link-chk
cog-chase-link-chk   used by  nlp-utils

cog-map-apply-link  dead used by cog-get-link
cog-get-link used by 
cog-get-pred

(define bar (let ((done #f))
	(lambda () (format #t "duude ~A\n" done) (set! done #t))))

(AnyNode \"left-word\") (WordNode \"###LEFT-WALL###\"

get-logli
      (catch #t
         (lambda () (xxxxx))
         (lambda (key . args) #f)))


(start-trace msg)

get-any-pair  get-clique-pair

wow 32 gigs to load all pairs!

tlb.clear()
reserve_upto(uuid)
getMaxUUID

(make-narrow-links (mst-parse-text "The game is played on a level playing field"))

(LgWordCset 
    (WordInstanceNode "foo@e5bfab2f-b3b1-4cf1-ae89-89aaa47bf871")
    (LgAnd 
        (LgConnector 
            (LgConnectorNode "ANY")
            (LgConnDirNode "-")
        )
    )
)

(unfold

 (use-modules (opencog) (opencog persist) (opencog persist-sql))
 (use-modules (opencog nlp) (opencog nlp learn))
 (sql-open "postgres:///en_pairs_rohit?user=linas")
 (fetch-all-words)
 (fetch-any-pairs)



=========================================================
(sql-open "postgres:///en_snapshot?user=ubuntu")
Start counting, num words=106696
num words=106696

select count(*) from atoms where type=123;  -- 123 is wordNode

   85 | SchemaNode
   88 | PredicateNode
  123 | WordNode
  142 | LinkGrammarRelationshipNode


 uuid | space | type | height |          name          | outgoing 
------+-------+------+--------+------------------------+----------
   29 |     1 |   88 |      0 | *-Sentence Word Pair-* | 
   30 |     1 |   85 |      0 | *-Pair Distance-* | 
  141 |     1 |  142 |      0 | ANY  | 


select count(*) from atoms where outgoing[1]='29';
gives ... 12956699
30 gives ... 26174210   ... wtf!?

after loading clique only: 37925105 atoms = 38M/51G = 1.35KB/atom

(ListLink (WordNode "playing") (WordNode "field"))
zero

(ListLink (WordNode "day") (WordNode "field"))
1 and 1 at 30
Lincoln
the
which

   (ListLink (Word "the" ) (Word "field" ))
(cog-chase-link
(cog-get-link 'EvaluationLink PAIR (Pred


(define cnt 0)
(for-each
	(lambda (PAIR)
		(set! cnt (+ cnt 1))
		(if (not (eqv? (count-dist-pair PAIR) (count-clique-pair PAIR)))
			(throw 'bad-count 'foobar PAIR)
			(format #t "Its OK ~A\n" cnt)
		))
	(get-all-pairs))



115 | LgWordCset
2440463600
   1 | 2440463600 |  177 | {1,0,12}   |             | 
2440463720   {636276,2440463719}
2440463718   {107,2440463716}
2440463717   {101,2440463715}
2440463714   {1748714,2440463710}
2440463669  {2440463611,2440463599}


19741227 = 19.8M atoms / 30G = 1.52KB/atom

echo "" | ./submit-one.pl localhost 17001 observe-mst


(mst-parse-text "Area: total: 29,743 km² country comparison to the world: 149. land: 28,454 km² water: 1,289 km² Area comparative Australia comparative: about one third (33%) the size of Tasmania.")

freshie (0 ())
28 words

74  -- 34
108 -- 32
140 -- 30
170 -- 28
198 -- 26
224 -- 24
248 -- 
270
269
290

bad-pair in max-of-pair-list


 (use-modules (opencog) (opencog persist) (opencog persist-sql))
 (use-modules (opencog nlp) (opencog nlp learn))
 (sql-open "postgres:///en_pairs_mst?user=linas")
 (fetch-all-words)
 (length (get-all-words))
396262
 (fetch-pseudo-csets (get-all-words))
 (length (filter-words-with-csets  (get-all-words)))
30127

 (cset-observations (get-all-words))
436595.0


425186
(cset-vec-support (Word "the"))
(cset-vec-len (Word "the"))

(

   (length (cog-incoming-by-type WORD 'LgWordCset))

(define n 0)
(for-each
	(lambda (cset) 
		(set! n (+ 1 n)))
	(cog-incoming-by-type (Word "the") 'LgWordCset))

Ben, Ruiting,

For your enjoyment: I have some very preliminary results on word
similarity.  They look pretty nice, even thogh based on a fairly
small number of observations. 

If you've been watching TV instead of reading email, here's the story
so far: Starting from a large text corpus, the mutual information (MI)
of word-pairs are counted. This MI is used to perform a maximum
spanning-tree (MST) parse (of a different subset of) the corpus. From each
parse, a pseudo-disjunct is extracted for each word.  The
pseudo-disjunct is like a real LG disjunct, except that each connector
in the disjunct is the word at the far end of the link.

So, for example, in in idealized world, the MST parse of the sentence
"Ben ate pizza" would prodouce the parse Ben <--> ate <--> pizza and
from this, we can extract the psuedo-disjunct (Ben- pizza+) on the
word "ate".  Similarly, the sentence "Ben puked pizza" should produce
the disjunct (Ben- pizza+) on the word "puke".  Since these two 
disjuncts are the same, we can conclude that the two words "ate"
and "puke" are very similar to each other.  Considering all of the
other disjuncts that arise in this example, we can conclude that these
are the only two words that are similar.

Note that a given word may have very many psuedo-disjuncts attached
to it. Each disjunct has a count of the number of times it has been
observed.  Thus, this set of disjuncts can be imagined to be a vector
in a high-dimensional vector space, which each disjunct being a single
basis element.  The similarity of two words can be taken to be the
cosine-similariy between the disjunct-vectors (or pick another,
different metric, as you please.)

Below are a set of examples, for English, on a somewhat smmall dataset.
Collected over a few days, it contains just under half-a-million 
observations of disjuncts, distributed across about 30K words.
Thus, most words will have only a copule of disjuncts on them, 
which may have been seen only a couple of times. its important, at
this stage, to limit oneself to only the most popular words.

We expect the determiners "the" and "a" to be similar, and they are:
(cset-vec-cosine (Word "the") (Word "a")) = 0.1554007744026141

Even more similar:
(cset-vec-cosine (Word "the") (Word "this")) = 0.3083725359820755

Not very similar at all:
(cset-vec-cosine (Word "the") (Word "that")) = 0.01981486048876119

Oh hey this and that are similar. Notice the triangle with "the".
(cset-vec-cosine (Word "this") (Word "that")) = 0.14342403062507977

Some more results
 (cset-vec-cosine (Word "this") (Word "these")) = 0.23100101197144984
 (cset-vec-cosine (Word "this") (Word "those")) = 0.1099725424243773
 (cset-vec-cosine (Word "these") (Word "those")) = 0.13577971016706158

We expect that determiners, nouns and verbs to all be very differrent
from one-another. And they are:
 (cset-vec-cosine (Word "the") (Word "ball")) = 2.3964597196461594e-4
 (cset-vec-cosine (Word "the") (Word "jump")) = 0.0
 (cset-vec-cosine (Word "ball") (Word "jump")) = 0.0

We expect verbs to be similar, and they sort-of are.
 (cset-vec-cosine (Word "run") (Word "jump")) = 0.05184758473652128
 (cset-vec-cosine (Word "run") (Word "look")) = 0.05283524652572603

Since this is a sampling from wikipedia, there will be very few
"action" verbs, unless the sample accidentally contains articles
about sports. A "common sense" corpus, or a corpus that talks about
what people do, could/should improve the above verbs.  These are
very basic to human behavior, but are rare in most writing.

I'm thinking that a corpus of children's lit, and young-adult-lit
would be much better for these kinds of things.

An adjective.
 (cset-vec-cosine (Word "wide") (Word "narrow")) = 0.06262242910851494
 (cset-vec-cosine (Word "wide") (Word "look")) = 0.0
 (cset-vec-cosine (Word "wide") (Word "ball")) = 0.02449979787750126
 (cset-vec-cosine (Word "wide") (Word "the")) = 0.04718158900583385

 (cset-vec-cosine (Word "heavy") (Word "wide")) = 0.05752237416355278

Here's a set of antonyms!
 (cset-vec-cosine (Word "heavy") (Word "light")) = 0.16760038078849773

A pronoun
 (cset-vec-cosine (Word "ball") (Word "it")) = 0.009201177048960233
 (cset-vec-cosine (Word "wide") (Word "it")) = 0.005522960959398417

 (cset-vec-cosine (Word "the") (Word "it")) = 0.01926824360790382

Wow!! In English, "it" is usually a male!
 (cset-vec-cosine (Word "it") (Word "she")) = 0.1885493638629482
 (cset-vec-cosine (Word "it") (Word "he")) = 0.4527656594627214
 (cset-vec-cosine (Word "he") (Word "she")) = 0.1877589816088902

I can post the database on mondy, let me know when you're ready to
receive it.

above dataset has 200183 (200K) disjuncts in it

SIMILARITY_LINK

ac

scheme@(guile-user)> (batch-sim (Word "him") ac)
terminate called after throwing an instance of
'opencog::RuntimeException'
  what():  Failed to execute!
(/home/linas/src/novamente/src/atomspace-git/opencog/persist/sql/multi-driver/ll-pg-cxx.cc:113)
Aborted


[2017-05-07 17:01:27:152] [WARN] PQresult message: ERROR:  duplicate key
value violates unique constraint "atoms_uuid_idx"
DETAIL:  Key (uuid)=(2441253852) already exists.

[2017-05-07 17:01:27:152] [WARN] PQ query was: INSERT INTO Atoms (uuid,
space, type, height, outgoing) VALUES (2441253852, 1, 43, 1, '{1888882,
127137759}');


dohhh Need to reserve some uuid's!


[2017-05-04 17:31:29:122] [ERROR] There is no value for key
(PredicateNode "link count") ; [8812231717367445517][1]
 on atom (AnchorNode "MST data") ; [1539316140051770629][1]

createdb -T en_pairs_mst -e en_pairs_sim "forked from en_pairs_mst, holds similarity data"

COMMENT ON DATABASE en_pairs_mst IS 'forked from en_pairs_rohit, holds disjunct data';

COMMENT ON DATABASE en_pairs_rohit IS 'forked from en_pairs_2016, converted to modern format';

COMMENT ON DATABASE en_pairs_2016 IS 'Rohits original pair data; old format; missing correct word-counts';

(define ac (filter-words-with-csets (get-all-words)))

(cset-vec-len
(cset-vec-observations

(define lens (map (lambda (wrd) (cons (cset-vec-len wrd) wrd)) ac))

(define slens (sort lens (lambda (a b) (> (car a) (car b)))))

(define obs (map (lambda (wrd) (cons (cset-vec-observations wrd) wrd)) ac))

(define sobs (sort obs (lambda (a b) (> (car a) (car b)))))


(define firm (filter (lambda (wrd) (< 8.0 (cset-vec-len wrd))) ac))

*) count words during MST
err this can be reconstructed by taking:
   counts of disjuncts  based on counts of csets .... 
so never mind....

what are teh most comon disjuncts???

(filter (lambda (cset) (< 10 (get-count cset)))
	(cog-incoming-by-type (Word "United") 'LgWordCset))

156 ... 125.888

5  41.44827196747233 "and"
8  31.658516707416464 "as"
10  30.140583554376658 "well"
11  29.969530201342277 "in"
18  18.805788982259568 "first"
21  17.254613233923575 "is"
22  16.742203742203742 "also"
23  15.386776859504135 "can"
24  15.359470949456778 "on"
25  14.910157559503853 "at"
26  14.424603174603176 "been"
31  13.231375985977214 "but"
32  13.122743682310471 "part"
34  12.835568802781918 "with"
35  12.835051546391755 "old"
36  12.726962457337885 "same"
38  11.925403225806452 "one"
39  11.611694152923539 "which"
43  10.856905158069885 "not"

(filter (lambda (cset) (< 5 (get-count cset)))
	(cog-incoming-by-type (Word "Gestalt") 'LgWordCset))

(.+) 34
(of -)  14

(is+) 216
was+ 197
(has+ 55
was+ was+ 12
is+ was+ 10

get-cset-vec
ad   cset-vec-observations
(define disjunct-entropy
(define total-cset-count (cset-observations all-cset-words))
(define all-cset-words (filter-words-with-csets (get-all-words)))

(define total-cset-count 0)
(cog-map-type 
	(lambda (cset) 
		(set! total-cset-count (+ total-cset-count (get-count cset))) #f)
	'LgWordCset)

7.984991833299495  bits total MI bits

(cset-vec-mi (Word "United"))  7.116097374166928
is the relative(?) MI to the disjuncts in the word.
(is how much MI this word contributes to the total MI)
(and its slightly below average)

(cset-vec-frequency (Word "United"))

(/ (log (cset-vec-frequency (Word "United"))) (log 2))
-10.48276867673862  is the entropy for that word, only.

"Cao" "Award" "x" "y" "Prime" "we" "per" "Division" "League" "Game"

(define cao (get-cset-vec (Word "Cao")))

34 (length cao)

(filter (lambda (cset) (< 10 (get-count cset))) cao)

18  ,- Cao- Cao+  garbage !!

8 Grammy- for+ Best+
7 Academy- for+ Best+

23 Minister+
5 the- Minister+
3 as- Minister+
3 Governor-General- Minister+

 "The" "a" "to" "in" "of" "and" "the" "," "."

 "Bay" "Street" "Island" "of" "century" "right" "Game" "Georgian" "or" "a" ";" "near" "Party" "team" "law" "Australia" "her" "research" "Church" "east" "Government"

--------------------------------------------------------------

1985 words of length > 8
all pairs of above with cosine > 0.5

23993 pairs, but some are junk
15809 good pairs.

store-sim
 (sim-pair WORD-A WORD-B) cos-key
            (FloatValue SIM (get-angle SIM)))
(define (sim-pair WORD-A WORD-B) (SimilarityLink WORD-A WORD-B))
(define cos-key (PredicateNode "*-Cosine Distance Key-*"))


(define all-sims '())
(cog-map-type
	(lambda (sim)  (set! all-sims (cons sim all-sims)) #f)
	'SimilarityLink)

(define (cosine-of-sim SIM)
	(car (cog-value->list (cog-value SIM cos-key))))

(define good-sims
(filter
	(lambda (sim)
		(< 0.5 (car (cog-value->list (cog-value sim cos-key)))))
	all-sims))


(map (lambda (sim) (sim-cosine sim)) (take ranked-sims 20))
	

 'Poir .. Perls'
 'Poir .. Sevan'
 'Sevan .. Perls'
 'Sevan .. Ruins'
 'Ruins .. Perls'
 'Poir .. Ruins'
 'Gongora .. Perls'
  'Poir .. Gongora'
  'Gongora .. Sevan'
  'Gongora .. Ruins'
  'Poir .. Gag'

 (use-modules (opencog) (opencog persist) (opencog persist-sql))
 (use-modules (opencog nlp) (opencog nlp learn))
 (sql-open "postgres:///en_pairs_sim?user=linas")
 (use-modules (opencog cogserver))
 (start-cogserver "opencog2.conf")
 (fetch-all-words)
(fetch-pseudo-csets (get-all-words))

70 74 128

95  0.953598053136202  'conjunction .. accordance'

504  0.868429815807705  'in .. from'
633  0.8549756852697713  'in .. at'
637  0.8545553489854567  'In .. By'
643  0.8540378312493768  'in .. After'
740  0.846034030453443  'canal .. swamp'


754  0.843837363738534  'at .. At'
757  0.8436223414042503  'in .. In'
818  0.838269351079866  'in .. on'
840  0.8366056647469058  'creation .. existence'
878  0.8332692184393486  'e.g .. i.e'
965  0.8265058609938521  'and .. but'
969  0.8264399296782371  'in .. With'
971  0.8263325988164274  'in .. inside'


canal -- 68 dj 

(define (prt-sim sim port)
   (format port "~A  '~A .. ~A'\n" (sim-cosine sim)
      (cog-name (gar sim)) (cog-name (gdr sim))))

get-disjunct-string

20.0  canal  the-
8.0  canal  the- .+
5.0  canal  the- ,+

14.0  swamp  the-
3.0  swamp  the- .+


18.0  creation  the- of+
10.0  existence  the- of+

627  in  the+
75  in  a+
61  in  which+
49  in  the+ the+
36  in  used-
33  in  his+
32  in  order+
31  in  United+
27  in  gallantry-
26  in  born-
23  in  role-

8338 -- in
2185 from

155  from  the+
20  from  :+ :+ :+ :+ :+ :+ :+ :+ :+ :+ 0+ 0+ 0+ 0+ 0+ 0+ 0+ 0+ 0+ 0+
18  from  a+
9  from  derived-
9  from  until+
9  from  degree-
8  from  his+
8  from  comes-
8  from  away-
7.0  from  time+
7.0  from  the+ the+

get-pair-mi
get-pair-mi-str ("

MI(fast, horse) = 5.258979
MI(fast, car) = 3.805734

(get-pair-logli get-any-pair (Word "fast") (Word "horse"))
-log P(fast, horse) = 24.054777  P = 5.7383969102974027e-8
-log P(fast, car) = 23.832385  P = 6.694794440144226e-8


-log P(*, horse) = 14.383531  P = 4.6787056718009e-5
-log P(*, car) = 12.707894    P = 1.4946610743515038e-4
-log P(fast, *) =  14.930225  P = 3.2029815202410256e-5


MI(fast, {hosrse, car}) = linear interploation of the two. 
  [
  p(fast,horse) log p(fast, horse) / p(fast,*) p(*,horse)
+
  p(fast,car) log p(fast, car) / p(fast,*) p(*,car) ] 
   / [p(fast,horse) + p(fast,car)]

= [ p(fast,horse) 5.258979 + p(fast,car) 3.805734] /
     1.2433191350441628e-7
= 5.565671566878678e-7 / 1.2433191350441628e-7 
= 4.476462567015012



(get-left-wild-prob GETTER WORD)
(get-left-wild-log-prob GETTER WORD)
(get-pair-prob GETTER WORD WORD)

(get-logli ATOM)

(define (get-left-wild-prob GETTER WORD)
	(EvaluationLink any-pair-pred (ListLink any-left word))
(define (get-any-wild-wild)
   (EvaluationLink any-pair-pred (ListLink any-left any-right))
)

(define (get-any-wild-wild)
   (EvaluationLink any-pair-pred (ListLink any-left any-right))
)

get-any-pair PAIR -- public OK defined in common.scm
get-clique-pair PAIR --public OK

kill get-pair-mi-str 
make get-pair-mi public. done


(define all-cset-words (filter-words-with-csets (get-all-words)))
(define all-disjuncts (get-all-disjuncts))
(define all-csets (get-all-csets))
(define total-cset-count (get-total-cset-count))

in the en_pairs sim: MI is  7.9849918332741225
(- (+ 10.280666542033556 16.00578269190252) 18.301457400661953)

in en_pairs_mst:
(length all-cset-words) 49423
(length all-disjuncts) 486824  + 73 more
(length all-csets) 749337 + 118 more
total-cset-count 1154809  + 235 more
word-entropy-bits 10.353641069558124
disjunct-entropy-bits 16.48346995957877
cset-entropy-bits 18.958440018522307
MI is 7.878671010614585

all connectors ...
(length (get-all-pseudo-connectors)) 81557


wtf:
(length all-disjuncts) 225396 
wiki-mst-en.sh is running
why is get_nodes bad? because no nodes are being created. so that OK.
why is total stores for node =0?  just like above. its OK.

postgres:///en_pairs_mst?user=linas  is the ongoing accumulation of mst stats...

guile -l mst-count-en.scm
335 secs for words
1071 secs for pairs
results size is 32G for 19741168 atoms
1213 secs for csets


fix message -- done
add  sql-clear-stats -- done

./mst-one.sh en gamma-pages/G/Gzhelian localhost 17001


move base-stats.scm to pair-stats.scm -- DONE

Cannot connect to database: FATAL:  remaining connection slots are reserved for non-replication superuser connections

get-clique-pair get-any-pair

(display-backtrace (fluid-ref the-last-stack))

Throw to key `bad-summation' with args `(count-all-pairs "Error:
pair-counts unequal: 5974976.0 5754410.0\n")'.
pair-counts unequal: 5974600.0 5761584.0\n")'. afer redoing the left!
pair-counts unequal: 5974600.0 5761584.0\n")'  afer doing left 2x
pair-counts unequal: 5974976.0 5761682.0\n")' after redoing right.
pair-counts unequal: 5974976.0 5761682.0\n")' after right 2x
pair-counts unequal: 5974600.0 5761584.0\n") after redoing  left

(define aw (get-all-words))

(ob 'left-stars)

(define save-1 (map (lambda (w) (cons (ob 'left-wild-count w) w)) aw))

(length (cob 'cache-all-left-counts))

(for-each (lambda (a b) (if (not (equal? a b)) (error "aiiide ~A ~A" a b)))
	save-1 save-2)

ERROR: aiiide ~A ~A (54.0 . (WordNode "d'Urville")
) (56.0 . (WordNode "d'Urville")
)

So... recomputing the right counts changed the left-count on above....

wtf.... (ob 'left-wildcard w) is empty....

set-pair-count calls make-pair
set-left-wild-count calls set-pair-count with 'left-wildcard  which is null

foobar confused about which pari si which

Glurg. and now its this:

pair-counts unequal: 2133920.0 1168749.0\n")'
(define w (WordNode "d'Urville"))
(define ob (make-pair-wild (make-any-link)))
(define ob (make-pair-count-api ob))
(define cob (make-compute-count ob))

(ob 'left-support-size)
(length (ob 'left-stars))
 (cob 'compute-total-count)
(length (cob 'cache-all-left-counts))
(cob 'compute-total-count)
(define save-1 (map (lambda (w) (cons (ob 'left-wild-count w) w)) aw))

(cob 'compute-left-count w)
(ob 'left-wildcard w)
(ob 'right-wildcard w)
(ob 'left-wild-count w)

(for-each (lambda (a b) (if (not (equal? a b)) (error "aiiide ~A ~A" a b)))
	save-1 save-2)

(fold (lambda (p s) (+ s (car p))) 0 save-1)   1173656.0

(define rave-1 (map (lambda (w) (cons (ob 'right-wild-count w) w)) aw))

(fold (lambda (p s) (+ s (car p))) 0 rave-1)   2133920.0

(define (lsum w)
	(

1) fetch failed
2) compute failed.
3) left-stars returns junk fixed

(define mave-1 (map (lambda (w) (cons (ob 'left-wild-count w) w)) aw))

pair-counts unequal: 34692424.0 34689203.0\n")'.

Elapsed time to load words: 45 secs
Done loading words, now loading any-pairs
Elapsed time to load ANY-link pairs: 322 secs
Finished loading any-word-pairs
Support: num left=106696 num right=106696
Done with wild-card count N(*,w) and N(w,*) in 222 secs << par-map vs..  217
Done computing N(*,*) total-count=34688664.0 in 13 secs
Start computing log P(*,w)
Done computing 106696 left-wilds in 39 secs  << 120% vs. 15
Done storing 106696 left-wilds in 458 secs  << par-for vs 101 secs for non-par
Done with -log P(*,w), start -log P(w,*)
Done computing 106696 right-wilds in 45 secs vs. 15 now
Done storing 106696 right-wilds in 458 secs << par-for vs 103 now
Done computing -log P(w,*) and <-->
Going to do individual word-pair MI
Done computing 2360328 pair MI's in 962 secs (1124 secs under load)
Stored 100000 of 2360328 pairs in 191 secs (523.5602094240837 pairs/sec)
....
Stored 2000000 of 2360328 pairs in 317 secs (315.45741324921136 pairs/sec)
Stored 2100000 of 2360328 pairs in 251 secs (398.40637450199205 pairs/sec)
Stored 2200000 of 2360328 pairs in 254 secs (393.7007874015748 pairs/sec)
Stored 2300000 of 2360328 pairs in 300 secs (333.3333333333333 pairs/sec)
Done storing 2360328 pair MI's in 6964 secs  <<< 6847 under load
Finished with MI computations

Sooo any-pair:
  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
 5180 linas     20   0 11.819g 8.935g  37080 S   0.0  3.5 117:00.53 guile
 5525 linas     20   0 11.483g 8.931g  37616 S   0.0  3.5 129:07.73 guile


----------------
clique pairs:

Start loading words ...
Elapsed time to load words: 45 secs
Done loading words, now loading clique pairs
Elapsed time to load clique pairs: 1145 secs  <<< vs 322 for any-pairs
Finished loading clique-word-pairs
Support: num left=106696 num right=106696
Done with wild-card count N(*,w) and N(w,*) in 737 secs  <<< vs 215 for any
Done computing N(*,*) total-count=31628463.0 in 14 secs  <<<!? almost the same??
Start computing log P(*,w)
Done computing 106696 left-wilds in 14 secs
Done storing 106696 left-wilds in 103 secs
Done with -log P(*,w), start -log P(w,*)
Done computing 106696 right-wilds in 15 secs
Done storing 106696 right-wilds in 103 secs
Done computing -log P(w,*) and <-->
Going to do individual word-pair MI
Done computing 4810 pair MI's in 37872 secs << 10.5 hours!!!
Done storing 4810 pair MI's in 7 secs   << whhhat!????
Finished with MI computations


  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
17274 linas     20   0 26.656g 0.024t  37676 S   0.0  9.6 406:04.03 guile


=================================================================
=================================================================
disjuncts & csets:

Start loading words ...
Elapsed time to load words: 126 secs   << now 112 ...814 ... 22 .. 20
Done loading words, now loading pairs
Elapsed time to load csets: 783 secs  << now 367 on fresh..553...294..309
Finished loading any-word-pairs
Support: num left=396262 num right=291637  << in 18 13
Done with wild-card count N(*,w) and N(w,*) in 39 secs  `<< now 203 !???  fluke
    << 85 after redesign ,, 72
Done computing N(*,*) total-count=661104.0 in 34 secs << uncahnged
    << 14 after redesign 15
Done computing 446204 pairs in 13 secs << 23 after red 24
Start computing log P(*,w)
Done computing 291637 left-wilds in 33 secs << 27
Done storing 291637 left-wilds in 670 secs << now  493 .. 711 (spin media)
    << dropped to 87 secs on SSD
Done with -log P(*,w), start -log P(w,*)
Done computing 396262 right-wilds in 26 secs  now 4 secs
Done storing 396262 right-wilds in 549 secs  <<< now  28 !! wtf ??? .. 47
Done computing -log P(w,*) and <-->
Going to do individual word-pair MI
Done computing 446204 pair MI's in 88 secs << 70 secs
Stored 100000 of 446204 pairs in 268 secs (373.13432835820896 pairs/sec)
Stored 200000 of 446204 pairs in 238 secs (420.16806722689074 pairs/sec)
Stored 300000 of 446204 pairs in 286 secs (349.65034965034965 pairs/sec)
Stored 400000 of 446204 pairs in 303 secs (330.03300330033005 pairs/sec)
Done storing 446204 pair MI's in 1215 secs ... 1345 (spin media)
    << 201 secs SSD
Going to do column and row subtotals
Finished left entropy subtotals in 46 secs << 43
Finished right entropy subtotals in 20 secs << 16
Finished left MI subtotals in 40 secs << 35
Finished right MI subtotals in 12 secs << 8

Finished with MI computations



(use-modules (opencog) (opencog persist) (opencog persist-sql))
(use-modules (opencog nlp) (opencog nlp learn))
(sql-open "postgres:///en_pairs_sim?user=linas")
(use-modules (opencog cogserver))
(start-cogserver "opencog2.conf")
(define pca (make-pseudo-cset-api))
(batch-pairs pca)

(pca 'fetch-pairs)
(print-matrix-summary-report pca #t)
(define psa (add-pair-stars pca))(define psa (add-pair-stars pca))
(define sup (add-support-compute psa))
(sup 'cache-all)
(define cca (make-central-compute psa))
(cca 'cache-all)
(define sto (make-store psa))
(sto 'store-wildcards)

(print-matrix-summary-report pca #t)
Summary Report for Correlation Matrix Word-Disjunct Pairs (aka Connector
Sets)
Left type: WordNode    Right Type: LgAnd    Pair Type: LgWordCset
Wildcard: (ListLink (ctv 0 0 661104)
   (AnyNode "cset-word")
   (AnyNode "cset-disjunct")
)
Rows: 37413 Columns: 291637
Size: 446204 non-zero entries of 10911015081 possible
Fraction non-zero: 4.0895E-5 Sparsity (-log_2): 14.578
Total observations: 661104.0  Avg obs per pair: 1.4816
Entropy Total: 18.301   Left: 16.006   Right: 10.281
Total MI: -7.985

                 Left         Right     Avg-left     Avg-right
                 ----         -----     --------     ---------
Support (l_0)  4122.        370.0
Count   (l_1)  8763.        680.7         2.126        1.839
Length  (l_2)  236.8        51.39         5.7452E-2    .1389
RMS Count      216.6        46.40         5.2550E-2    .1254



duuuu
(define pca (make-pseudo-cset-api))
(define wpca (add-pair-wildcards pca))
(define cpca (add-pair-count-api pca))
(define fpca (add-pair-freq-api pca))

(define w (car (wpca 'left-support)))
(define d (car  (wpca 'right-support)))
(cpca 'left-wild-count d)
(define d (car (drop-while 
	(lambda (dj) (> 10 (cpca 'left-wild-count dj))) (wpca 'right-support))))

(define w (car (drop-while 
	(lambda (wrd) (> 10 (cpca 'right-wild-count wrd))) (wpca 'left-support))))

(cpca 'right-wild-count w)

(fpca 'left-wild-freq d)
(/ (cpca 'left-wild-count d) (cpca 'wild-wild-count))

(fpca 'right-wild-freq w)
set-right-wild-freq

(define cf (make-compute-freq (add-pair-freq-api (add-pair-wildcards cpca))))
(cf 'init-freq)
(cf 'compute-right-freq w)
(cf 'cache-right-freq w)
'compute-right-freq w

(define righties (cf 'cache-all-right-freqs))
(define okr (filter (lambda (x) (not (null? x))) righties))
(length okr)

etierh not iint or ot being computed.   FIXED

ERROR: In procedure cog-value: There is no value for key (PredicateNode
"*-FrequencyKey-*") ; [6632538966455889482][1]
 on atom (LgWordCset (ctv 1.000000 0.000000 1.000000)

(LgWordCset 
   (WordNode "dentist" 
   (LgAnd
      (PseudoConnector
         (WordNode "an")
         (LgConnDirNode "-"))
      (PseudoConnector
         (WordNode ",")
         (LgConnDirNode "+"))))


there's no compute-pair    'set-pair-freq

=========================================================================


2017-05-13 01:35:49 UTC [229-2879] LOG:  checkpoints are occurring too frequently (29 seconds apart)
2017-05-13 01:35:49 UTC [229-2880] HINT:  Consider increasing the configuration parameter "max_wal_size".

pre postgres 9.5:
 checkpoint segments. 100 or so is not out of the ordinary.
 increase your checkpoint_timeout to 1 hour, as well as look at
increasing your checkpoint_completion_target
------

2017-05-17 07:48:25 UTC [228-1] LOG:  database system was shut down at 2017-05-17 05:02:36 UTC
2017-05-17 07:48:25 UTC [229-1] [unknown]@[unknown] LOG:  incomplete startup packet
2017-05-17 07:48:25 UTC [228-2] LOG:  invalid primary checkpoint record
2017-05-17 07:48:25 UTC [228-3] LOG:  invalid secondary checkpoint record
2017-05-17 07:48:25 UTC [228-4] PANIC:  could not locate a valid checkpoint record
2017-05-17 07:48:25 UTC [230-1] postgres@postgres FATAL:  the database system is starting up
2017-05-17 07:48:25 UTC [203-1] LOG:  startup process (PID 228) was terminated by signal 6: Aborted
2017-05-17 07:48:25 UTC [203-2] LOG:  aborting startup due to startup process failure
2017-05-17 07:51:21 UTC [1430-1] LOG:  database system was shut down at 2017-05-17 05:02:36 UTC
2017-05-17 07:51:21 UTC [1430-2] LOG:  invalid primary checkpoint record
2017-05-17 07:51:21 UTC [1430-3] LOG:  invalid secondary checkpoint record
2017-05-17 07:51:21 UTC [1430-4] PANIC:  could not locate a valid checkpoint record
2017-05-17 07:51:21 UTC [1429-1] LOG:  startup process (PID 1430) was terminated by signal 6: Aborted
2017-05-17 07:51:21 UTC [1429-2] LOG:  aborting startup due to startup process failure


http://stackoverflow.com/questions/8799474/postgresql-error-panic-could-not-locate-a-valid-checkpoint-record

 time cp -pr main main-fu  <<< 23 minutes
 du -sm  <<  81638  -- 82 gigabytes!

/usr/lib/postgresql/9.5/bin/pg_resetxlog  /var/lib/postgresql/9.5/main
Transaction log reset

sudo service postgresql start

2017-05-17 13:17:08 UTC [15452-1] LOG:  database system was shut down at 2017-05-17 13:05:10 UTC
2017-05-17 13:17:08 UTC [15452-2] FATAL:  could not access status of transaction 2804419190
2017-05-17 13:17:08 UTC [15452-3] DETAIL:  Could not open file "pg_clog/0A72": No such file or directory.
2017-05-17 13:17:08 UTC [15451-1] LOG:  startup process (PID 15452) exited with exit code 1
2017-05-17 13:17:08 UTC [15451-2] LOG:  aborting startup due to startup process failure


https://www.postgresql.org/message-id/AANLkTims48njGKkvkXHiTG6=19hQ31VFmFRPPLg+5w03@mail.gmail.com

dd if=/dev/zero of=Transaction_missing_file_of pg_clog bs=256K count=1
(To make the uncommitted record as they haven't been committed).

dd if=/dev/zero of=0A72 bs=256K count=1


Last entries in pg_clog are from 14 May, so 3 days of nothingness.
2017-05-17 13:27:53 UTC [24212-1] LOG:  database system was interrupted; last known up at 2017-05-17 13:17:08 UTC
2017-05-17 13:27:53 UTC [24212-2] LOG:  database system was not properly shut down; automatic recovery in progress
2017-05-17 13:27:53 UTC [24212-3] LOG:  invalid record length at D62/6C000098
2017-05-17 13:27:53 UTC [24212-4] LOG:  redo is not required
2017-05-17 13:27:53 UTC [24212-5] FATAL:  could not access status of transaction 2124106599
2017-05-17 13:27:53 UTC [24212-6] DETAIL:  Could not open file "pg_multixact/offsets/7E9B": No such file or directory.

dd if=/dev/zero of=7E9B bs=256K count=1
members/1FA5

psql
\l

en_pairs
en_pairs_old
en_pairs_partial
en_snapshot

pg_dump en_pairs
pg_dump -cC en_pairs
pg_dumpall 

time pg_dump en_pairs >en_pairs.sql 

pg_dump: Dumping the contents of table "valuations" failed: PQgetResult() failed.
pg_dump: Error message from server: ERROR:  could not access status of transaction 2786849088
DETAIL:  Could not open file "pg_clog/0A61": No such file or directory.

dd if=/dev/zero of=~/9.5/main/pg_clog/0A61 bs=256K count=1
pg_clog/0A51
pg_clog/0A70
pg_clog/0A59
pg_clog/0A5C
pg_clog/0A50
pg_clog/093A

everything from that to 0A5E

for ((i=0;i<293;i++))
do
        b=$(echo "ibase=16;93A" | bc)
        j=$(echo "$b+$i" |bc)
        k=$(echo "obase=16;$j" | bc)
        echo dd if=/dev/zero of=~/9.5/main/pg_clog/0$k bs=256K count=1
done

pg_clog/0923
pg_clog/08E4
pg_clog/085E
0524
pg_clog/0523

mv /var/lib/postgresql/9.5/main /var/lib/postgresql/9.5/main-semi-fu

/usr/lib/postgresql/9.5/bin/initdb /var/lib/postgresql/9.5/main
CREATE ROLE ubuntu WITH CREATEDB;
ALTER ROLE ubuntu WITH LOGIN;
createdb en_pairs
psql en_pairs < ~/src/atomspace/opencog/persist/sql/multi-driver/atom.sql

time psql en_pairs < /var/lib/postgresql/en_pairs.sql
real    59m16.468s
user    0m57.480s
sys     0m12.480s

psql en_pairs
select count(*) from atoms where type=123; 123 == wordnode
276715  << there used to be about a million, here

select count(*) from atoms where type=81; 81 == evaluationlink.
37199086  37 M. Hmmm

select sum(floatvalue[3]) from valuations where type=7;
select * from valuations limit 1;
select * from atoms, valuations where valuations.type=7 and valuations.atom=atoms.uuid and atoms.type = 81 limit 1;

Total counts on all evaluationlinks.
(this should be doubled, clique and any.)
select sum(floatvalue[3]) from atoms, valuations where valuations.type=7 and valuations.atom=atoms.uuid and atoms.type = 81;

gives: 327030163 == 327M observations of links! wow!

Nonetheless, restart from scratch.

ALTER DATABASE en_pairs RENAME TO en_pairs_semi_fu;

COMMENT ON DATABASE en_pairs_semi_fu IS 
   'rohit-pairs and some gutenberg, after the crash'; 




=======================================
and again, on fanny:

time cp -pr main main-fu

real    23m29.237s
user    0m0.464s
sys     2m54.152s

/usr/lib/postgresql/9.6/bin/pg_resetxlog  /var/lib/postgresql/9.6/main
/usr/lib/postgresql/9.6/bin/pg_resetxlog  -f /var/lib/postgresql/9.6/main

pg_clog/0351

dd if=/dev/zero of=~/9.6/main/pg_clog/0351 bs=256K count=1
pg_multixact/offsets/057A
pg_multixact/members/0E99
Those 3 fixed it.

time pg_dumpall > everything.sql
pg_clog/033C 
create all from 02CE to pg_clog/0350

#!/bin/bash


# inclusive
start=$(echo "ibase=16;2CE" | bc)
end=$(echo "ibase=16;350" | bc)

len=$(echo "$end-$start+1" | bc)
echo $len

for ((i=0;i<$len;i++))
do
        j=$(echo "$start+$i" |bc)
        k=$(echo "obase=16;$j" | bc)
        # echo $k
        dd if=/dev/zero of=~/9.6/main/pg_clog/0$k bs=256K count=1
done

cd /home2/postgresql/data-lost-dumps
time pg_dumpall > everything.sql
real    13m5.740s
user    1m13.272s
sys     1m3.764s
-rw-r--r--  1 postgres postgres 15190388055 May 17 15:59 everything.sql
so 15 gigabytes.

sudo service postgresql stop
mv /var/lib/postgresql/9.6/main /var/lib/postgresql/9.6/main-semi-fu
/usr/lib/postgresql/9.6/bin/initdb  /var/lib/postgresql/9.6/main

sudo service postgresql start

time psql < /home2/postgresql/data-lost-dumps/everything.sql
real    55m43.405s
user    1m13.960s
sys     0m21.596s


=======================================
objdump -d post-process.o

linkage_set_domain_names +0xe0

linkage->pp_info[j].num_domains = k;
for (d = pp->d_type_array[j]; d != NULL; d = d->next) k++;
char buff[] = {d->type, '\0'}
string_set_add (buff, postprocessor->string_set);
build_type_array  not needed if not printed.

linkage->pp_info[j].domain_name[k] =

=====================================================
en_pairs_2016
-------------
Rohit's original pair data; old format; missing correct word-counts.
All data is from Wikipedia article random planar-tree parses.
Contains word-pair counts only (and some MI calcs in obsolete format).

STATUS: obsolete, archived.
DATE: 17 May 2017
REASON: converted to newer format.

en_pairs_2016=> \dt+
                       List of relations
 Schema |   Name    | Type  | Owner |    Size    | Description
--------+-----------+-------+-------+------------+-------------
 public | atoms     | table | linas | 2198 MB    |
 public | global    | table | linas | 8192 bytes |
 public | spaces    | table | linas | 8192 bytes |
 public | typecodes | table | linas | 48 kB      |
(4 rows)


select count(atoms.stv_count) from atoms, typecodes where
atoms.type=typecodes.type and typecodes.typename='EvaluationLink';

gives: 9045489  i.e. 9M different evlinks
gives 536234371 i.e. 536M observations  when sum()
gives 396255  distinct wordnodes

866733953 bytes uncompressed.
141609207 bytes compressed
md5sum en_pairs_2016.sql.bz2
28577666fb51d3dc3658688a73e8bee6  en_pairs_2016.sql.bz2

==================================================================

en_pairs_rohit
--------------
forked from en_pairs_2016, converted to modern format
This includes 8.9 word-pairs with MI on them. (But the MI is
in the old format).

STATUS: obsolete, archived.
DATE: 18 May 2017
REASON: This is included in the newer en_pairs_mst, which contains
all data here, plus data from MST parsing. Also, since its word-pairs
from wikipedia only, the data quality is mediocre.

en_pairs_rohit=> \dt+
                        List of relations
 Schema |     Name     | Type  | Owner |    Size    | Description
--------+--------------+-------+-------+------------+-------------
 public | atoms        | table | linas | 1735 MB    |
 public | atoms_backup | table | linas | 2198 MB    |
 public | global       | table | linas | 8192 bytes |
 public | spaces       | table | linas | 8192 bytes |
 public | typecodes    | table | linas | 48 kB      |
 public | valuations   | table | linas | 2321 MB    |
 public | values       | table | linas | 8192 bytes |
(7 rows)

atoms_backup is a copy of atoms from en_pairs_2016

SELECT count(*) FROM atoms;  <<< 19741280 = 19M atoms total

SELECT count(*) FROM atoms WHERE height=0; <<<  396313 = 396K
SELECT count(*) FROM atoms WHERE height=1; <<< 9672482 = 9.6M
SELECT count(*) FROM atoms WHERE height=2; <<< 9672472 = 9.6M
SELECT count(*) FROM atoms WHERE height=3; <<<      13

select count(atoms.uuid) from atoms,typecodes where
atoms.type=typecodes.type and typecodes.typename='EvaluationLink';

gives 9672459 i.e. 9.6M atoms. This is a 6% more than en_pairs_2016,
(which had 9.0M) because maybe it includes the partial sums??

gives 396262 WordNodes -- as before, plus 7 new test words.

select sum(valuations.floatvalue[3]) from atoms,typecodes,valuations where
valuations.atom = atoms.uuid and
atoms.type=typecodes.type and typecodes.typename='EvaluationLink';

gives 1672941118 == 1.6GB of counts so this is triple the pairs, because
it includes: left and right sums, and the total sum. Hmm. Should be
quadruple!?  Yes, see below.

select * from atoms where outgoing='{143427138,143427163}';
is the ListLink (Any Any)

select * from atoms where outgoing='{152,143670792}';
select * from valuations where atom=143670793;
gives 418235277 == 418M observations of ANY,ANY

 2440463583 |   53 |  *-Mutual Info Key-* | PredicateNode

select count(*) from valuations where key=2440463583;
8880914  so 8.9M pairs with mutual info on them.


2957364787 bytes uncompressed -- 2.9GB
448704179 bytes compressed -- 448 MBytes

 md5sum en_pairs_rohit.sql
792a8830520c8cdddb5b723656ae82cc  en_pairs_rohit.sql

 md5sum en_pairs_rohit.sql.bz2
6f85e89787cbf20c54167868867cf41c  en_pairs_rohit.sql.bz2

==================================================================

en_pairs_mst
------------
forked from en_pairs_rohit, holds disjunct data from MST parsing.
Both word-pairs and MST  parses came from wikipedia articles;
this appears to give only mediocre results.

STATUS: archived.
DATE: 18 May 2017
REASON: The wikipedia-based data is mediocre.

                       List of relations
 Schema |    Name    | Type  | Owner |    Size    | Description
--------+------------+-------+-------+------------+-------------
 public | atoms      | table | linas | 1886 MB    |
 public | spaces     | table | linas | 8192 bytes |
 public | typecodes  | table | linas | 48 kB      |
 public | valuations | table | linas | 2421 MB    |
 public | values     | table | linas | 8192 bytes |
(5 rows)

SELECT count(*) FROM atoms; <<< 21381856 = 21M atoms

SELECT count(*) FROM atoms WHERE height=0; <<<   396313 = 396K == rohit.
SELECT count(*) FROM atoms WHERE height=1; <<<  9763966 = 9.8M almost rohit
SELECT count(*) FROM atoms WHERE height=2; <<< 10280485 = 10.2M = 6% larger
SELECT count(*) FROM atoms WHERE height=3; <<<   941092 = 941K

The height-3 are exactly the pseudo-disjuncts.

SELECT count(atoms.uuid) FROM atoms,typecodes WHERE
atoms.type=typecodes.type AND typecodes.typename='EvaluationLink';

gives 9672459 so exactly the same as en_pairs_rohit, that's good.

'WordNode' gives 396262 -- 400K words, exactly same as before, Good.

'LgWordCset' gives 941092 - almost a million connector sets.

SELECT sum(valuations.floatvalue[3]) FROM atoms,typecodes,valuations
WHERE valuations.atom = atoms.uuid AND
atoms.type=typecodes.type AND typecodes.typename='LgWordCset';

gives 1669981 -- 1.7M observations of csets or maybe 1.8 obs per cset.
A bit disappointing....

2205218439 bytes uncompressed (2.2GB)
325948435 bytes compressed (325 MByte)

 md5sum en_pairs_mst.sql
955b7fe0578ded9a266f0874e8a02d6f  en_pairs_mst.sql

 md5sum en_pairs_mst.sql.bz2
ee81f6b11e4629ffa30efc0950af3595  en_pairs_mst.sql.bz2

==================================================================

simil_en
--------
The similarity database published on the web, forked from an earlier
version of en_pairs_mst.  Contains pairs derived only from wikipedia.
plus some number of disjuncts from mst parses.

Published on web 12 May 2017
322343968 bytes compressed (322MBytes)

 md5sum simil_en.sql.bz2
b9bb221069867c5f4a307670a34387c8  simil_en.sql.bz2

==================================================================

en_pairs_sim
------------
Forked from earlier version of en_pairs_mst, contains less data.
(half as many disjuncts) This is the dataset analyzed in the diary.

The simil_en is a snapshot of this; the en_pairs_sim contains
additional caches of partial sums across disjuncts, etc.

STATUS: working DB
DATE: 21 May 2017

                       List of relations
 Schema |    Name    | Type  | Owner |    Size    | Description
--------+------------+-------+-------+------------+-------------
 public | atoms      | table | linas | 1840 MB    |
 public | spaces     | table | linas | 8192 bytes |
 public | typecodes  | table | linas | 48 kB      |
 public | valuations | table | linas | 2702 MB    |
 public | values     | table | linas | 8192 bytes |
(5 rows)

SELECT count(atoms.uuid) FROM atoms,typecodes WHERE
atoms.type=typecodes.type AND typecodes.typename='EvaluationLink';

gives 9672459 so exactly the same as en_pairs_rohit, that's good.

'LgWordCset' gives 446204 which is as expected, (as reported in diary)

We are not creating a backup of this yet, the simil_en is good enough
backup; this dataset marches on as a working dataset.

==================================================================

en_pairs_semi_fu
----------------
Forked from en_pairs_rohit, plus more WP data, plus some gutenberg.
Has some data loss (many missing words, missing LGLink-pairs), due to
server lockup + crash failure (and fsync was off, dohhhh).

Large database, bloated with ExecutationLinks, and the clique pairs,
which just are not useful at this time. In fact, 95% of the atoms are
these junk atoms.  This dataset is just wayyy too bloated to be useful.

STATUS: obsolete, archived.
DATE: 18 May 2017
REASON: abandoned. Too bloated to be useful, per above.

                       List of relations
 Schema |    Name    | Type  | Owner |    Size    | Description 
--------+------------+-------+-------+------------+-------------
 public | atoms      | table | linas | 12 GB      | 
 public | spaces     | table | linas | 8192 bytes | 
 public | typecodes  | table | linas | 48 kB      | 
 public | valuations | table | linas | 9633 MB    | 
 public | values     | table | linas | 8192 bytes | 
(5 rows)

SELECT count(*) FROM atoms;   <<< 132172780 = 132M atoms total


SELECT count(atoms.uuid) FROM atoms,typecodes WHERE
atoms.type=typecodes.type AND typecodes.typename='EvaluationLink';

gives 37199086 = 37M evlinks compared to rohits 9M

However, of these
SELECT count(*) FROM Atoms WHERE outgoing @> ARRAY[CAST(29 AS BIGINT)];
where PredicateNode "*-Sentence Word Pair-*" uuid=29;
gives 29637409 = 29.6M clique-pairs

vs LinkGrammarRelationshipNode uuid=141; <<< 7561677 7.5M

So many of rohit's pairs were lost, and most of the new data are the
cliique pairs.

'WordNode' gives 276715 which is 2/3rds of rohits 400K so where did
   all the words go? More importantly, why aren't the foreign-key 
   constraints violated???

'ExecutionLink' has 62936410 = 62M counted pairs

SELECT count(*) FROM atoms WHERE height=0;   <<<     276972  = 277K
SELECT count(*) FROM atoms WHERE height=1;   <<<   30958666  = 30M
SELECT count(*) FROM atoms WHERE height=2;   <<<  100135499  = 100M
SELECT count(*) FROM atoms WHERE height=3;   <<<     801643  = 802K
SELECT count(*) FROM atoms WHERE height=4;   <<<          0

wtf is height=3? Answer: some (many?) random "ANY" disjuncts
from the random tree parses. (!)  These have low UUID's!

Max observed UUID is 135947882
Loaded 276972 atoms at height 0 <<< so a lot of words are missing.
also: there are 508 links with missing uuids in thier outgoing set.

7721725512 bytes uncompressed (7.7GB) 17 May 2017
1207333639 bytes compressed (1.2GB)

 md5sum en_pairs_semi_fu.sql.bz2
06b0acfecf9f5d4b25cca903b8f3b2a7  en_pairs_semi_fu.sql.bz2

==================================================================
en_snap
-------
STATUS: deleted
DATE: 21 May 2017
REASON: bloated junk, looks like wikipedia.

select count(*) from atoms;   <<< 41511869 = 41M

A total of 106696 = 106K WordNodes

 SELECT count(*) FROM Atoms WHERE outgoing @> ARRAY[CAST(141 AS BIGINT)]; 
gives 2786640 == 2.7M  LG links.

and 9587761 = 9.6M clique pairs, and 18M ExecutionLinks.

==================================================================
en_pairs_tone
-------------
Random-planar-tree parsed books from "tranche-1" of mostly project
gutenberg books. Contains counts for word-pairs, words and disjuncts.

STATUS: good
DATE: 24 May 2017
REASON: I think it's good.

                        List of relations
 Schema |    Name    | Type  | Owner  |    Size    | Description 
--------+------------+-------+--------+------------+-------------
 public | atoms      | table | ubuntu | 909 MB     | 
 public | spaces     | table | ubuntu | 40 kB      | 
 public | typecodes  | table | ubuntu | 56 kB      | 
 public | valuations | table | ubuntu | 591 MB     | 
 public | values     | table | ubuntu | 8192 bytes | 
(5 rows)

select count(*) from atoms;  <<< 10317409 = 10M atoms total
WordNodes: 139790 -- 140K
EvaluationLink : 4886362 -- 4.9M
ListLink: exactly the same.

select count(*) from valuations; <<< 5431036 = 5.4M values

SELECT sum(floatvalue[3]) FROM valuations WHERE type=7;
 gives  396713166 << 397M total obs.

SELECT sum(valuations.floatvalue[3]) FROM valuations, atoms, typecodes
WHERE valuations.atom=atoms.uuid AND atoms.type=typecodes.type AND
typecodes.typename='EvaluationLink';

gives 139806259 << 140M pair observations
.. WordNode: 125696239 << 125M obs
...LgWordCset: 125707119 << 126M disjuncts

SentenceNode: 330376 == 330K unique sentences
ParseNode: 5173173 == 5.1M parses
###LEFT-WALL### seen 5173095 = ... a few missing left-walls!?

464744628 bytes uncompressed == 464MB en_pairs_tone.sql 24 May 2017
81217915 bytes compressed == 81MB en_pairs_tone.sql.bz2

md5sum:
28562003d0567039571006803b716dc0  en_pairs_tone.sql
c4a981af336075f0121ac020887bfa47  en_pairs_tone.sql.bz2

==================================================================
en_pairs_tone_mst
-----------------
Disjuncts from MST-parsed books from "tranche-1" of mostly project
gutenberg books. Based off of the en_pairs_tone. Contains MI for tone,
but not the cosine angles.

STATUS: good
DATE: 27 May 2017
REASON: I think it's good.

en_pairs_tone_mst=> \dt+
                        List of relations
 Schema |    Name    | Type  | Owner  |    Size    | Description 
--------+------------+-------+--------+------------+-------------
 public | atoms      | table | ubuntu | 1496 MB    | 
 public | spaces     | table | ubuntu | 40 kB      | 
 public | typecodes  | table | ubuntu | 56 kB      | 
 public | valuations | table | ubuntu | 1871 MB    | 
 public | values     | table | ubuntu | 8192 bytes | 
(5 rows)

select count(*) from atoms; << 16487725 = 16.5M (6M more than baseline)

select count(*) from valuations; <<< 19330366 = 19.3M (14M more than base)

SELECT sum(valuations.floatvalue[3]) FROM valuations, atoms, typecodes
WHERE valuations.atom=atoms.uuid AND atoms.type=typecodes.type AND
valuations.type=7 AND typecodes.typename='EvaluationLink';

EaluationLink:  559225036 = 559M almost 4X more than baseline.
WordNode: 125696239 = 126M = identical to baseline;
LgWordCset: 133363005 = 134M  Hm. 9M more ob.

Key 10317416  *-FrequencyKey-*
Key 10872983  *-Mutual Info Key-*

1461271903 bytes uncompressed = 1.46G
208591406 bytes compressed = 209 MB

180dff2b3d683ad5559290338b5815fa  en_pairs_tone_mst.sql
e7dddab32c92b0fd0e88adfe6be1a87b  en_pairs_tone_mst.sql.bz2

==================================================================
en_pairs_ttwo
-------------
Random parses from tranche-1 and tranche-2. 

STATUS: good
DATE: 29 May 2017
REASON: I think it's good.

                        List of relations
 Schema |    Name    | Type  | Owner  |    Size    | Description 
--------+------------+-------+--------+------------+-------------
 public | atoms      | table | ubuntu | 1483 MB    | 
 public | spaces     | table | ubuntu | 40 kB      | 
 public | typecodes  | table | ubuntu | 56 kB      | 
 public | valuations | table | ubuntu | 956 MB     | 
 public | values     | table | ubuntu | 8192 bytes | 

select count(*) from atoms; <<< 16817599 = 16.8M atoms (6M more than tone)
select count(*) from valuations; <<< 8770525 = 8.8m (3.4M more)

SELECT count(atoms.uuid) FROM atoms,typecodes WHERE
atoms.type=typecodes.type AND typecodes.typename='foobar';

WordNode: 186573 = 187K (47K more)
EvaluationLink:  8047063 = 8M (3.1M more)

SELECT sum(floatvalue[3]) FROM valuations WHERE type=7;
767377888 << 767M observations = 370M more

SELECT sum(valuations.floatvalue[3]) FROM valuations, atoms, typecodes
WHERE valuations.atom=atoms.uuid AND atoms.type=typecodes.type AND
typecodes.typename='EvaluationLink';

EvaluationLink: 267913561 << 268M pair obs, more than double of tone.
WordNode: 243085829 << 243 M -- almost double
LgWordCset: << 243114608 -- almost double

SentenceNode << 795835 = 796K more than double
ParseNode << 12468055 = 12.5M parses more than double.

772033746 Bytes = 772M uncompressed.
132694670 Bytes = 133M compressed

8bbfb8f0f4956f21ec1120b550890e0f  en_pairs_ttwo.sql
0b1908dfc232de4ea4e20d616cbbe290  en_pairs_ttwo.sql.bz2

==================================================================
==================================================================
==================================================================
==================================================================

Plan:
load en_pairs_mst
load en_pairs_semi_fu
recompute MI for word-pairs.
fork, and restart mst counting...


(use-modules (opencog) (opencog persist) (opencog persist-sql))
(sql-open "postgres:///en_pairs_mst?user=linas")
(use-modules (opencog cogserver))
(start-cogserver "opencog3.conf")
(sql-load)

sql-load has no docs

also missing type inheritance!  (but what if inheritance conflicts!?)

SQLAtomStorage.cc:1583 thrown by makeAtom
but who calls makeAtom?
load_all_atoms_cb

QLAtomStorage.cc:1360 null pointer deref.
get_recursive_if_not_exists
from :1377 PseudoPtr po(petAtom(idu)); returned null ptr for 132204462

132204462
132272910
132300252
133895580
133896697
133884903

27 missing uuids so far.  They're not in rohit, so wtf?

1673 should be omp-algo


#define OC_OMP 1
setting_omp(num_threads(), 3);
num_threads


SELECT uuid, name FROM atoms WHERE type = 73
  EXCEPT SELECT atoms.uuid,atoms.name FROM atoms, atoms_wtf 
     WHERE atoms_wtf.uuid = atoms.uuid;

 2293473835 | tail-piece
 1621296002 | dendropark
 2146998680 | Fellers
  244689200 | PVC
 1438975809 | Arntzenius
  709360907 | server-based
 2400387025 | Kihelkonna
  799467208 | Crispe's
  610089230 | Byssocallis
  325547913 | leveraging
  179977711 | amounted
  492116248 | Kampf
  209124496 | Barranca
 1158151745 | Ilisl
 1005621585 | Caravans
 1926542305 | agonising
 1593374046 | Urged


SELECT * FROM Atoms WHERE outgoing @> ARRAY[CAST(2293473835 AS BIGINT)];

 2293477332 |     1 |    8 |      1 |      | {570739,2293473835}
 2293477368 |     1 |    8 |      1 |      | {1537258,2293473835}
 2293477336 |     1 |    8 |      1 |      | {2293473835,241}
 2293477334 |     1 |    8 |      1 |      | {573730097,2293473835}
 2293477354 |     1 |    8 |      1 |      | {4369780,2293473835}
 2439795736 |     1 |    8 |      1 |      | {143427138,2293473835}
 2439795738 |     1 |    8 |      1 |      | {2293473835,143427163}


CREATE TABLE tmp_atoms AS 
   SELECT   uuid,  space, type, height, name, outgoing 
   FROM atoms WHERE height=0
     EXCEPT SELECT atoms.uuid,  atoms.space, atoms.type, atoms.height, atoms.name, atoms.outgoing
          FROM atoms, atoms_wtf 
          WHERE atoms_wtf.uuid = atoms.uuid;

338354

UPDATE tmp_atoms SET type= x WHERE NAME='joe';

INSERT INTO atoms_wtf 
   SELECT   uuid,  space, type, height, name, outgoing 

fuck it. 
load rohit first, then load semi_fu then load mst

(use-modules (opencog) (opencog persist) (opencog persist-sql))
(use-modules (opencog nlp))
(use-modules (opencog cogserver))
(sql-open "postgres:///en_pairs_rohit?user=linas")
(start-cogserver "opencog2.conf")
(sql-load)
OK, that's loading in parallel yayyy! peaked over 17K/second
dropped down to 11.3K per sec
Need to load 19M for this one <<< 19741280 
     ... in 1691 seconds (11674 per second)
     ... using 27GB RAM
     ... in approx 260 cpu-minutes.

OK, so can hit rates over 20K atoms/sec during loads, when the 
DB is in RAM (or maybe SSD). Drops to 300 atoms/sec when DB is
on spinning disk. Ouch!

Hmmm .. 20K/sec if there are not values on the atom.
10K/sec if there are values ...

So when bulk loading....
calls load_all_atoms_cb
which does get values.   get_atom_values
get_all_values_cb

(sql-close)
(sql-open "postgres:///en_pairs_semi_fu?user=linas")
(sql-load)
loaded 132172832  in 9938 seconds (13299 per second)
Atomspace holds 146629585 atoms in 171GBytes RAM. Ouch. 1159:08 CPU
again: 953:04.24 CPU again 949:04.10

(sql-close) <<< 1163:38 CPU
(sql-open "postgres:///en_pairs_semi_ok?user=linas")
(sql-store)
Store rate is 20K atoms/minute! 1.2M/hour --> 100 hours (4 days) to
store fu.  Lets try again. parallelize too

So... store queues not being used. Lots of fetches, but these
seem pointless ?  FIXED
Max UUID is 2 !!!!??   FIXED

OK, better: 1.3K/sec, about 100K/min - 1470 min = 24 hours

num_get_links and write queues not used.  FIXED
... and max uuid is still 2. FIXED
should call storeAtom(h, false) FIXED

OK, store queues are cranking away, 100% i/o bound.  1.1K/sec
--> 38 hours to complete!  Ouch.
... dropped to 603 per second after 15% complete.

Plan B:
copy en_pairs_semi_fu to en_pairs_wiki
load en_pairs_mst
close
open en_pairs_wiki

=================================
/home/ubuntu/src/atomspace/opencog/persist/sql/multi-driver/ll-pg-cxx.cc:113)

PQresult message: ERROR:  could not read block 479803 in file
"base/16446/16452.3": read only 0 of 8192 bytes
SELECT * FROM Atoms WHERE type = 82 AND outgoing = '{23, 7830585, 9}';
SELECT * FROM Atoms WHERE type = 137 AND outgoing = '{232023, 14}';
SELECT * FROM Atoms WHERE type = 137 AND outgoing = '{2433080, 852}';
SELECT * FROM Atoms WHERE type = 137 AND outgoing = '{9196089, 2499}';
SELECT * FROM Atoms WHERE type = 137 AND outgoing = '{3250528, 10}';
SELECT * FROM Atoms WHERE type = 82 AND outgoing = '{23, 30218901, 9}';

/usr/lib/postgresql/9.5/bin/pg_resetxlog  /var/lib/postgresql/9.5/main

Crap.  Total data corruption.
Restart, again
====================================
/etc/postgresql/9.6/main/postgresql.conf
increase shared_buffers to 24GB
shared_buffers = 24GB
max_worker_processes = 24
fsync = on  
effective_cache_size = 128GB

increse  /etc/sysctl.d/30-postgresql-shm.conf too

grep ^VmPeak /proc/4170/status

hugpages may be too big... but anonhugepages shoud work fine

no commit delay:  300%, 70% idle 6% wait 10 loadavg 10m val/h 20a/h
10K commit
11:18

=====================================================
-- Restart counting. Done,  May 21 06:15 UTC

As of: 2017-05-21 18:59:08 i.e. 12.7 hours later,
284 articles 

select count(*) from atoms; <<< 1832992 = 1.8M

SELECT count(atoms.uuid) FROM atoms,typecodes WHERE
atoms.type=typecodes.type AND typecodes.typename='EvaluationLink';
gives 840285 = 840K  and equal number of ListLink
39772 = 39K WordNode

SELECT sum(floatvalue[3]) FROM valuations WHERE type=7;
aka
SELECT sum(valuations.floatvalue[3]) FROM valuations,typecodes
WHERE valuations.type=typecodes.type AND typecodes.typename='CountTruthValue';

gives 39459145 = 39M counts = 3.1M counted per hour = 863 pairs/second

----------------
As of 2017-05-22 05:56:04 i.e. 24 hours later
497 articles  .. really 500 a day, avg.

select count(*) from atoms; << 2829421 = 2.8M
1309922 = 1.3M EvaluationLinks
53781 = 54K words

67789172 = 68M counts = 2.8M/hour = 784 pairs/sec

----------------
As of 2017-05-22 23:58:10 
888 articles

select count(*) from atoms; <<< 4239364 = 4.2M 
1980561 = 2M eval links
71595 = 71K words

116752710 = 117M counts in 42 hours = 2.8M/hour
          or (117M-68M) / 18 hours = 2.7M/hour

------------------
Restart from scratch 2017-05-23 00:10:00
at 01:51 have 129302108= 129M so 12M in 1.7 hours = 7M/hour
So now its more than 2x faster. almost 3x, with rounding errors
Yayyyy!!!

05:30 152806491 =153 -117 = 36M obs in 5.4 hours = 6.7M obs/hour
                = 1854 obs/second

----------------------------------------------------

Why is it slowing?
---------------
1) why is valuation updates about 3.5x of sum(3)?
2) why is get-got almost 2x bigger than delta for nodes? A: 
3) why is get-got almost 1.5x bigger than delta for links? A: LgAnd's

One sentence:
sum valuations=245   but 461 valuation updates!?
5 WordNodes
7 ListLinks
7 EvaluationLinks
----------------- expect 19 atoms
got 41 atoms... many are LgWordCsets, LgAnd's OK.  total stores is perfect.

num_get_nodes=34 huh???
this time, 922 updates!!!! wtf
why are fecth and store counts same?? maybe cause not syn
cog-logger-set-sync!

There were 23 fetches logged:
1 sent
1 parse
5 word
 -- total 7 nodes
?? where are the connectors? not fetched, cause not incr'ed so OK.
7 eval
9 lgwordcset
 -- total 16 links
 ListLinks, not fetched cause not incr'ed. so OK.

245 stores. again 922 updates of values...

SentenceNode got update twice...
ParseNode twice ... 
2x for all the words ... 

Then lots of updates, even when not teh main target of the store...
Now, only 490 updates. Still too many. should be 245 ... !?
barrier is broken.. wewell its not forcing a flush

does close have a barrier?

well, busy_writers is a bad idea... because it races.
but queue size was wrong.

OK, so 105 of 245 ... 123 

 why is fillfraction 55K ? Because drain is no longer being hit.

=====================================================
TODO:
-- verify integrity of the database.
-- verify that MST has all the pairs that rohit does. OK.
-- Update the dump status above; copy it over. OK, Done.
-- Create the missing status on en_pairs_sim from the paper.


(use-modules (opencog) (opencog persist) (opencog persist-sql))
(use-modules (opencog nlp) (opencog nlp learn))
(sql-open "postgres:///en_pairs_sim?user=linas")
(use-modules (opencog cogserver))
(start-cogserver "opencog2.conf")
(define pca (make-pseudo-cset-api))
(batch-pairs pca)

So now word-pair loading is out of control...
loadeed csets in 553 seconds, same as before, but at 2400% cpu

Crap.  Below is a disaster.
commit_delay = 0
synchronous_commit = local
Stored 1000 of 291637 lefties in 270 secs (3.7037037037037037 stores/sec)
Stored 2000 of 291637 lefties in 320 secs (3.125 stores/sec)

Try again:
commit_delay = 0
synchronous_commit = off
Stored 20000 of 291637 lefties in 45 secs (444.44444444444446 stores/sec)
Stored 40000 of 291637 lefties in 47 secs (425.531914893617 stores/sec)
Stored 60000 of 291637 lefties in 62 secs (322.5806451612903 stores/sec)

OK, so we are back in business
======================================================================

(add-pair-mi-api pca) 'compute-left-fractional

right-wild gives dj

/tmp/ranked-word-ent.dat

(define cs (cog-incoming-by-type (Word "possible") 'LgWordCset))

(filter (lambda (cset) (< 10 (get-count cset))) cs)

possible N=3 has 1: a-
         N=2 has 5: (is- that+) (it- to+) 
         N=1 = 106

education: 100  N=3 has 1  N=2 has 7

lost 100  1 and 7
days  98 2 7
children 101 1 9

(define bins (second binned-pair-mi))
(fold + 0 (array->list bins))

-----------------------------------------------------------
1 word was observed 38977 times
 37502
32517
22632

differences:
there is a left and a right diff.
The wild-card support needs to be a union
overload 'left-stars 'right-stars 'pair-count 'item-pair
this can be a generic map function of any kind! not just a diff!

=======================================
There is no value for key (PredicateNode "*-FrequencyKey-*")

en_pairs_tone_mst: spinnning drives:
Done storing 4886362 pair MI's in 6903 secs


=======================================

OK, so:
pca is the pseudo-cset-api
pma adds special stars to it
pdi will provide utilities
   pdi takes pma and wraps it with default stars
      default stars should see the pma under it.

15265 pos only

15420 the all by itself
 7168 for "a"
total 15420+7168 -256 = 22588 - 256 = 22332  which is what union reports...
unions 22260 < so wtf is this? oh 72 obse are identical!
256 interested!  sum = 22260+256 = 22516

Hmmm. 
-       (filter!
-               (lambda (wrd)
-                       (not (null? (get-cset-vec wrd))))
-               WORD-LIST)

(cog-incoming-by-type ITEM 'LgWordCset)

 Error: do_store_single_atom: Maxiumum Link size is 330.
 (/home/ubuntu/src/atomspace/opencog/persist/sql/multi-driver/SQLAtomStorage.cc:1202)
Aborted

relex crash always on this:
“What the hell is happening here?!”
split-books/gneiosric-ab   three out of three crashes

cat gneiosric-ab | ./split-sentences.pl > g-split
./ss-one.sh en gneiosric-ab localhost 17005

cat g-split | ./submit-one.pl localhost 17005 observe-text  breaks
g2  breaks
g2b breaks
g2guess is OK
g2bb is OK
g2ba breaks
g2baa is OK
g2bab breaks
g2baba breaks
g2babaa is OK
g2babab breaks
g2bababa breaks
g3 is OK

cat g4 |nc localhost 4445   breaks!
echo 「...」 |nc localhost 4445  breks
link-parser works ... but eats the trailing character...!?

and generates zillions of parses!!??

of which most are identical...
relex definitely crashes...
linkage_set_domain_names+0xe0

6 links,
5th link crashes..
dtype array holds junk

dtsz supposed to be the actual size of valid entries
ppn->dtsz

chk_d_type reallocs but does not memset....
dtsz is too small.!!
chk_d_type

chk_d_type(pp->pp_node, numli...
 do not set the pipinfo if domains is zero.
so do not free. either

*** START OF THIS PROJECT GUTENBERG EBOOK
***START OF THE PROJECT GUTENBERG EBOOK

END OF THIS PROJECT GUTENBERG EBOOK

*** START: FULL LICENSE ***
The Full Project Gutenberg License

sed -n '/PROJECT GUTENBERG EBOOK/,$p' filename

schweben

getp "is a"
54756-0.txt

grep -l 大
grep -l Anmerkungen *

purezza
quella

if

Langauge:

54637-0.txt
54640-0.txt
54652-0.txt
54655-0.txt
54660-0.txt
54665-0.txt
54667-0.txt
54668-0.txt
54672-0.txt
54675-0.txt
54676-0.txt
54679-0.txt
54681-0.txt
54706-0.txt
54711-0.txt
54714-0.txt
54719-0.txt
54721-0.txt
54724-0.txt
54729-0.txt


guile

(use-modules (opencog) (opencog persist) (opencog persist-sql))
(use-modules (opencog nlp) (opencog nlp learn))
(use-modules (opencog cogserver))
(start-cogserver "opencog2.conf")
(sql-open "postgres:///en_pairs_tone_mst?user=ubuntu")
(sql-load)
(sql-stats)
(sql-close)
Finished loading 16487725 atoms in total in 2212 seconds (7453 per second)
started at 20K/sec .. towards end, was 75% system cpu... why????
21GB ram = 1400Bytes/atom. as usual. Need a diet plan.

(sql-open "postgres:///en_pairs_ttwo?user=ubuntu")
(sql-load)
(sql-stats)
(sql-close)
Finished loading 16817599 atoms in total in 991 seconds (16970 per second)
Much faster because most atoms are in atomspace already.
sql-stats: Atomspace holds 22987920 atoms ... and is 26GB in size.


(sql-open "postgres:///en_pairs_ttwo_mst?user=ubuntu")
(sql-store)
(sql-stats)
(sql-close)

Initial rate is (3389 per second) on SSD which is 10x the spinning-disk
Peaked at (3546 per second) half-way throough
Dropped to (2537 per second) overall average.
version but is still pathetically slow.
iotop shows 3.2 MBytes/sec  and about 770 tps
so where is the bottleneck?
 Bottleneck is still disk i/o, even though its SSD:
how can I tell?
1) guile is under 90% cpu
2) 20+ postgres procs show 30% cpu, each
3) sql-stats shows 8 threads busy draining.
4) loadavg shows 6
5) top shows > 2.0% wait,  (on 24 cpus!) 4% system 18% user 75% idle
   viz about 0.5 cou wait, 1 cpu system, 4cpu's busy
   and since guile is less than  1 cpu, the postgres take up the
   remaining cpu.  Since 18 cpus are idle, we must be stalled in i/o.
So, somehow still stuck in i/o waiting for postgres to flush to disk.

6) iotop shows 60 to 100 MBytes/sec, highly variable.
   wait sometimes spikes to 15% (and io dropts to zero)
   sometimes rate spikes to 300MB/sec! but rarely.

7) Launching any-parsing does not seem to affect iowait!
   Nore does it change store performance at all!!!
   but it does raise the write rates and the tps

?? Is it postgres indexing? Can we suspend that while storing?

--------- meanhwile continue pair-parsing
launch tranche-3 any-parsing Tue May 30 04:39:44 UTC 2017

----- anyway, recompute pair mi and resume mst-parsing

en_pairs_ttwo_mst

(define ala (make-any-link-api))
(batch-all-pair-mi ala)
Final store: about  (1250.0 pairs/sec)
Done storing 8047063 pair MI's in 6905 secs

sql-stats: Atomspace holds 23178644 atoms = 23M = 35GBytes
Now can start tranche-2 MST parsing.

Done. Wow. That was fast! did anything actually happen?

select count(*) from atoms; <<< 27638783 = 27M

get-all-words -- 188793  vs. tone: 139790
all-cset-words -- 83131  vs tone 139790 ??
disjuncts -- 1670883 vs tone 1860796

wtf somethng broke....

(define (filter-words-with-csets WORD-LIST)
   (filter!  (lambda (wrd) (not (null? (get-cset-vec wrd)))) WORD-LIST))


---------- meanwhile, finish stats work
(fetch-all-sims)

general idea: how many pairs are there out of N^2?
what is the distribution of pair memebership?

sims should be LLOBJ

Umm batch-all-pair-mi is where?

batch-sim should NOT store!
batch-sim-pairs 

So: 1) cutoff for sim  2) cutoff for store.

start 2.4G and run 0.3 sim
again 0.1 sim...

possible: (37413 * 37412)/2 = 699847578 = 700M pairs
estimate: 6.5% of these, so= 45M pairs!? Ouch.  .. 50-60 GB RAM 
    and insanely slow .. 466K secs = 130 hrs = 5.4 days
running at 1.5K pairs/sec ouch.

Try again:
(use-modules (opencog) (opencog persist) (opencog persist-sql))
(use-modules (opencog nlp) (opencog nlp learn))
(sql-open "postgres:///en_pairs_ultrasim?user=linas")
(fetch-all-words)

(define pca (make-pseudo-cset-api))
(pca 'fetch-pairs)

(sql-clear-stats)
(define ac (get-all-cset-words)) 
(length ac)
(load "gram-sim.scm")
(batch-sim-pairs ac 0.1)

---------- meanwhile, compute & cache similarity
; (sql-open "postgres:///en_pairs_tone_sim?user=ubuntu")

Wait, where? 
Oh, gram-sim.

-----------
todo items:
* trim low observation counts ....
* implement sql delete function.

---------- debug hang:
latest bdgw from git does not solve it.
latest stable-2.2 guile does not solve it.

revert to distro bdwgc
#0  0x00007f362151c826 in __GI___sigsuspend (
    set=set@entry=0x7f36214b1740 <suspend_handler_mask>)
    at ../sysdeps/unix/sysv/linux/sigsuspend.c:30
#1  0x00007f3621293602 in GC_suspend_handler_inner
(dummy=dummy@entry=0x0, 
    context=context@entry=0x7fff6c807540) at pthread_stop_world.c:324
#2  0x00007f36212936cf in GC_suspend_handler (sig=30, info=<optimized
out>, 
    context=0x7fff6c807540) at pthread_stop_world.c:237

thr 2: find_slot_map (
    cache=0x7f361fe85ab0, ip=0x1) at ../../libguile/vm.c:936
#1  scm_i_vm_mark_stack (vp=0xbdca3120, mark_stack_ptr=0x7f361fe85ef0, 
    mark_stack_limit=0x7f361fe95eb0) at ../../libguile/vm.c:1011
#2  0x00007f36212883be in GC_mark_from (mark_stack_top=0x7f361fe85ea0, 
    mark_stack_top@entry=0x7f361fe85f00, 
    mark_stack=mark_stack@entry=0x7f361fe85eb0, 
    mark_stack_limit=mark_stack_limit@entry=0x7f361fe95eb0) at
mark.c:784
#3  0x00007f36212889de in GC_do_local_mark
(local_mark_stack=0x7f361fe85eb0, 
    local_top=0x7f361fe85f00) at mark.c:1048
#4  0x00007f3621288bf8 in GC_mark_local (
    local_mark_stack=local_mark_stack@entry=0x7f361fe85eb0,
id=id@entry=1)
    at mark.c:1181
#5  0x00007f3621288f0a in GC_help_marker
(my_mark_no=my_mark_no@entry=195743)
    at mark.c:1249
#6  0x00007f3621292edc in GC_mark_thread (id=<optimized out>)
    at pthread_support.c:380


single-stepping:

scm_i_vm_mark_stack (vp=0xbdca3120, mark_stack_ptr=0x7f361fe85ef0, 
    mark_stack_limit=0x7f361fe95eb0) at ../../libguile/vm.c:975
975            fp = SCM_FRAME_DYNAMIC_LINK (fp))
(gdb) print fp
$1 = (union scm_vm_stack_element *) 0x7f36183d5e38
(gdb) step
973       for (fp = vp->fp, sp = vp->sp;
(gdb) 
979           for (slot = nlocals - 1; sp < fp; sp++, slot--)
(gdb) 
1011          slot_map = find_slot_map (SCM_FRAME_RETURN_ADDRESS (fp),
&cache);
(gdb) 
1006          sp = SCM_FRAME_PREVIOUS_SP (fp);
(gdb) print fp
$2 = (union scm_vm_stack_element *) 0x7f36183d5e38
(gdb) print sp
$3 = (union scm_vm_stack_element *) 0x7f36183d5e48
(gdb) step
1011          slot_map = find_slot_map (SCM_FRAME_RETURN_ADDRESS (fp),
&cache);
(gdb) 
find_slot_map (cache=0x7f361fe85ab0, ip=0x1) at ../../libguile/vm.c:932
932       size_t slot = (((scm_t_uintptr) ip) >> 2) %
SLOT_MAP_CACHE_SIZE;
(gdb) 
935       if (cache->entries[slot].ip == ip)
(gdb) 
scm_i_vm_mark_stack (vp=0xbdca3120, mark_stack_ptr=0x7f361fe85ef0, 
    mark_stack_limit=0x7f361fe95eb0) at ../../libguile/vm.c:1011
1011          slot_map = find_slot_map (SCM_FRAME_RETURN_ADDRESS (fp),
&cache);
(gdb) 
find_slot_map (cache=0x7f361fe85ab0, ip=0x1) at ../../libguile/vm.c:936
936         map = cache->entries[slot].map;
(gdb) 
scm_i_vm_mark_stack (vp=0xbdca3120, mark_stack_ptr=0x7f361fe85ef0, 
    mark_stack_limit=0x7f361fe95eb0) at ../../libguile/vm.c:975
975            fp = SCM_FRAME_DYNAMIC_LINK (fp))
(gdb) print fp
$4 = (union scm_vm_stack_element *) 0x7f36183d5e38

git tag -l
Try guile-2.2  v2.2.0 Wed Mar 15 09:02:52 2017
Try guile-2.1.8  v2.1.8 Fri Mar 10 11:01:04 2017 tried it - spins. its broke
   (breaks after about 300 cpu-min)

OK guile-2.0.11 on xenial crashes almost immediately with
guile: hashtab.c:137: vacuum_weak_hash_table: Assertion `removed <= len' failed.


=======================
other guile bugs:
 (acos 1.0)  can return small imaginaey number
 (fold of reals can return small imaginary parts

=======================
total unique pairs
1) no way to get all pairs...
2) support not computed or stored.. DONE
3) stored support not fetchable FIXED with report-API
4) store left and right sizes DONE
cache-all-pair-freqs returs total 

* sep out bin-counting code into own file DONE
add-subtotal-mi-compute DONE

call-only-once in sing
fetch-all-words in sing
add-pair-freq-api in mst

(use-modules (opencog) (opencog persist) (opencog persist-sql))
(use-modules (opencog nlp) (opencog nlp learn))
(use-modules (opencog analysis))
(sql-open "postgres:///en_pairs_sim?user=linas")
(fetch-all-words)

(define ala (make-any-link-api))
(ala 'fetch-pairs)  << 1099 secs 1074 1028
(batch-short ala)
(batch-all-pair-mi ala)

Support: found num left=395274 num right=396260 in 426 secs << 395, ph:527
Done with wild-card count N(x,*) and N(*,y) in 1259 secs << ph:1300
Done computing N(*,*) total-count=418235277.0 in 51 secs << ph:46
Going to do individual pair frequencies
Done computing 8880914 pairs in 1074 secs  << 1007 ph:872
Start computing log P(*,y)
Done computing 396260 left-wilds in 61 secs << ph:51
Done storing 396260 left-wilds in 121 secs << ph:115
Done computing 395274 right-wilds in 55 secs << ph:51
Done with -log P(*,y), start -log P(x,*)
Done storing 395274 right-wilds in 121 secs << ph:127
Done computing -log P(x,*) and P(*,y)
Going to do individual pair MI
Too many heap sections: Increase MAXHINCR or MAX_HEAP_SECTS
Fuck.

alloc.c:        ABORT("Too many heap sections: Increase MAXHINCR or
MAX_HEAP_SECTS");
MAX_HEAP_SECTS
include/private/gc_priv.h:#   define MAXHINCR 4096

define HBLKSIZE 4096
include/private/gc_priv.h:#
 define MAX_HEAP_SECTS 8192  if -DLARGE_CONFIG
--enable-large-config
--enable-parallel-mark didn't do this.

Done computing 8880914 pair MI's in 3590 secs
Done storing 8880914 pairs in 4190 secs
Going to do column and row subtotals
Finished left entropy subtotals in 580 secs
Finished right entropy subtotals in 517 secs
Finished left MI subtotals in 353 secs
Finished right MI subtotals in 330 secs
Finished left support subtotals in 1021 secs << 772 after star fix
Finished right support subtotals in 961 secs << 745
Going to compute the left, right and total entropy
Finished left norm totals in 210 secs << 232
Finished right norm totals in 210 secs << 237
Done computing totals in 2360 secs
Start saving left-wildcards
Done storing 396260 left-wilds in 224 secs
Done storing 395274 right-wilds in 230 secs
Finished with MI computations


========================================================
support stats

|(*,y)| = number of non-zero entries for column y

sum_y |(*,y)| = right-support

sqrt [ sum_x N^2 (x,*) / num-rows ]

left-length(y) = sqrt(sum_x N^2(x,y)) = col-length
so sum over rights
divide by num-rights == num cols
so this is right-legnth

<xun> = sum_y N(*,y) / num-cols
      = N(*,*) / num-cols

<0w> = sum_y p(*,y) |(*,y)|

<xw> = s x p
    = sum_y p(*,y) N(*,y)

but p(*,y) = N(*,y) / N(*,*)

<x^2w> = s x^2 p 
       = sum_y p(*,y) N^2(*,y)

s (x- <xw>)^2  p =

<x^2w> - 2<xw> s x p + <xw>^2
= <x^2w> - <xw>^2

anyway, its not clear that's what we want, anyway.  Do we want count
variation? or length variation?  length variation is trite if we've got
totals. But count-variation requires....

2d 2 obj, each = 1, avg=1

<x^2w> = 1/2 + 1/2 = 1 ... 
so for lensq, needed to divide by support.
and for avg, need to divide by support too.


Argh. Sim has the old style. pair-entropy

(define fla (add-pair-freq-api ala))
(define rla (add-report-api ala))
(rla 'left-dim)
(rla 'right-dim)
(rla 'num_pairs)
(rla 'left-entropy)
(rla 'right-entropy)
(rla 'total-entropy)
(rla 'total-mi)

(define pca (make-pseudo-cset-api))
(pca 'fetch-pairs)
(batch-all-pair-mi pca)  
(define fca (add-pair-freq-api pca))
(define ac (get-all-cset-words))

5205

(fca 'pair-mi  xxxx)
So:
(EvaluationLink  ; 388
 (LinkGrammarRelationshipNode "ANY")
  (ListLink (AnyNode "left-word") (WordNode "one-point")))
has no "*-Entropy Key-* why?
because not computeed ... why?
Going to do MI column and row subtotals
should be 'cache-all-subtotals
Going to compute the left, right and total entropy

(define wca (add-pair-stars pca))
(define fca (add-pair-freq-api wca))
(define rb (wca 'right-basis))
(define dj (car rb))
(define lwd (pca 'left-wildcard dj))
 (fca 'left-wild-entropy dj)

      (define (left-sum FN)
         (fold
            (lambda (right-item sum)
               (+ sum (FN right-item)))
            0 rb))

      (define (right-sum FN)
         (fold
            (lambda (left-item sum)
               (+ sum (FN left-item)))
            0 (wca 'left-basis)))

argh. compute-left-entropy is wrong... FIXED
(define rca (add-report-api wca))
(rca 'set-entropy le re tent)
wild-wild-counta DONE
time for totlaa DONE

(define (an llobj) 
	(lambda (message . args)
		(case message ((name) "the big old name")
		(else (apply llobj (cons message args))))))


atom->getKeys()
    std::set<Handle> getKeys() const;

todo: print times  DONE
todo: create a report. DONE
todo: investigate exception DONE

todo: how many words, on average, go into a pair?
what about hubiness? in the graph con sense?
i.e avg incomiing avg outgoing (i.e. left, right support sizes)

avg left-support: non-zero / num-lefts(rows) 
left-size: tot count /num-lefts<F8>x

avg length
( err... left-length 'rigt-basis



Crazy idea: iterate; the places we end up at should be the dependents
since everything points at them, and they never point away.
